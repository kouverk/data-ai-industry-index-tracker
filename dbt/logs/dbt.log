[0m17:47:16.778523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a88ba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c037c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c037ed0>]}


============================== 17:47:16.786875 | 71de3fa4-fdb5-40e6-814d-dcfa2e5ed5d4 ==============================
[0m17:47:16.786875 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:47:16.787783 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'log_format': 'default', 'printer_width': '80', 'log_path': '/Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/logs', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'version_check': 'True', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '.', 'no_print': 'None', 'indirect_selection': 'eager', 'invocation_command': 'dbt debug --profiles-dir .', 'log_cache_events': 'False', 'introspect': 'True', 'empty': 'None', 'quiet': 'False'}
[0m17:47:16.819173 [info ] [MainThread]: dbt version: 1.10.13
[0m17:47:16.819663 [info ] [MainThread]: python version: 3.13.0
[0m17:47:16.820068 [info ] [MainThread]: python path: /Users/kouverbingham/.pyenv/versions/3.13.0/bin/python3.13
[0m17:47:16.820390 [info ] [MainThread]: os info: macOS-15.7.3-x86_64-i386-64bit-Mach-O
[0m17:47:16.830539 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'SNOWFLAKE_ACCOUNT'
[0m17:47:16.837424 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.17416091, "process_in_blocks": "0", "process_kernel_time": 0.514742, "process_mem_max_rss": "118468608", "process_out_blocks": "0", "process_user_time": 3.494493}
[0m17:47:16.838295 [debug] [MainThread]: Command `dbt debug` failed at 17:47:16.838112 after 0.18 seconds
[0m17:47:16.839219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0d6780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c106330>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1099d0>]}
[0m17:47:16.840202 [debug] [MainThread]: Flushing usage events
[0m17:47:17.173590 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:47:37.483591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110447a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bf3c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bf3ed0>]}


============================== 17:47:37.493083 | 4f936df2-657f-445e-a222-b976dab4855e ==============================
[0m17:47:37.493083 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:47:37.494705 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'log_format': 'default', 'no_print': 'None', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'empty': 'None', 'fail_fast': 'False', 'quiet': 'False', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'invocation_command': 'dbt debug --profiles-dir .', 'log_path': '/Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/logs', 'static_parser': 'True', 'profiles_dir': '.', 'warn_error': 'None', 'printer_width': '80', 'partial_parse': 'True', 'target_path': 'None', 'debug': 'False', 'use_experimental_parser': 'False', 'version_check': 'True'}
[0m17:47:37.516759 [info ] [MainThread]: dbt version: 1.10.13
[0m17:47:37.517367 [info ] [MainThread]: python version: 3.13.0
[0m17:47:37.517764 [info ] [MainThread]: python path: /Users/kouverbingham/.pyenv/versions/3.13.0/bin/python3.13
[0m17:47:37.518142 [info ] [MainThread]: os info: macOS-15.7.3-x86_64-i386-64bit-Mach-O
[0m17:47:39.368338 [info ] [MainThread]: Using profiles dir at .
[0m17:47:39.369032 [info ] [MainThread]: Using profiles.yml file at ./profiles.yml
[0m17:47:39.369414 [info ] [MainThread]: Using dbt_project.yml file at /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/dbt_project.yml
[0m17:47:39.370701 [info ] [MainThread]: adapter type: snowflake
[0m17:47:39.371441 [info ] [MainThread]: adapter version: 1.10.2
[0m17:47:39.516669 [info ] [MainThread]: Configuration:
[0m17:47:39.517189 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m17:47:39.517698 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m17:47:39.518089 [info ] [MainThread]: Required dependencies:
[0m17:47:39.518647 [debug] [MainThread]: Executing "git --help"
[0m17:47:39.578762 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:47:39.581194 [debug] [MainThread]: STDERR: "b''"
[0m17:47:39.582802 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m17:47:39.583714 [info ] [MainThread]: Connection:
[0m17:47:39.584377 [info ] [MainThread]:   account: aab46027
[0m17:47:39.584839 [info ] [MainThread]:   user: kouverk
[0m17:47:39.585396 [info ] [MainThread]:   database: DATAEXPERT_STUDENT
[0m17:47:39.585869 [info ] [MainThread]:   warehouse: COMPUTE_WH
[0m17:47:39.586341 [info ] [MainThread]:   role: ACCOUNTADMIN
[0m17:47:39.586986 [info ] [MainThread]:   schema: KOUVERK_DATA_INDUSTRY
[0m17:47:39.588063 [info ] [MainThread]:   authenticator: None
[0m17:47:39.588822 [info ] [MainThread]:   oauth_client_id: None
[0m17:47:39.589195 [info ] [MainThread]:   query_tag: None
[0m17:47:39.589594 [info ] [MainThread]:   client_session_keep_alive: False
[0m17:47:39.589949 [info ] [MainThread]:   host: None
[0m17:47:39.590282 [info ] [MainThread]:   port: None
[0m17:47:39.590681 [info ] [MainThread]:   proxy_host: None
[0m17:47:39.591269 [info ] [MainThread]:   proxy_port: None
[0m17:47:39.591774 [info ] [MainThread]:   protocol: None
[0m17:47:39.592193 [info ] [MainThread]:   connect_retries: 1
[0m17:47:39.592798 [info ] [MainThread]:   connect_timeout: None
[0m17:47:39.593457 [info ] [MainThread]:   retry_on_database_errors: False
[0m17:47:39.593913 [info ] [MainThread]:   retry_all: False
[0m17:47:39.594308 [info ] [MainThread]:   insecure_mode: False
[0m17:47:39.594708 [info ] [MainThread]:   reuse_connections: True
[0m17:47:39.595213 [info ] [MainThread]:   s3_stage_vpce_dns_name: None
[0m17:47:39.596092 [info ] [MainThread]: Registered adapter: snowflake=1.10.2
[0m17:47:39.813999 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m17:47:39.903498 [debug] [MainThread]: Using snowflake connection "debug"
[0m17:47:39.903982 [debug] [MainThread]: On debug: select 1 as id
[0m17:47:39.904335 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:47:42.958600 [debug] [MainThread]: Snowflake adapter: Error running SQL: select 1 as id
[0m17:47:42.959814 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m17:47:42.960968 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m17:47:42.962196 [info ] [MainThread]: [31m1 check failed:[0m
[0m17:47:42.963042 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  250001 (08001): Failed to connect to DB: aab46027.snowflakecomputing.com:443. Role 'ACCOUNTADMIN' specified in the connect string is not granted to this user. Contact your local system administrator, or attempt to login with another role, e.g. PUBLIC.

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m17:47:42.972161 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 5.617357, "process_in_blocks": "0", "process_kernel_time": 0.802345, "process_mem_max_rss": "222937088", "process_out_blocks": "0", "process_user_time": 4.896184}
[0m17:47:42.973358 [debug] [MainThread]: Command `dbt debug` failed at 17:47:42.973109 after 5.62 seconds
[0m17:47:42.974139 [debug] [MainThread]: Connection 'debug' was left open.
[0m17:47:42.974787 [debug] [MainThread]: On debug: No close available on handle
[0m17:47:42.975496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d057950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d1b55b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d008490>]}
[0m17:47:42.976347 [debug] [MainThread]: Flushing usage events
[0m17:47:43.200728 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:48:29.952982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2f3a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa5bc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa5bed0>]}


============================== 17:48:29.960750 | fad17fad-2545-44b7-9988-1173cdf47937 ==============================
[0m17:48:29.960750 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:48:29.961506 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'write_json': 'True', 'quiet': 'False', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'no_print': 'None', 'partial_parse': 'True', 'log_cache_events': 'False', 'warn_error': 'None', 'use_experimental_parser': 'False', 'profiles_dir': '.', 'use_colors': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt debug --profiles-dir .', 'debug': 'False', 'target_path': 'None', 'log_format': 'default', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'empty': 'None', 'log_path': '/Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/logs'}
[0m17:48:29.977251 [info ] [MainThread]: dbt version: 1.10.13
[0m17:48:29.977743 [info ] [MainThread]: python version: 3.13.0
[0m17:48:29.978084 [info ] [MainThread]: python path: /Users/kouverbingham/.pyenv/versions/3.13.0/bin/python3.13
[0m17:48:29.978435 [info ] [MainThread]: os info: macOS-15.7.3-x86_64-i386-64bit-Mach-O
[0m17:48:31.249449 [info ] [MainThread]: Using profiles dir at .
[0m17:48:31.250273 [info ] [MainThread]: Using profiles.yml file at ./profiles.yml
[0m17:48:31.250887 [info ] [MainThread]: Using dbt_project.yml file at /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/dbt_project.yml
[0m17:48:31.251814 [info ] [MainThread]: adapter type: snowflake
[0m17:48:31.252282 [info ] [MainThread]: adapter version: 1.10.2
[0m17:48:31.447455 [info ] [MainThread]: Configuration:
[0m17:48:31.448034 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m17:48:31.448461 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m17:48:31.448870 [info ] [MainThread]: Required dependencies:
[0m17:48:31.449674 [debug] [MainThread]: Executing "git --help"
[0m17:48:31.479342 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:48:31.480962 [debug] [MainThread]: STDERR: "b''"
[0m17:48:31.481591 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m17:48:31.482058 [info ] [MainThread]: Connection:
[0m17:48:31.482723 [info ] [MainThread]:   account: aab46027
[0m17:48:31.483487 [info ] [MainThread]:   user: kouverk
[0m17:48:31.484016 [info ] [MainThread]:   database: DATAEXPERT_STUDENT
[0m17:48:31.484422 [info ] [MainThread]:   warehouse: COMPUTE_WH
[0m17:48:31.485081 [info ] [MainThread]:   role: None
[0m17:48:31.485926 [info ] [MainThread]:   schema: KOUVERK_DATA_INDUSTRY
[0m17:48:31.486438 [info ] [MainThread]:   authenticator: None
[0m17:48:31.486989 [info ] [MainThread]:   oauth_client_id: None
[0m17:48:31.487605 [info ] [MainThread]:   query_tag: None
[0m17:48:31.488365 [info ] [MainThread]:   client_session_keep_alive: False
[0m17:48:31.488882 [info ] [MainThread]:   host: None
[0m17:48:31.489526 [info ] [MainThread]:   port: None
[0m17:48:31.489968 [info ] [MainThread]:   proxy_host: None
[0m17:48:31.490456 [info ] [MainThread]:   proxy_port: None
[0m17:48:31.490800 [info ] [MainThread]:   protocol: None
[0m17:48:31.491261 [info ] [MainThread]:   connect_retries: 1
[0m17:48:31.491586 [info ] [MainThread]:   connect_timeout: None
[0m17:48:31.491956 [info ] [MainThread]:   retry_on_database_errors: False
[0m17:48:31.492418 [info ] [MainThread]:   retry_all: False
[0m17:48:31.492807 [info ] [MainThread]:   insecure_mode: False
[0m17:48:31.493514 [info ] [MainThread]:   reuse_connections: True
[0m17:48:31.494137 [info ] [MainThread]:   s3_stage_vpce_dns_name: None
[0m17:48:31.495274 [info ] [MainThread]: Registered adapter: snowflake=1.10.2
[0m17:48:31.674568 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m17:48:31.738494 [debug] [MainThread]: Using snowflake connection "debug"
[0m17:48:31.739273 [debug] [MainThread]: On debug: select 1 as id
[0m17:48:31.739713 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:48:34.889600 [debug] [MainThread]: SQL status: SUCCESS 1 in 3.150 seconds
[0m17:48:34.892091 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m17:48:34.892985 [info ] [MainThread]: [32mAll checks passed![0m
[0m17:48:34.900356 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 5.058915, "process_in_blocks": "0", "process_kernel_time": 0.708746, "process_mem_max_rss": "222593024", "process_out_blocks": "0", "process_user_time": 5.224143}
[0m17:48:34.901407 [debug] [MainThread]: Command `dbt debug` succeeded at 17:48:34.901196 after 5.06 seconds
[0m17:48:34.902031 [debug] [MainThread]: Connection 'debug' was left open.
[0m17:48:34.902572 [debug] [MainThread]: On debug: Close
[0m17:48:35.075432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11af03bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b05dd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aeb58c0>]}
[0m17:48:35.076530 [debug] [MainThread]: Flushing usage events
[0m17:48:35.388600 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:49:51.622195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e43a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5f7c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5f7ed0>]}


============================== 17:49:51.630821 | 738054f4-39b5-477a-9f53-5ea652826913 ==============================
[0m17:49:51.630821 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:49:51.631749 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'use_colors': 'True', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'log_path': '/Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/logs', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'quiet': 'False', 'static_parser': 'True', 'warn_error': 'None', 'profiles_dir': '.', 'log_format': 'default', 'write_json': 'True', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'None', 'cache_selected_only': 'False', 'printer_width': '80', 'invocation_command': 'dbt deps --profiles-dir .', 'partial_parse': 'True', 'target_path': 'None', 'introspect': 'True', 'debug': 'False', 'indirect_selection': 'eager'}
[0m17:49:51.880102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '738054f4-39b5-477a-9f53-5ea652826913', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109934510>]}
[0m17:49:51.907297 [debug] [MainThread]: Set downloads directory='/var/folders/28/cy7q0kv11699hc7mkbsl5qbc0000gn/T/dbt-downloads-24_sue_g'
[0m17:49:51.908006 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m17:49:52.168130 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m17:49:52.171815 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m17:49:52.283644 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m17:49:52.305170 [info ] [MainThread]: Updating lock file in file path: /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/package-lock.yml
[0m17:49:52.308502 [debug] [MainThread]: Set downloads directory='/var/folders/28/cy7q0kv11699hc7mkbsl5qbc0000gn/T/dbt-downloads-j9zl66yw'
[0m17:49:52.313973 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m17:49:52.886494 [info ] [MainThread]: Installed from version 1.3.3
[0m17:49:52.888376 [info ] [MainThread]: Up to date!
[0m17:49:52.889954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '738054f4-39b5-477a-9f53-5ea652826913', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a48f350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a48fdf0>]}
[0m17:49:52.916899 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 1.5356914, "process_in_blocks": "0", "process_kernel_time": 0.620653, "process_mem_max_rss": "125382656", "process_out_blocks": "0", "process_user_time": 4.087987}
[0m17:49:52.918551 [debug] [MainThread]: Command `dbt deps` succeeded at 17:49:52.918247 after 1.54 seconds
[0m17:49:52.945858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a69f950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a47a7b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a47b6b0>]}
[0m17:49:52.960134 [debug] [MainThread]: Flushing usage events
[0m17:49:53.344108 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:51:28.235635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a85fa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c00bc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c00bed0>]}


============================== 17:51:28.242801 | 0a9add7f-ba24-4059-82d7-9701adc024c6 ==============================
[0m17:51:28.242801 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:51:28.243558 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'target_path': 'None', 'fail_fast': 'False', 'cache_selected_only': 'False', 'no_print': 'None', 'log_path': '/Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/logs', 'introspect': 'True', 'indirect_selection': 'eager', 'printer_width': '80', 'partial_parse': 'True', 'empty': 'None', 'quiet': 'False', 'debug': 'False', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'log_format': 'default', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt seed --profiles-dir .', 'log_cache_events': 'False', 'warn_error': 'None', 'profiles_dir': '.', 'write_json': 'True'}
[0m17:51:30.354455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0a9add7f-ba24-4059-82d7-9701adc024c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b358510>]}
[0m17:51:30.452943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0a9add7f-ba24-4059-82d7-9701adc024c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1172f9370>]}
[0m17:51:30.454489 [info ] [MainThread]: Registered adapter: snowflake=1.10.2
[0m17:51:30.645288 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:51:30.646814 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m17:51:30.647333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0a9add7f-ba24-4059-82d7-9701adc024c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11730d050>]}
[0m17:51:34.250013 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values`. Arguments to generic tests
should be nested under the `arguments` property.`
[0m17:51:34.251474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '0a9add7f-ba24-4059-82d7-9701adc024c6', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1179bb4d0>]}
[0m17:51:34.880207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0a9add7f-ba24-4059-82d7-9701adc024c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11770b150>]}
[0m17:51:35.142926 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/manifest.json
[0m17:51:35.148468 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/semantic_manifest.json
[0m17:51:35.213419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0a9add7f-ba24-4059-82d7-9701adc024c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117dafa00>]}
[0m17:51:35.214241 [info ] [MainThread]: Found 18 models, 3 seeds, 49 data tests, 5 sources, 608 macros
[0m17:51:35.214796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0a9add7f-ba24-4059-82d7-9701adc024c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117c1d790>]}
[0m17:51:35.220065 [info ] [MainThread]: 
[0m17:51:35.221005 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:51:35.222953 [info ] [MainThread]: 
[0m17:51:35.224234 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m17:51:35.230693 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT'
[0m17:51:35.299887 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT"
[0m17:51:35.300421 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT: show terse schemas in database DATAEXPERT_STUDENT
    limit 10000
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT"} */
[0m17:51:35.300770 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:51:39.415635 [debug] [ThreadPool]: SQL status: SUCCESS 423 in 4.115 seconds
[0m17:51:39.427952 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT, now list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging)
[0m17:51:39.428782 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate'
[0m17:51:39.435220 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY'
[0m17:51:39.455653 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"
[0m17:51:39.451579 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"
[0m17:51:39.459037 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY"
[0m17:51:39.459821 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts'
[0m17:51:39.460562 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"} */;
[0m17:51:39.460961 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"} */;
[0m17:51:39.461356 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY"} */;
[0m17:51:39.463868 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"
[0m17:51:39.465048 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:51:39.465670 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:51:39.467045 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"} */;
[0m17:51:39.472609 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:51:39.854732 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c1de73-0107-8ace-0000-33eb033524e6
[0m17:51:39.855330 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m17:51:39.856195 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m17:51:39.856958 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m17:51:42.220866 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c1de73-0107-8ae8-0000-33eb0335341a
[0m17:51:42.222524 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m17:51:42.223645 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m17:51:42.224502 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m17:51:42.242186 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2.777 seconds
[0m17:51:42.349913 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01c1de73-0107-8ace-0000-33eb033524ea
[0m17:51:42.351008 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m17:51:42.352017 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m17:51:42.352771 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m17:51:42.354310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0a9add7f-ba24-4059-82d7-9701adc024c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ba901b0>]}
[0m17:51:42.365477 [debug] [Thread-2 (]: Began running node seed.data_ai_index.role_mappings
[0m17:51:42.367403 [info ] [Thread-2 (]: 2 of 3 START seed file KOUVERK_DATA_INDUSTRY.role_mappings ..................... [RUN]
[0m17:51:42.369345 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate, now seed.data_ai_index.role_mappings)
[0m17:51:42.370603 [debug] [Thread-2 (]: Began compiling node seed.data_ai_index.role_mappings
[0m17:51:42.371685 [debug] [Thread-1 (]: Began running node seed.data_ai_index.database_mappings
[0m17:51:42.373073 [debug] [Thread-3 (]: Began running node seed.data_ai_index.technology_mappings
[0m17:51:42.374108 [debug] [Thread-2 (]: Began executing node seed.data_ai_index.role_mappings
[0m17:51:42.375663 [info ] [Thread-1 (]: 1 of 3 START seed file KOUVERK_DATA_INDUSTRY.database_mappings ................. [RUN]
[0m17:51:42.382320 [info ] [Thread-3 (]: 3 of 3 START seed file KOUVERK_DATA_INDUSTRY.technology_mappings ............... [RUN]
[0m17:51:42.604682 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging, now seed.data_ai_index.database_mappings)
[0m17:51:42.631052 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY, now seed.data_ai_index.technology_mappings)
[0m17:51:42.652512 [debug] [Thread-1 (]: Began compiling node seed.data_ai_index.database_mappings
[0m17:51:42.661814 [debug] [Thread-3 (]: Began compiling node seed.data_ai_index.technology_mappings
[0m17:51:42.662664 [debug] [Thread-1 (]: Began executing node seed.data_ai_index.database_mappings
[0m17:51:42.663526 [debug] [Thread-3 (]: Began executing node seed.data_ai_index.technology_mappings
[0m17:51:42.697300 [debug] [Thread-2 (]: Using snowflake connection "seed.data_ai_index.role_mappings"
[0m17:51:42.698236 [debug] [Thread-2 (]: On seed.data_ai_index.role_mappings: create table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.role_mappings (keyword text,canonical_name text,tier integer)
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "seed.data_ai_index.role_mappings"} */
[0m17:51:42.702056 [debug] [Thread-1 (]: Using snowflake connection "seed.data_ai_index.database_mappings"
[0m17:51:42.703695 [debug] [Thread-1 (]: On seed.data_ai_index.database_mappings: create table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.database_mappings (keyword text,canonical_name text,category text,era text)
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "seed.data_ai_index.database_mappings"} */
[0m17:51:42.709802 [debug] [Thread-3 (]: Using snowflake connection "seed.data_ai_index.technology_mappings"
[0m17:51:42.711029 [debug] [Thread-3 (]: On seed.data_ai_index.technology_mappings: create table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.technology_mappings (keyword text,canonical_name text,category text,era text)
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "seed.data_ai_index.technology_mappings"} */
[0m17:51:42.969293 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.269 seconds
[0m17:51:42.999292 [debug] [Thread-2 (]: Using snowflake connection "seed.data_ai_index.role_mappings"
[0m17:51:43.000946 [debug] [Thread-2 (]: On seed.data_ai_index.role_mappings: BEGIN
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "seed.data_ai_index.role_mappings"} */
[0m17:51:43.002530 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.289 seconds
[0m17:51:43.014913 [debug] [Thread-3 (]: Using snowflake connection "seed.data_ai_index.technology_mappings"
[0m17:51:43.019120 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.314 seconds
[0m17:51:43.020061 [debug] [Thread-3 (]: On seed.data_ai_index.technology_mappings: BEGIN
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "seed.data_ai_index.technology_mappings"} */
[0m17:51:43.025931 [debug] [Thread-1 (]: Using snowflake connection "seed.data_ai_index.database_mappings"
[0m17:51:43.028192 [debug] [Thread-1 (]: On seed.data_ai_index.database_mappings: BEGIN
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "seed.data_ai_index.database_mappings"} */
[0m17:51:43.151308 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.124 seconds
[0m17:51:43.161017 [debug] [Thread-3 (]: Using snowflake connection "seed.data_ai_index.technology_mappings"
[0m17:51:43.162315 [debug] [Thread-3 (]: On seed.data_ai_index.technology_mappings: insert into DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.technology_mappings (keyword, canonical_name, category, era) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(...
[0m17:51:43.170503 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.141 seconds
[0m17:51:43.173620 [debug] [Thread-1 (]: Using snowflake connection "seed.data_ai_index.database_mappings"
[0m17:51:43.175268 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.173 seconds
[0m17:51:43.176297 [debug] [Thread-1 (]: On seed.data_ai_index.database_mappings: insert into DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.database_mappings (keyword, canonical_name, category, era) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s...
[0m17:51:43.180714 [debug] [Thread-2 (]: Using snowflake connection "seed.data_ai_index.role_mappings"
[0m17:51:43.184730 [debug] [Thread-2 (]: On seed.data_ai_index.role_mappings: insert into DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.role_mappings (keyword, canonical_name, tier) values
            (%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s...
[0m17:51:44.042211 [debug] [Thread-3 (]: SQL status: SUCCESS 175 in 0.879 seconds
[0m17:51:44.043472 [debug] [Thread-3 (]: Using snowflake connection "seed.data_ai_index.technology_mappings"
[0m17:51:44.044422 [debug] [Thread-3 (]: On seed.data_ai_index.technology_mappings: COMMIT
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "seed.data_ai_index.technology_mappings"} */
[0m17:51:44.162721 [debug] [Thread-2 (]: SQL status: SUCCESS 78 in 0.976 seconds
[0m17:51:44.164619 [debug] [Thread-1 (]: SQL status: SUCCESS 53 in 0.982 seconds
[0m17:51:44.167000 [debug] [Thread-2 (]: Using snowflake connection "seed.data_ai_index.role_mappings"
[0m17:51:44.168645 [debug] [Thread-1 (]: Using snowflake connection "seed.data_ai_index.database_mappings"
[0m17:51:44.170072 [debug] [Thread-2 (]: On seed.data_ai_index.role_mappings: COMMIT
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "seed.data_ai_index.role_mappings"} */
[0m17:51:44.171398 [debug] [Thread-1 (]: On seed.data_ai_index.database_mappings: COMMIT
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "seed.data_ai_index.database_mappings"} */
[0m17:51:44.530595 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.485 seconds
[0m17:51:44.549311 [debug] [Thread-3 (]: Writing runtime SQL for node "seed.data_ai_index.technology_mappings"
[0m17:51:44.615067 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a9add7f-ba24-4059-82d7-9701adc024c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117bef250>]}
[0m17:51:44.616718 [info ] [Thread-3 (]: 3 of 3 OK loaded seed file KOUVERK_DATA_INDUSTRY.technology_mappings ........... [[32mINSERT 175[0m in 1.98s]
[0m17:51:44.617723 [debug] [Thread-3 (]: Finished running node seed.data_ai_index.technology_mappings
[0m17:51:44.635078 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.461 seconds
[0m17:51:44.636202 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.data_ai_index.database_mappings"
[0m17:51:44.641742 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a9add7f-ba24-4059-82d7-9701adc024c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11afdbad0>]}
[0m17:51:44.642418 [info ] [Thread-1 (]: 1 of 3 OK loaded seed file KOUVERK_DATA_INDUSTRY.database_mappings ............. [[32mINSERT 53[0m in 2.04s]
[0m17:51:44.643486 [debug] [Thread-1 (]: Finished running node seed.data_ai_index.database_mappings
[0m17:51:44.652619 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.480 seconds
[0m17:51:44.654195 [debug] [Thread-2 (]: Writing runtime SQL for node "seed.data_ai_index.role_mappings"
[0m17:51:44.660769 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a9add7f-ba24-4059-82d7-9701adc024c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11af20de0>]}
[0m17:51:44.662291 [info ] [Thread-2 (]: 2 of 3 OK loaded seed file KOUVERK_DATA_INDUSTRY.role_mappings ................. [[32mINSERT 78[0m in 2.29s]
[0m17:51:44.665199 [debug] [Thread-2 (]: Finished running node seed.data_ai_index.role_mappings
[0m17:51:44.667803 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:51:44.668317 [debug] [MainThread]: Connection 'seed.data_ai_index.database_mappings' was left open.
[0m17:51:44.669104 [debug] [MainThread]: On seed.data_ai_index.database_mappings: Close
[0m17:51:44.829239 [debug] [MainThread]: Connection 'seed.data_ai_index.role_mappings' was left open.
[0m17:51:44.829883 [debug] [MainThread]: On seed.data_ai_index.role_mappings: Close
[0m17:51:44.997751 [debug] [MainThread]: Connection 'seed.data_ai_index.technology_mappings' was left open.
[0m17:51:44.998516 [debug] [MainThread]: On seed.data_ai_index.technology_mappings: Close
[0m17:51:45.169251 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts' was left open.
[0m17:51:45.170683 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts: Close
[0m17:51:45.331417 [info ] [MainThread]: 
[0m17:51:45.332466 [info ] [MainThread]: Finished running 3 seeds in 0 hours 0 minutes and 10.11 seconds (10.11s).
[0m17:51:45.336206 [debug] [MainThread]: Command end result
[0m17:51:45.402306 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/manifest.json
[0m17:51:45.405138 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/semantic_manifest.json
[0m17:51:45.417192 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/run_results.json
[0m17:51:45.417924 [info ] [MainThread]: 
[0m17:51:45.418830 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:51:45.419723 [info ] [MainThread]: 
[0m17:51:45.420821 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m17:51:45.422102 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 1 occurrence
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m17:51:45.430484 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 17.322947, "process_in_blocks": "0", "process_kernel_time": 1.359668, "process_mem_max_rss": "244101120", "process_out_blocks": "0", "process_user_time": 10.40235}
[0m17:51:45.431595 [debug] [MainThread]: Command `dbt seed` succeeded at 17:51:45.431102 after 17.32 seconds
[0m17:51:45.433114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b956750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11baafa70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11baaf770>]}
[0m17:51:45.434263 [debug] [MainThread]: Flushing usage events
[0m17:51:45.746081 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:53:53.289040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131cfa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11497fc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11497fed0>]}


============================== 17:53:53.296646 | 476bcd84-97b8-4ea2-a0e9-b4f503bb4c66 ==============================
[0m17:53:53.296646 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:53:53.297769 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'log_format': 'default', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'introspect': 'True', 'debug': 'False', 'quiet': 'False', 'no_print': 'None', 'version_check': 'True', 'profiles_dir': '.', 'warn_error': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'log_path': '/Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/logs', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'printer_width': '80', 'write_json': 'True', 'invocation_command': 'dbt run --profiles-dir .', 'indirect_selection': 'eager'}
[0m17:53:55.065939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113cc0510>]}
[0m17:53:55.171044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fbfd370>]}
[0m17:53:55.172706 [info ] [MainThread]: Registered adapter: snowflake=1.10.2
[0m17:53:55.383835 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:53:55.658347 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:53:55.658870 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:53:55.745299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fc05150>]}
[0m17:53:55.915168 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/manifest.json
[0m17:53:55.918231 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/semantic_manifest.json
[0m17:53:55.959667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fbe9400>]}
[0m17:53:55.960332 [info ] [MainThread]: Found 18 models, 3 seeds, 49 data tests, 5 sources, 608 macros
[0m17:53:55.960826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120273850>]}
[0m17:53:55.965066 [info ] [MainThread]: 
[0m17:53:55.965830 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:53:55.966601 [info ] [MainThread]: 
[0m17:53:55.967486 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m17:53:55.977925 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT'
[0m17:53:55.981433 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT'
[0m17:53:55.988612 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT'
[0m17:53:56.091407 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT"
[0m17:53:56.092140 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT"
[0m17:53:56.092709 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT"
[0m17:53:56.093128 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT: show terse schemas in database DATAEXPERT_STUDENT
    limit 10000
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT"} */
[0m17:53:56.093542 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT: show terse schemas in database DATAEXPERT_STUDENT
    limit 10000
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT"} */
[0m17:53:56.093917 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT: show terse schemas in database DATAEXPERT_STUDENT
    limit 10000
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT"} */
[0m17:53:56.094275 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:53:56.094624 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:53:56.094936 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:53:59.472660 [debug] [ThreadPool]: SQL status: SUCCESS 423 in 3.378 seconds
[0m17:53:59.492101 [debug] [ThreadPool]: SQL status: SUCCESS 423 in 3.397 seconds
[0m17:54:00.099256 [debug] [ThreadPool]: SQL status: SUCCESS 423 in 4.004 seconds
[0m17:54:00.114534 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT, now create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts)
[0m17:54:00.115143 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT, now create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging)
[0m17:54:00.116666 [debug] [ThreadPool]: Creating schema "database: "DATAEXPERT_STUDENT"
schema: "KOUVERK_DATA_INDUSTRY_marts"
"
[0m17:54:00.117607 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT, now create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate)
[0m17:54:00.118501 [debug] [ThreadPool]: Creating schema "database: "DATAEXPERT_STUDENT"
schema: "KOUVERK_DATA_INDUSTRY_staging"
"
[0m17:54:00.125909 [debug] [ThreadPool]: Using snowflake connection "create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"
[0m17:54:00.126664 [debug] [ThreadPool]: Creating schema "database: "DATAEXPERT_STUDENT"
schema: "KOUVERK_DATA_INDUSTRY_intermediate"
"
[0m17:54:00.129584 [debug] [ThreadPool]: Using snowflake connection "create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"
[0m17:54:00.130388 [debug] [ThreadPool]: On create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts: create schema if not exists DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"} */
[0m17:54:00.132913 [debug] [ThreadPool]: Using snowflake connection "create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"
[0m17:54:00.133477 [debug] [ThreadPool]: On create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging: create schema if not exists DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"} */
[0m17:54:00.134457 [debug] [ThreadPool]: On create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate: create schema if not exists DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"} */
[0m17:54:00.295659 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.162 seconds
[0m17:54:00.338942 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.203 seconds
[0m17:54:00.370246 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.235 seconds
[0m17:54:00.376330 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate'
[0m17:54:00.377366 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging'
[0m17:54:00.384966 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts'
[0m17:54:00.395515 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY'
[0m17:54:00.399705 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"
[0m17:54:00.403958 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"
[0m17:54:00.422449 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY"
[0m17:54:00.424902 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"
[0m17:54:00.425514 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"} */;
[0m17:54:00.426021 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"} */;
[0m17:54:00.426489 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY"} */;
[0m17:54:00.427096 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"} */;
[0m17:54:00.427844 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:54:00.428245 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:54:00.428574 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:54:00.428888 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:54:03.100053 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2.672 seconds
[0m17:54:03.101237 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2.673 seconds
[0m17:54:03.102135 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2.674 seconds
[0m17:54:03.113425 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 2.684 seconds
[0m17:54:03.116648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123e787a0>]}
[0m17:54:03.119892 [debug] [Thread-1 (]: Began running node model.data_ai_index.dim_date
[0m17:54:03.121034 [debug] [Thread-3 (]: Began running node model.data_ai_index.dim_technologies
[0m17:54:03.122341 [debug] [Thread-4 (]: Began running node model.data_ai_index.stg_github__repo_stats
[0m17:54:03.123708 [debug] [Thread-2 (]: Began running node model.data_ai_index.dim_roles
[0m17:54:03.124618 [info ] [Thread-1 (]: 1 of 18 START sql table model KOUVERK_DATA_INDUSTRY_marts.dim_date ............. [RUN]
[0m17:54:03.125751 [info ] [Thread-3 (]: 3 of 18 START sql table model KOUVERK_DATA_INDUSTRY_marts.dim_technologies ..... [RUN]
[0m17:54:03.126528 [info ] [Thread-4 (]: 4 of 18 START sql view model KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats  [RUN]
[0m17:54:03.127417 [info ] [Thread-2 (]: 2 of 18 START sql table model KOUVERK_DATA_INDUSTRY_marts.dim_roles ............ [RUN]
[0m17:54:03.128552 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate, now model.data_ai_index.dim_date)
[0m17:54:03.129548 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts, now model.data_ai_index.dim_technologies)
[0m17:54:03.130718 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY, now model.data_ai_index.stg_github__repo_stats)
[0m17:54:03.131701 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging, now model.data_ai_index.dim_roles)
[0m17:54:03.132406 [debug] [Thread-1 (]: Began compiling node model.data_ai_index.dim_date
[0m17:54:03.132915 [debug] [Thread-3 (]: Began compiling node model.data_ai_index.dim_technologies
[0m17:54:03.133507 [debug] [Thread-4 (]: Began compiling node model.data_ai_index.stg_github__repo_stats
[0m17:54:03.133927 [debug] [Thread-2 (]: Began compiling node model.data_ai_index.dim_roles
[0m17:54:03.177339 [debug] [Thread-4 (]: Writing injected SQL for node "model.data_ai_index.stg_github__repo_stats"
[0m17:54:03.183510 [debug] [Thread-1 (]: Using snowflake connection "model.data_ai_index.dim_date"
[0m17:54:03.205633 [debug] [Thread-3 (]: Writing injected SQL for node "model.data_ai_index.dim_technologies"
[0m17:54:03.208021 [debug] [Thread-2 (]: Writing injected SQL for node "model.data_ai_index.dim_roles"
[0m17:54:03.209050 [debug] [Thread-1 (]: On model.data_ai_index.dim_date: select datediff(
        month,
        cast('2011-01-01' as date),
        cast('2026-12-01' as date)
        )
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.dim_date"} */
[0m17:54:03.212222 [debug] [Thread-2 (]: Began executing node model.data_ai_index.dim_roles
[0m17:54:03.213490 [debug] [Thread-3 (]: Began executing node model.data_ai_index.dim_technologies
[0m17:54:03.243500 [debug] [Thread-4 (]: Began executing node model.data_ai_index.stg_github__repo_stats
[0m17:54:03.342982 [debug] [Thread-3 (]: Writing runtime sql for node "model.data_ai_index.dim_technologies"
[0m17:54:03.349289 [debug] [Thread-2 (]: Writing runtime sql for node "model.data_ai_index.dim_roles"
[0m17:54:03.352598 [debug] [Thread-4 (]: Writing runtime sql for node "model.data_ai_index.stg_github__repo_stats"
[0m17:54:03.355007 [debug] [Thread-3 (]: Using snowflake connection "model.data_ai_index.dim_technologies"
[0m17:54:03.356203 [debug] [Thread-3 (]: On model.data_ai_index.dim_technologies: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_technologies
    
    
    
    as (with tech_mappings as (
    select distinct
        canonical_name as technology_name,
        category,
        era
    from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.technology_mappings
),

db_mappings as (
    select distinct
        canonical_name as technology_name,
        category,
        era
    from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.database_mappings
),

combined as (
    select * from tech_mappings
    union all
    select * from db_mappings
)

select
    md5(cast(coalesce(cast(technology_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as technology_id,
    technology_name,
    category,
    era,
    current_timestamp() as _created_at
from combined
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.dim_technologies"} */;
[0m17:54:03.358997 [debug] [Thread-4 (]: Using snowflake connection "model.data_ai_index.stg_github__repo_stats"
[0m17:54:03.359828 [debug] [Thread-4 (]: On model.data_ai_index.stg_github__repo_stats: create or replace   view DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats
  
  
  
  
  as (
    with source as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.raw_github_repo_stats
),

cleaned as (
    select
        full_name as repo_id,
        repo_name,
        full_name,
        category,
        stars,
        forks,
        open_issues,
        watchers,
        language as primary_language,
        description,
        created_at as repo_created_at,
        updated_at as repo_updated_at,
        pushed_at as last_push_at,
        fetched_at,
        _loaded_at

    from source
)

select * from cleaned
  )
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.stg_github__repo_stats"} */;
[0m17:54:03.361299 [debug] [Thread-2 (]: Using snowflake connection "model.data_ai_index.dim_roles"
[0m17:54:03.362103 [debug] [Thread-2 (]: On model.data_ai_index.dim_roles: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_roles
    
    
    
    as (with role_mappings as (
    select distinct
        canonical_name as role_name,
        tier
    from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.role_mappings
)

select
    md5(cast(coalesce(cast(role_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as role_id,
    role_name,
    tier,
    case tier
        when 1 then 'Core Data Roles'
        when 2 then 'Adjacent Data Roles'
        when 3 then 'AI/ML Specialized'
        when 4 then 'Historical/Legacy'
        when 5 then 'Overlapping Tech'
    end as tier_description,
    current_timestamp() as _created_at
from role_mappings
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.dim_roles"} */;
[0m17:54:03.633785 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.273 seconds
[0m17:54:03.664109 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123e9f590>]}
[0m17:54:03.665331 [info ] [Thread-4 (]: 4 of 18 OK created sql view model KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats  [[32mSUCCESS 1[0m in 0.53s]
[0m17:54:03.666495 [debug] [Thread-4 (]: Finished running node model.data_ai_index.stg_github__repo_stats
[0m17:54:03.667374 [debug] [Thread-4 (]: Began running node model.data_ai_index.stg_hn__job_postings
[0m17:54:03.668355 [info ] [Thread-4 (]: 5 of 18 START sql view model KOUVERK_DATA_INDUSTRY_staging.stg_hn__job_postings  [RUN]
[0m17:54:03.669572 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.data_ai_index.stg_github__repo_stats, now model.data_ai_index.stg_hn__job_postings)
[0m17:54:03.670136 [debug] [Thread-4 (]: Began compiling node model.data_ai_index.stg_hn__job_postings
[0m17:54:03.673369 [debug] [Thread-4 (]: Writing injected SQL for node "model.data_ai_index.stg_hn__job_postings"
[0m17:54:03.674616 [debug] [Thread-4 (]: Began executing node model.data_ai_index.stg_hn__job_postings
[0m17:54:03.680786 [debug] [Thread-4 (]: Writing runtime sql for node "model.data_ai_index.stg_hn__job_postings"
[0m17:54:03.683236 [debug] [Thread-4 (]: Using snowflake connection "model.data_ai_index.stg_hn__job_postings"
[0m17:54:03.683940 [debug] [Thread-4 (]: On model.data_ai_index.stg_hn__job_postings: create or replace   view DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_hn__job_postings
  
  
  
  
  as (
    with source as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.raw_hn_job_postings
),

cleaned as (
    select
        id as posting_id,
        thread_id,
        thread_month,
        author,

        -- Clean HTML from text
        regexp_replace(text, '<[^>]+>', ' ') as posting_text,

        -- Parse month into proper date
        to_date(thread_month, 'MMMM YYYY') as posting_month,
        extract(year from to_date(thread_month, 'MMMM YYYY')) as posting_year,

        posted_at,
        _loaded_at

    from source
    where text is not null
      and trim(text) != ''
)

select * from cleaned
  )
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.stg_hn__job_postings"} */;
[0m17:54:03.985150 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.301 seconds
[0m17:54:03.988582 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123f89b20>]}
[0m17:54:03.989616 [info ] [Thread-4 (]: 5 of 18 OK created sql view model KOUVERK_DATA_INDUSTRY_staging.stg_hn__job_postings  [[32mSUCCESS 1[0m in 0.32s]
[0m17:54:03.990419 [debug] [Thread-4 (]: Finished running node model.data_ai_index.stg_hn__job_postings
[0m17:54:03.991175 [debug] [Thread-4 (]: Began running node model.data_ai_index.stg_linkedin__postings
[0m17:54:03.991963 [info ] [Thread-4 (]: 6 of 18 START sql view model KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__postings  [RUN]
[0m17:54:03.993100 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.data_ai_index.stg_hn__job_postings, now model.data_ai_index.stg_linkedin__postings)
[0m17:54:03.993688 [debug] [Thread-4 (]: Began compiling node model.data_ai_index.stg_linkedin__postings
[0m17:54:03.996942 [debug] [Thread-4 (]: Writing injected SQL for node "model.data_ai_index.stg_linkedin__postings"
[0m17:54:03.998437 [debug] [Thread-4 (]: Began executing node model.data_ai_index.stg_linkedin__postings
[0m17:54:04.002761 [debug] [Thread-4 (]: Writing runtime sql for node "model.data_ai_index.stg_linkedin__postings"
[0m17:54:04.005056 [debug] [Thread-4 (]: Using snowflake connection "model.data_ai_index.stg_linkedin__postings"
[0m17:54:04.005705 [debug] [Thread-4 (]: On model.data_ai_index.stg_linkedin__postings: create or replace   view DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__postings
  
  
  
  
  as (
    with source as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.raw_linkedin_postings
),

cleaned as (
    select
        job_link as posting_id,
        job_title,
        company,
        job_location,

        -- Parse location into components
        split_part(job_location, ',', 1) as city,
        trim(split_part(job_location, ',', 2)) as state_or_country,

        first_seen as posted_at,
        job_level,
        job_type,
        search_city,
        search_country,
        search_position,

        _loaded_at

    from source
    where job_title is not null
)

select * from cleaned
  )
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.stg_linkedin__postings"} */;
[0m17:54:04.038927 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.829 seconds
[0m17:54:04.060195 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_ai_index.dim_date"
[0m17:54:04.061538 [debug] [Thread-1 (]: Began executing node model.data_ai_index.dim_date
[0m17:54:04.065957 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_ai_index.dim_date"
[0m17:54:04.069052 [debug] [Thread-1 (]: Using snowflake connection "model.data_ai_index.dim_date"
[0m17:54:04.069888 [debug] [Thread-1 (]: On model.data_ai_index.dim_date: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_date
    
    
    
    as (

with date_spine as (
    





with rawdata as (

    

    

    with p as (
        select 0 as generated_number union all select 1
    ), unioned as (

    select

    
    p0.generated_number * power(2, 0)
     + 
    
    p1.generated_number * power(2, 1)
     + 
    
    p2.generated_number * power(2, 2)
     + 
    
    p3.generated_number * power(2, 3)
     + 
    
    p4.generated_number * power(2, 4)
     + 
    
    p5.generated_number * power(2, 5)
     + 
    
    p6.generated_number * power(2, 6)
     + 
    
    p7.generated_number * power(2, 7)
    
    
    + 1
    as generated_number

    from

    
    p as p0
     cross join 
    
    p as p1
     cross join 
    
    p as p2
     cross join 
    
    p as p3
     cross join 
    
    p as p4
     cross join 
    
    p as p5
     cross join 
    
    p as p6
     cross join 
    
    p as p7
    
    

    )

    select *
    from unioned
    where generated_number <= 191
    order by generated_number



),

all_periods as (

    select (
        

    dateadd(
        month,
        row_number() over (order by generated_number) - 1,
        cast('2011-01-01' as date)
        )


    ) as date_month
    from rawdata

),

filtered as (

    select *
    from all_periods
    where date_month <= cast('2026-12-01' as date)

)

select * from filtered


),

formatted as (
    select
        date_month as date_key,
        extract(year from date_month) as year,
        extract(month from date_month) as month,
        to_char(date_month, 'MMMM') as month_name,
        to_char(date_month, 'Mon') as month_short,
        to_char(date_month, 'YYYY-MM') as year_month,
        extract(quarter from date_month) as quarter,
        'Q' || extract(quarter from date_month) as quarter_name,
        case
            when extract(year from date_month) < 2015 then 'Hadoop Era'
            when extract(year from date_month) < 2020 then 'Cloud Transition'
            when extract(year from date_month) < 2023 then 'Modern Data Stack'
            else 'AI/LLM Era'
        end as data_era
    from date_spine
)

select * from formatted
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.dim_date"} */;
[0m17:54:04.334786 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.328 seconds
[0m17:54:04.339710 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1241374d0>]}
[0m17:54:04.340971 [info ] [Thread-4 (]: 6 of 18 OK created sql view model KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__postings  [[32mSUCCESS 1[0m in 0.35s]
[0m17:54:04.342055 [debug] [Thread-4 (]: Finished running node model.data_ai_index.stg_linkedin__postings
[0m17:54:04.342929 [debug] [Thread-4 (]: Began running node model.data_ai_index.stg_linkedin__skills
[0m17:54:04.343708 [info ] [Thread-4 (]: 7 of 18 START sql view model KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__skills  [RUN]
[0m17:54:04.344735 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.data_ai_index.stg_linkedin__postings, now model.data_ai_index.stg_linkedin__skills)
[0m17:54:04.345569 [debug] [Thread-4 (]: Began compiling node model.data_ai_index.stg_linkedin__skills
[0m17:54:04.349333 [debug] [Thread-4 (]: Writing injected SQL for node "model.data_ai_index.stg_linkedin__skills"
[0m17:54:04.350336 [debug] [Thread-4 (]: Began executing node model.data_ai_index.stg_linkedin__skills
[0m17:54:04.354932 [debug] [Thread-4 (]: Writing runtime sql for node "model.data_ai_index.stg_linkedin__skills"
[0m17:54:04.357073 [debug] [Thread-4 (]: Using snowflake connection "model.data_ai_index.stg_linkedin__skills"
[0m17:54:04.357960 [debug] [Thread-4 (]: On model.data_ai_index.stg_linkedin__skills: create or replace   view DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__skills
  
  
  
  
  as (
    with source as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.raw_linkedin_skills
),

-- Split comma-separated skills into individual rows
exploded as (
    select
        job_link as posting_id,
        trim(s.value::string) as skill_name,
        _loaded_at
    from source,
    lateral flatten(input => split(job_skills, ',')) as s
    where job_skills is not null
      and trim(job_skills) != ''
)

select * from exploded
where skill_name is not null
  and skill_name != ''
  )
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.stg_linkedin__skills"} */;
[0m17:54:04.498539 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 1.141 seconds
[0m17:54:04.505543 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1207af0d0>]}
[0m17:54:04.508248 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1.145 seconds
[0m17:54:04.514125 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1240fe890>]}
[0m17:54:04.509615 [info ] [Thread-3 (]: 3 of 18 OK created sql table model KOUVERK_DATA_INDUSTRY_marts.dim_technologies  [[32mSUCCESS 1[0m in 1.38s]
[0m17:54:04.515238 [info ] [Thread-2 (]: 2 of 18 OK created sql table model KOUVERK_DATA_INDUSTRY_marts.dim_roles ....... [[32mSUCCESS 1[0m in 1.38s]
[0m17:54:04.516282 [debug] [Thread-3 (]: Finished running node model.data_ai_index.dim_technologies
[0m17:54:04.517234 [debug] [Thread-2 (]: Finished running node model.data_ai_index.dim_roles
[0m17:54:04.517875 [debug] [Thread-3 (]: Began running node model.data_ai_index.stg_linkedin__summaries
[0m17:54:04.518827 [debug] [Thread-2 (]: Began running node model.data_ai_index.fct_github_repo_stats
[0m17:54:04.521056 [info ] [Thread-3 (]: 8 of 18 START sql view model KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__summaries  [RUN]
[0m17:54:04.522158 [info ] [Thread-2 (]: 9 of 18 START sql table model KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats  [RUN]
[0m17:54:04.523167 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.data_ai_index.dim_technologies, now model.data_ai_index.stg_linkedin__summaries)
[0m17:54:04.524176 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.data_ai_index.dim_roles, now model.data_ai_index.fct_github_repo_stats)
[0m17:54:04.525490 [debug] [Thread-3 (]: Began compiling node model.data_ai_index.stg_linkedin__summaries
[0m17:54:04.526527 [debug] [Thread-2 (]: Began compiling node model.data_ai_index.fct_github_repo_stats
[0m17:54:04.533205 [debug] [Thread-3 (]: Writing injected SQL for node "model.data_ai_index.stg_linkedin__summaries"
[0m17:54:04.540030 [debug] [Thread-2 (]: Writing injected SQL for node "model.data_ai_index.fct_github_repo_stats"
[0m17:54:04.541763 [debug] [Thread-2 (]: Began executing node model.data_ai_index.fct_github_repo_stats
[0m17:54:04.543180 [debug] [Thread-3 (]: Began executing node model.data_ai_index.stg_linkedin__summaries
[0m17:54:04.550927 [debug] [Thread-2 (]: Writing runtime sql for node "model.data_ai_index.fct_github_repo_stats"
[0m17:54:04.557954 [debug] [Thread-3 (]: Writing runtime sql for node "model.data_ai_index.stg_linkedin__summaries"
[0m17:54:04.560644 [debug] [Thread-2 (]: Using snowflake connection "model.data_ai_index.fct_github_repo_stats"
[0m17:54:04.561367 [debug] [Thread-2 (]: On model.data_ai_index.fct_github_repo_stats: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats
    
    
    
    as (with repo_stats as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats
)

select
    repo_id,
    repo_name,
    full_name,
    category,
    primary_language,
    description,
    stars,
    forks,
    open_issues,
    watchers,
    repo_created_at,
    last_push_at,
    fetched_at,
    -- Derived metrics
    round(forks * 1.0 / nullif(stars, 0), 4) as fork_to_star_ratio,
    round(open_issues * 1.0 / nullif(stars, 0), 6) as issues_per_star,
    datediff('day', repo_created_at, fetched_at) as days_since_creation,
    datediff('day', last_push_at, fetched_at) as days_since_last_push,
    -- Activity classification
    case
        when datediff('day', last_push_at, fetched_at) <= 7 then 'Very Active'
        when datediff('day', last_push_at, fetched_at) <= 30 then 'Active'
        when datediff('day', last_push_at, fetched_at) <= 90 then 'Moderate'
        else 'Low Activity'
    end as activity_level
from repo_stats
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.fct_github_repo_stats"} */;
[0m17:54:04.563898 [debug] [Thread-3 (]: Using snowflake connection "model.data_ai_index.stg_linkedin__summaries"
[0m17:54:04.564594 [debug] [Thread-3 (]: On model.data_ai_index.stg_linkedin__summaries: create or replace   view DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__summaries
  
  
  
  
  as (
    with source as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.raw_linkedin_summaries
),

cleaned as (
    select
        job_link as posting_id,
        job_summary as description_text,
        _loaded_at
    from source
    where job_summary is not null
      and trim(job_summary) != ''
)

select * from cleaned
  )
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.stg_linkedin__summaries"} */;
[0m17:54:04.628247 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.270 seconds
[0m17:54:04.631529 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1240cab70>]}
[0m17:54:04.632307 [info ] [Thread-4 (]: 7 of 18 OK created sql view model KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__skills  [[32mSUCCESS 1[0m in 0.29s]
[0m17:54:04.632963 [debug] [Thread-4 (]: Finished running node model.data_ai_index.stg_linkedin__skills
[0m17:54:04.633399 [debug] [Thread-4 (]: Began running node model.data_ai_index.int_hn__databases_extracted
[0m17:54:04.633885 [info ] [Thread-4 (]: 10 of 18 START sql table model KOUVERK_DATA_INDUSTRY_intermediate.int_hn__databases_extracted  [RUN]
[0m17:54:04.634429 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.data_ai_index.stg_linkedin__skills, now model.data_ai_index.int_hn__databases_extracted)
[0m17:54:04.634826 [debug] [Thread-4 (]: Began compiling node model.data_ai_index.int_hn__databases_extracted
[0m17:54:04.638492 [debug] [Thread-4 (]: Writing injected SQL for node "model.data_ai_index.int_hn__databases_extracted"
[0m17:54:04.639663 [debug] [Thread-4 (]: Began executing node model.data_ai_index.int_hn__databases_extracted
[0m17:54:04.643494 [debug] [Thread-4 (]: Writing runtime sql for node "model.data_ai_index.int_hn__databases_extracted"
[0m17:54:04.645326 [debug] [Thread-4 (]: Using snowflake connection "model.data_ai_index.int_hn__databases_extracted"
[0m17:54:04.645906 [debug] [Thread-4 (]: On model.data_ai_index.int_hn__databases_extracted: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_hn__databases_extracted
    
    
    
    as (

with postings as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_hn__job_postings
),

db_mappings as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.database_mappings
),

-- Cross join postings with database mappings and check for matches
matched as (
    select
        p.posting_id,
        p.posting_month,
        p.posting_year,
        d.canonical_name as database_name,
        d.category,
        d.era
    from postings p
    cross join db_mappings d
    where regexp_like(lower(p.posting_text), '\\b' || lower(d.keyword) || '\\b')
)

select distinct
    posting_id,
    posting_month,
    posting_year,
    database_name,
    category,
    era
from matched
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.int_hn__databases_extracted"} */;
[0m17:54:04.880424 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.314 seconds
[0m17:54:04.884835 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f36390>]}
[0m17:54:04.886043 [info ] [Thread-3 (]: 8 of 18 OK created sql view model KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__summaries  [[32mSUCCESS 1[0m in 0.36s]
[0m17:54:04.887482 [debug] [Thread-3 (]: Finished running node model.data_ai_index.stg_linkedin__summaries
[0m17:54:04.888411 [debug] [Thread-3 (]: Began running node model.data_ai_index.int_hn__roles_extracted
[0m17:54:04.889263 [info ] [Thread-3 (]: 11 of 18 START sql table model KOUVERK_DATA_INDUSTRY_intermediate.int_hn__roles_extracted  [RUN]
[0m17:54:04.890171 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.data_ai_index.stg_linkedin__summaries, now model.data_ai_index.int_hn__roles_extracted)
[0m17:54:04.890947 [debug] [Thread-3 (]: Began compiling node model.data_ai_index.int_hn__roles_extracted
[0m17:54:04.896206 [debug] [Thread-3 (]: Writing injected SQL for node "model.data_ai_index.int_hn__roles_extracted"
[0m17:54:04.897578 [debug] [Thread-3 (]: Began executing node model.data_ai_index.int_hn__roles_extracted
[0m17:54:04.901021 [debug] [Thread-3 (]: Writing runtime sql for node "model.data_ai_index.int_hn__roles_extracted"
[0m17:54:04.903268 [debug] [Thread-3 (]: Using snowflake connection "model.data_ai_index.int_hn__roles_extracted"
[0m17:54:04.903990 [debug] [Thread-3 (]: On model.data_ai_index.int_hn__roles_extracted: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_hn__roles_extracted
    
    
    
    as (

with postings as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_hn__job_postings
),

role_mappings as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.role_mappings
),

-- Cross join postings with role mappings and check for matches
matched as (
    select
        p.posting_id,
        p.posting_month,
        p.posting_year,
        r.canonical_name as role,
        r.tier
    from postings p
    cross join role_mappings r
    where regexp_like(lower(p.posting_text), '\\b' || lower(r.keyword) || '\\b')
)

select distinct
    posting_id,
    posting_month,
    posting_year,
    role,
    tier
from matched
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.int_hn__roles_extracted"} */;
[0m17:54:04.918297 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.848 seconds
[0m17:54:04.921600 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f35c10>]}
[0m17:54:04.922688 [info ] [Thread-1 (]: 1 of 18 OK created sql table model KOUVERK_DATA_INDUSTRY_marts.dim_date ........ [[32mSUCCESS 1[0m in 1.79s]
[0m17:54:04.923608 [debug] [Thread-1 (]: Finished running node model.data_ai_index.dim_date
[0m17:54:04.924330 [debug] [Thread-1 (]: Began running node model.data_ai_index.int_hn__technologies_extracted
[0m17:54:04.925341 [info ] [Thread-1 (]: 12 of 18 START sql table model KOUVERK_DATA_INDUSTRY_intermediate.int_hn__technologies_extracted  [RUN]
[0m17:54:04.926406 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_ai_index.dim_date, now model.data_ai_index.int_hn__technologies_extracted)
[0m17:54:04.927672 [debug] [Thread-1 (]: Began compiling node model.data_ai_index.int_hn__technologies_extracted
[0m17:54:04.932737 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_ai_index.int_hn__technologies_extracted"
[0m17:54:04.935067 [debug] [Thread-1 (]: Began executing node model.data_ai_index.int_hn__technologies_extracted
[0m17:54:04.938894 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_ai_index.int_hn__technologies_extracted"
[0m17:54:04.940922 [debug] [Thread-1 (]: Using snowflake connection "model.data_ai_index.int_hn__technologies_extracted"
[0m17:54:04.941564 [debug] [Thread-1 (]: On model.data_ai_index.int_hn__technologies_extracted: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_hn__technologies_extracted
    
    
    
    as (

with postings as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_hn__job_postings
),

tech_mappings as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.technology_mappings
),

-- Cross join postings with tech mappings and check for matches
matched as (
    select
        p.posting_id,
        p.posting_month,
        p.posting_year,
        t.canonical_name as technology,
        t.category,
        t.era
    from postings p
    cross join tech_mappings t
    where regexp_like(lower(p.posting_text), '\\b' || lower(t.keyword) || '\\b')
)

select distinct
    posting_id,
    posting_month,
    posting_year,
    technology,
    category,
    era
from matched
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.int_hn__technologies_extracted"} */;
[0m17:54:05.395224 [debug] [Thread-2 (]: Snowflake adapter: Snowflake query id: 01c1de76-0107-8ae8-0000-33eb03353486
[0m17:54:05.395967 [debug] [Thread-2 (]: Snowflake adapter: Snowflake error: 100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
[0m17:54:05.405962 [debug] [Thread-2 (]: Database Error in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)
  100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
  compiled code at target/run/data_ai_index/models/marts/fct_github_repo_stats.sql
[0m17:54:05.407068 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1241ab6b0>]}
[0m17:54:05.407929 [error] [Thread-2 (]: 9 of 18 ERROR creating sql table model KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats  [[31mERROR[0m in 0.88s]
[0m17:54:05.408715 [debug] [Thread-2 (]: Finished running node model.data_ai_index.fct_github_repo_stats
[0m17:54:05.409282 [debug] [Thread-2 (]: Began running node model.data_ai_index.int_linkedin__skills_standardized
[0m17:54:05.409853 [info ] [Thread-2 (]: 13 of 18 START sql table model KOUVERK_DATA_INDUSTRY_intermediate.int_linkedin__skills_standardized  [RUN]
[0m17:54:05.410376 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.data_ai_index.fct_github_repo_stats, now model.data_ai_index.int_linkedin__skills_standardized)
[0m17:54:05.410813 [debug] [Thread-2 (]: Began compiling node model.data_ai_index.int_linkedin__skills_standardized
[0m17:54:05.414732 [debug] [Thread-2 (]: Writing injected SQL for node "model.data_ai_index.int_linkedin__skills_standardized"
[0m17:54:05.415472 [debug] [Thread-7 (]: Marking all children of 'model.data_ai_index.fct_github_repo_stats' to be skipped because of status 'error'.  Reason: Database Error in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)
  100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
  compiled code at target/run/data_ai_index/models/marts/fct_github_repo_stats.sql.
[0m17:54:05.417289 [debug] [Thread-2 (]: Began executing node model.data_ai_index.int_linkedin__skills_standardized
[0m17:54:05.422532 [debug] [Thread-2 (]: Writing runtime sql for node "model.data_ai_index.int_linkedin__skills_standardized"
[0m17:54:05.424755 [debug] [Thread-2 (]: Using snowflake connection "model.data_ai_index.int_linkedin__skills_standardized"
[0m17:54:05.425425 [debug] [Thread-2 (]: On model.data_ai_index.int_linkedin__skills_standardized: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_linkedin__skills_standardized
    
    
    
    as (

with skills as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__skills
),

tech_mappings as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.technology_mappings
),

-- Try to match LinkedIn skills to our technology taxonomy
matched as (
    select
        s.posting_id,
        s.skill_name as original_skill,
        t.canonical_name as technology,
        t.category,
        t.era
    from skills s
    left join tech_mappings t
        on lower(s.skill_name) = lower(t.keyword)
)

select
    posting_id,
    original_skill,
    coalesce(technology, original_skill) as skill_name,
    coalesce(category, 'other') as category,
    coalesce(era, 'unknown') as era,
    case when technology is not null then true else false end as is_standardized
from matched
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.int_linkedin__skills_standardized"} */;
[0m17:54:07.117933 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 2.472 seconds
[0m17:54:07.120773 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123f53b90>]}
[0m17:54:07.121520 [info ] [Thread-4 (]: 10 of 18 OK created sql table model KOUVERK_DATA_INDUSTRY_intermediate.int_hn__databases_extracted  [[32mSUCCESS 1[0m in 2.49s]
[0m17:54:07.122630 [debug] [Thread-4 (]: Finished running node model.data_ai_index.int_hn__databases_extracted
[0m17:54:07.419536 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 2.515 seconds
[0m17:54:07.423318 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123f51df0>]}
[0m17:54:07.424324 [info ] [Thread-3 (]: 11 of 18 OK created sql table model KOUVERK_DATA_INDUSTRY_intermediate.int_hn__roles_extracted  [[32mSUCCESS 1[0m in 2.53s]
[0m17:54:07.425429 [debug] [Thread-3 (]: Finished running node model.data_ai_index.int_hn__roles_extracted
[0m17:54:07.426271 [debug] [Thread-4 (]: Began running node model.data_ai_index.fct_hn_role_mentions
[0m17:54:07.426968 [info ] [Thread-4 (]: 14 of 18 START sql table model KOUVERK_DATA_INDUSTRY_marts.fct_hn_role_mentions  [RUN]
[0m17:54:07.427625 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.data_ai_index.int_hn__databases_extracted, now model.data_ai_index.fct_hn_role_mentions)
[0m17:54:07.428474 [debug] [Thread-4 (]: Began compiling node model.data_ai_index.fct_hn_role_mentions
[0m17:54:07.435360 [debug] [Thread-4 (]: Writing injected SQL for node "model.data_ai_index.fct_hn_role_mentions"
[0m17:54:07.436518 [debug] [Thread-4 (]: Began executing node model.data_ai_index.fct_hn_role_mentions
[0m17:54:07.441216 [debug] [Thread-4 (]: Writing runtime sql for node "model.data_ai_index.fct_hn_role_mentions"
[0m17:54:07.443005 [debug] [Thread-4 (]: Using snowflake connection "model.data_ai_index.fct_hn_role_mentions"
[0m17:54:07.443595 [debug] [Thread-4 (]: On model.data_ai_index.fct_hn_role_mentions: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_hn_role_mentions
    
    
    
    as (with role_extracted as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_hn__roles_extracted
),

dim_roles as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_roles
)

select
    md5(cast(coalesce(cast(r.posting_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(r.role as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as mention_id,
    r.posting_id,
    dr.role_id,
    r.role as role_name,
    r.tier,
    r.posting_month,
    r.posting_year
from role_extracted r
left join dim_roles dr on r.role = dr.role_name
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.fct_hn_role_mentions"} */;
[0m17:54:07.830406 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2.888 seconds
[0m17:54:07.833396 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123db8a70>]}
[0m17:54:07.835265 [info ] [Thread-1 (]: 12 of 18 OK created sql table model KOUVERK_DATA_INDUSTRY_intermediate.int_hn__technologies_extracted  [[32mSUCCESS 1[0m in 2.91s]
[0m17:54:07.836723 [debug] [Thread-1 (]: Finished running node model.data_ai_index.int_hn__technologies_extracted
[0m17:54:07.838218 [debug] [Thread-3 (]: Began running node model.data_ai_index.fct_hn_technology_mentions
[0m17:54:07.838881 [info ] [Thread-3 (]: 15 of 18 START sql table model KOUVERK_DATA_INDUSTRY_marts.fct_hn_technology_mentions  [RUN]
[0m17:54:07.839535 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.data_ai_index.int_hn__roles_extracted, now model.data_ai_index.fct_hn_technology_mentions)
[0m17:54:07.839954 [debug] [Thread-3 (]: Began compiling node model.data_ai_index.fct_hn_technology_mentions
[0m17:54:07.846299 [debug] [Thread-3 (]: Writing injected SQL for node "model.data_ai_index.fct_hn_technology_mentions"
[0m17:54:07.847585 [debug] [Thread-3 (]: Began executing node model.data_ai_index.fct_hn_technology_mentions
[0m17:54:07.852426 [debug] [Thread-3 (]: Writing runtime sql for node "model.data_ai_index.fct_hn_technology_mentions"
[0m17:54:07.856266 [debug] [Thread-3 (]: Using snowflake connection "model.data_ai_index.fct_hn_technology_mentions"
[0m17:54:07.856920 [debug] [Thread-3 (]: On model.data_ai_index.fct_hn_technology_mentions: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_hn_technology_mentions
    
    
    
    as (with tech_extracted as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_hn__technologies_extracted
),

db_extracted as (
    select
        posting_id,
        posting_month,
        posting_year,
        database_name as technology,
        category,
        era
    from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_hn__databases_extracted
),

combined as (
    select * from tech_extracted
    union all
    select * from db_extracted
),

dim_tech as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_technologies
)

select
    md5(cast(coalesce(cast(c.posting_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(c.technology as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as mention_id,
    c.posting_id,
    dt.technology_id,
    c.technology as technology_name,
    c.category,
    c.era,
    c.posting_month,
    c.posting_year
from combined c
left join dim_tech dt on c.technology = dt.technology_name
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.fct_hn_technology_mentions"} */;
[0m17:54:08.185592 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.741 seconds
[0m17:54:08.189747 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123f53d10>]}
[0m17:54:08.190849 [info ] [Thread-4 (]: 14 of 18 OK created sql table model KOUVERK_DATA_INDUSTRY_marts.fct_hn_role_mentions  [[32mSUCCESS 1[0m in 0.76s]
[0m17:54:08.191824 [debug] [Thread-4 (]: Finished running node model.data_ai_index.fct_hn_role_mentions
[0m17:54:08.192579 [debug] [Thread-1 (]: Began running node model.data_ai_index.fct_monthly_role_trends
[0m17:54:08.193262 [info ] [Thread-1 (]: 16 of 18 START sql table model KOUVERK_DATA_INDUSTRY_marts.fct_monthly_role_trends  [RUN]
[0m17:54:08.193895 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_ai_index.int_hn__technologies_extracted, now model.data_ai_index.fct_monthly_role_trends)
[0m17:54:08.194444 [debug] [Thread-1 (]: Began compiling node model.data_ai_index.fct_monthly_role_trends
[0m17:54:08.199391 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_ai_index.fct_monthly_role_trends"
[0m17:54:08.200450 [debug] [Thread-1 (]: Began executing node model.data_ai_index.fct_monthly_role_trends
[0m17:54:08.204668 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_ai_index.fct_monthly_role_trends"
[0m17:54:08.206712 [debug] [Thread-1 (]: Using snowflake connection "model.data_ai_index.fct_monthly_role_trends"
[0m17:54:08.207235 [debug] [Thread-1 (]: On model.data_ai_index.fct_monthly_role_trends: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_monthly_role_trends
    
    
    
    as (with mentions as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_hn_role_mentions
),

postings as (
    select
        posting_month,
        count(distinct posting_id) as total_postings
    from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_hn__job_postings
    group by 1
),

monthly_counts as (
    select
        posting_month,
        role_name,
        tier,
        count(distinct posting_id) as mention_count
    from mentions
    group by 1, 2, 3
)

select
    mc.posting_month,
    mc.role_name,
    mc.tier,
    mc.mention_count,
    p.total_postings,
    round(mc.mention_count * 100.0 / nullif(p.total_postings, 0), 2) as mention_pct,
    -- Year-over-year comparison
    lag(mc.mention_count, 12) over (
        partition by mc.role_name
        order by mc.posting_month
    ) as mentions_prev_year,
    -- Month-over-month change
    lag(mc.mention_count, 1) over (
        partition by mc.role_name
        order by mc.posting_month
    ) as mentions_prev_month
from monthly_counts mc
join postings p on mc.posting_month = p.posting_month
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.fct_monthly_role_trends"} */;
[0m17:54:08.797945 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.940 seconds
[0m17:54:08.802257 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123f53590>]}
[0m17:54:08.803333 [info ] [Thread-3 (]: 15 of 18 OK created sql table model KOUVERK_DATA_INDUSTRY_marts.fct_hn_technology_mentions  [[32mSUCCESS 1[0m in 0.96s]
[0m17:54:08.804226 [debug] [Thread-3 (]: Finished running node model.data_ai_index.fct_hn_technology_mentions
[0m17:54:08.805005 [debug] [Thread-4 (]: Began running node model.data_ai_index.fct_monthly_technology_trends
[0m17:54:08.805691 [info ] [Thread-4 (]: 17 of 18 START sql table model KOUVERK_DATA_INDUSTRY_marts.fct_monthly_technology_trends  [RUN]
[0m17:54:08.806327 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.data_ai_index.fct_hn_role_mentions, now model.data_ai_index.fct_monthly_technology_trends)
[0m17:54:08.806895 [debug] [Thread-4 (]: Began compiling node model.data_ai_index.fct_monthly_technology_trends
[0m17:54:08.811317 [debug] [Thread-4 (]: Writing injected SQL for node "model.data_ai_index.fct_monthly_technology_trends"
[0m17:54:08.812322 [debug] [Thread-4 (]: Began executing node model.data_ai_index.fct_monthly_technology_trends
[0m17:54:08.816615 [debug] [Thread-4 (]: Writing runtime sql for node "model.data_ai_index.fct_monthly_technology_trends"
[0m17:54:08.818753 [debug] [Thread-4 (]: Using snowflake connection "model.data_ai_index.fct_monthly_technology_trends"
[0m17:54:08.819261 [debug] [Thread-4 (]: On model.data_ai_index.fct_monthly_technology_trends: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_monthly_technology_trends
    
    
    
    as (with mentions as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_hn_technology_mentions
),

postings as (
    select
        posting_month,
        count(distinct posting_id) as total_postings
    from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_hn__job_postings
    group by 1
),

monthly_counts as (
    select
        posting_month,
        technology_name,
        category,
        era,
        count(distinct posting_id) as mention_count
    from mentions
    group by 1, 2, 3, 4
)

select
    mc.posting_month,
    mc.technology_name,
    mc.category,
    mc.era,
    mc.mention_count,
    p.total_postings,
    round(mc.mention_count * 100.0 / nullif(p.total_postings, 0), 2) as mention_pct,
    -- Year-over-year comparison
    lag(mc.mention_count, 12) over (
        partition by mc.technology_name
        order by mc.posting_month
    ) as mentions_prev_year,
    -- Month-over-month change
    lag(mc.mention_count, 1) over (
        partition by mc.technology_name
        order by mc.posting_month
    ) as mentions_prev_month
from monthly_counts mc
join postings p on mc.posting_month = p.posting_month
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.fct_monthly_technology_trends"} */;
[0m17:54:09.090856 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.883 seconds
[0m17:54:09.093682 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f37710>]}
[0m17:54:09.094711 [info ] [Thread-1 (]: 16 of 18 OK created sql table model KOUVERK_DATA_INDUSTRY_marts.fct_monthly_role_trends  [[32mSUCCESS 1[0m in 0.90s]
[0m17:54:09.095654 [debug] [Thread-1 (]: Finished running node model.data_ai_index.fct_monthly_role_trends
[0m17:54:09.710665 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.891 seconds
[0m17:54:09.716738 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12418c1d0>]}
[0m17:54:09.718252 [info ] [Thread-4 (]: 17 of 18 OK created sql table model KOUVERK_DATA_INDUSTRY_marts.fct_monthly_technology_trends  [[32mSUCCESS 1[0m in 0.91s]
[0m17:54:09.719583 [debug] [Thread-4 (]: Finished running node model.data_ai_index.fct_monthly_technology_trends
[0m17:54:25.183255 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 19.757 seconds
[0m17:54:25.186123 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1241d6750>]}
[0m17:54:25.186895 [info ] [Thread-2 (]: 13 of 18 OK created sql table model KOUVERK_DATA_INDUSTRY_intermediate.int_linkedin__skills_standardized  [[32mSUCCESS 1[0m in 19.78s]
[0m17:54:25.187804 [debug] [Thread-2 (]: Finished running node model.data_ai_index.int_linkedin__skills_standardized
[0m17:54:25.189140 [debug] [Thread-3 (]: Began running node model.data_ai_index.fct_linkedin_skill_counts
[0m17:54:25.190281 [info ] [Thread-3 (]: 18 of 18 START sql table model KOUVERK_DATA_INDUSTRY_marts.fct_linkedin_skill_counts  [RUN]
[0m17:54:25.190956 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.data_ai_index.fct_hn_technology_mentions, now model.data_ai_index.fct_linkedin_skill_counts)
[0m17:54:25.191546 [debug] [Thread-3 (]: Began compiling node model.data_ai_index.fct_linkedin_skill_counts
[0m17:54:25.195708 [debug] [Thread-3 (]: Writing injected SQL for node "model.data_ai_index.fct_linkedin_skill_counts"
[0m17:54:25.197419 [debug] [Thread-3 (]: Began executing node model.data_ai_index.fct_linkedin_skill_counts
[0m17:54:25.206006 [debug] [Thread-3 (]: Writing runtime sql for node "model.data_ai_index.fct_linkedin_skill_counts"
[0m17:54:25.207918 [debug] [Thread-3 (]: Using snowflake connection "model.data_ai_index.fct_linkedin_skill_counts"
[0m17:54:25.208517 [debug] [Thread-3 (]: On model.data_ai_index.fct_linkedin_skill_counts: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_linkedin_skill_counts
    
    
    
    as (with skills as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_linkedin__skills_standardized
),

postings as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__postings
)

select
    s.skill_name,
    s.category,
    s.era,
    s.is_standardized,
    count(distinct s.posting_id) as job_count,
    count(distinct s.posting_id) * 100.0 / (select count(distinct posting_id) from postings) as pct_of_jobs
from skills s
group by 1, 2, 3, 4
order by job_count desc
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.fct_linkedin_skill_counts"} */;
[0m17:54:33.830727 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 8.622 seconds
[0m17:54:33.834826 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '476bcd84-97b8-4ea2-a0e9-b4f503bb4c66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123e69d90>]}
[0m17:54:33.836169 [info ] [Thread-3 (]: 18 of 18 OK created sql table model KOUVERK_DATA_INDUSTRY_marts.fct_linkedin_skill_counts  [[32mSUCCESS 1[0m in 8.64s]
[0m17:54:33.837799 [debug] [Thread-3 (]: Finished running node model.data_ai_index.fct_linkedin_skill_counts
[0m17:54:33.840033 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:54:33.840723 [debug] [MainThread]: Connection 'create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging' was left open.
[0m17:54:33.841227 [debug] [MainThread]: On create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging: Close
[0m17:54:33.997569 [debug] [MainThread]: Connection 'create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts' was left open.
[0m17:54:33.999080 [debug] [MainThread]: On create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts: Close
[0m17:54:34.213836 [debug] [MainThread]: Connection 'create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate' was left open.
[0m17:54:34.214601 [debug] [MainThread]: On create_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate: Close
[0m17:54:34.372755 [debug] [MainThread]: Connection 'model.data_ai_index.fct_monthly_role_trends' was left open.
[0m17:54:34.373335 [debug] [MainThread]: On model.data_ai_index.fct_monthly_role_trends: Close
[0m17:54:34.521910 [debug] [MainThread]: Connection 'model.data_ai_index.int_linkedin__skills_standardized' was left open.
[0m17:54:34.522556 [debug] [MainThread]: On model.data_ai_index.int_linkedin__skills_standardized: Close
[0m17:54:34.698257 [debug] [MainThread]: Connection 'model.data_ai_index.fct_linkedin_skill_counts' was left open.
[0m17:54:34.699430 [debug] [MainThread]: On model.data_ai_index.fct_linkedin_skill_counts: Close
[0m17:54:34.872666 [debug] [MainThread]: Connection 'model.data_ai_index.fct_monthly_technology_trends' was left open.
[0m17:54:34.873423 [debug] [MainThread]: On model.data_ai_index.fct_monthly_technology_trends: Close
[0m17:54:35.042640 [info ] [MainThread]: 
[0m17:54:35.043677 [info ] [MainThread]: Finished running 13 table models, 5 view models in 0 hours 0 minutes and 39.08 seconds (39.08s).
[0m17:54:35.051608 [debug] [MainThread]: Command end result
[0m17:54:35.101085 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/manifest.json
[0m17:54:35.103327 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/semantic_manifest.json
[0m17:54:35.111232 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/run_results.json
[0m17:54:35.111756 [info ] [MainThread]: 
[0m17:54:35.112188 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m17:54:35.112625 [info ] [MainThread]: 
[0m17:54:35.113169 [error] [MainThread]: [31mFailure in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)[0m
[0m17:54:35.113587 [error] [MainThread]:   Database Error in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)
  100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
  compiled code at target/run/data_ai_index/models/marts/fct_github_repo_stats.sql
[0m17:54:35.113946 [info ] [MainThread]: 
[0m17:54:35.114329 [info ] [MainThread]:   compiled code at target/compiled/data_ai_index/models/marts/fct_github_repo_stats.sql
[0m17:54:35.114820 [info ] [MainThread]: 
[0m17:54:35.115458 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=18
[0m17:54:35.119738 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 41.955036, "process_in_blocks": "0", "process_kernel_time": 1.334507, "process_mem_max_rss": "239284224", "process_out_blocks": "0", "process_user_time": 7.676059}
[0m17:54:35.120546 [debug] [MainThread]: Command `dbt run` failed at 17:54:35.120392 after 41.96 seconds
[0m17:54:35.121029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112095af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1241ebcb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1241eba70>]}
[0m17:54:35.121504 [debug] [MainThread]: Flushing usage events
[0m17:54:35.469985 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:59:34.530831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd27a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f4d7c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f4d7ed0>]}


============================== 17:59:34.537270 | f21d0212-2f98-4fb8-bf9d-97cc6d36f8ac ==============================
[0m17:59:34.537270 [info ] [MainThread]: Running with dbt=1.10.13
[0m17:59:34.538608 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'invocation_command': 'dbt run --select fct_github_repo_stats --profiles-dir .', 'partial_parse': 'True', 'quiet': 'False', 'printer_width': '80', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'profiles_dir': '.', 'cache_selected_only': 'False', 'warn_error': 'None', 'empty': 'False', 'fail_fast': 'False', 'version_check': 'True', 'log_format': 'default', 'use_colors': 'True', 'log_path': '/Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'log_cache_events': 'False', 'no_print': 'None', 'indirect_selection': 'eager', 'introspect': 'True', 'static_parser': 'True'}
[0m17:59:36.052571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f21d0212-2f98-4fb8-bf9d-97cc6d36f8ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e81c510>]}
[0m17:59:36.150523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f21d0212-2f98-4fb8-bf9d-97cc6d36f8ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a7a9370>]}
[0m17:59:36.151514 [info ] [MainThread]: Registered adapter: snowflake=1.10.2
[0m17:59:36.333216 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m17:59:36.556911 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:59:36.557884 [debug] [MainThread]: Partial parsing: updated file: data_ai_index://models/marts/fct_github_repo_stats.sql
[0m17:59:37.273802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f21d0212-2f98-4fb8-bf9d-97cc6d36f8ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a7bdd50>]}
[0m17:59:37.437248 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/manifest.json
[0m17:59:37.440457 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/semantic_manifest.json
[0m17:59:37.470556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f21d0212-2f98-4fb8-bf9d-97cc6d36f8ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a79d400>]}
[0m17:59:37.471291 [info ] [MainThread]: Found 18 models, 3 seeds, 49 data tests, 5 sources, 608 macros
[0m17:59:37.471827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f21d0212-2f98-4fb8-bf9d-97cc6d36f8ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ae5f5b0>]}
[0m17:59:37.475388 [info ] [MainThread]: 
[0m17:59:37.476117 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:59:37.476682 [info ] [MainThread]: 
[0m17:59:37.477431 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m17:59:37.478716 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT'
[0m17:59:37.546835 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT"
[0m17:59:37.547717 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT: show terse schemas in database DATAEXPERT_STUDENT
    limit 10000
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT"} */
[0m17:59:37.548211 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:59:40.702967 [debug] [ThreadPool]: SQL status: SUCCESS 426 in 3.155 seconds
[0m17:59:40.725213 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT, now list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging)
[0m17:59:40.737976 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts'
[0m17:59:40.744510 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"
[0m17:59:40.747392 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"
[0m17:59:40.748108 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate'
[0m17:59:40.748916 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY'
[0m17:59:40.749625 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"} */;
[0m17:59:40.750312 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"} */;
[0m17:59:40.753791 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"
[0m17:59:40.756346 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY"
[0m17:59:40.757134 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:59:40.758668 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"} */;
[0m17:59:40.759441 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY"} */;
[0m17:59:40.761127 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:59:40.762097 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:59:40.893998 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.137 seconds
[0m17:59:43.610597 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2.850 seconds
[0m17:59:43.611749 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2.850 seconds
[0m17:59:43.633386 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2.876 seconds
[0m17:59:43.638237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f21d0212-2f98-4fb8-bf9d-97cc6d36f8ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11eae3e10>]}
[0m17:59:43.641598 [debug] [Thread-1 (]: Began running node model.data_ai_index.fct_github_repo_stats
[0m17:59:43.642468 [info ] [Thread-1 (]: 1 of 1 START sql table model KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats . [RUN]
[0m17:59:43.643281 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging, now model.data_ai_index.fct_github_repo_stats)
[0m17:59:43.643763 [debug] [Thread-1 (]: Began compiling node model.data_ai_index.fct_github_repo_stats
[0m17:59:43.653971 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_ai_index.fct_github_repo_stats"
[0m17:59:43.655080 [debug] [Thread-1 (]: Began executing node model.data_ai_index.fct_github_repo_stats
[0m17:59:43.701224 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_ai_index.fct_github_repo_stats"
[0m17:59:43.703297 [debug] [Thread-1 (]: Using snowflake connection "model.data_ai_index.fct_github_repo_stats"
[0m17:59:43.703858 [debug] [Thread-1 (]: On model.data_ai_index.fct_github_repo_stats: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats
    
    
    
    as (with repo_stats as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats
)

select
    repo_id,
    repo_name,
    full_name,
    category,
    primary_language,
    description,
    stars,
    forks,
    open_issues,
    watchers,
    repo_created_at,
    last_push_at,
    fetched_at,
    -- Derived metrics
    round(forks * 1.0 / nullif(stars, 0), 4) as fork_to_star_ratio,
    round(open_issues * 1.0 / nullif(stars, 0), 6) as issues_per_star,
    datediff('day', repo_created_at::date, fetched_at::date) as days_since_creation,
    datediff('day', last_push_at::date, fetched_at::date) as days_since_last_push,
    -- Activity classification
    case
        when datediff('day', last_push_at::date, fetched_at::date) <= 7 then 'Very Active'
        when datediff('day', last_push_at::date, fetched_at::date) <= 30 then 'Active'
        when datediff('day', last_push_at::date, fetched_at::date) <= 90 then 'Moderate'
        else 'Low Activity'
    end as activity_level
from repo_stats
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.fct_github_repo_stats"} */;
[0m17:59:44.788028 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c1de7b-0107-8ace-0000-33eb03352722
[0m17:59:44.788986 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
[0m17:59:44.801089 [debug] [Thread-1 (]: Database Error in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)
  100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
  compiled code at target/run/data_ai_index/models/marts/fct_github_repo_stats.sql
[0m17:59:44.803891 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f21d0212-2f98-4fb8-bf9d-97cc6d36f8ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11eb2b650>]}
[0m17:59:44.805138 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats  [[31mERROR[0m in 1.16s]
[0m17:59:44.806578 [debug] [Thread-1 (]: Finished running node model.data_ai_index.fct_github_repo_stats
[0m17:59:44.807605 [debug] [Thread-7 (]: Marking all children of 'model.data_ai_index.fct_github_repo_stats' to be skipped because of status 'error'.  Reason: Database Error in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)
  100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
  compiled code at target/run/data_ai_index/models/marts/fct_github_repo_stats.sql.
[0m17:59:44.810631 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:59:44.811267 [debug] [MainThread]: Connection 'model.data_ai_index.fct_github_repo_stats' was left open.
[0m17:59:44.811840 [debug] [MainThread]: On model.data_ai_index.fct_github_repo_stats: Close
[0m17:59:44.975101 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts' was left open.
[0m17:59:44.975999 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts: Close
[0m17:59:45.168138 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate' was left open.
[0m17:59:45.169119 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate: Close
[0m17:59:45.349591 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY' was left open.
[0m17:59:45.350344 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY: Close
[0m17:59:45.591593 [info ] [MainThread]: 
[0m17:59:45.592933 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 8.11 seconds (8.11s).
[0m17:59:45.595082 [debug] [MainThread]: Command end result
[0m17:59:45.658061 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/manifest.json
[0m17:59:45.660393 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/semantic_manifest.json
[0m17:59:45.667631 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/run_results.json
[0m17:59:45.668115 [info ] [MainThread]: 
[0m17:59:45.668610 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m17:59:45.669005 [info ] [MainThread]: 
[0m17:59:45.669580 [error] [MainThread]: [31mFailure in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)[0m
[0m17:59:45.670047 [error] [MainThread]:   Database Error in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)
  100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
  compiled code at target/run/data_ai_index/models/marts/fct_github_repo_stats.sql
[0m17:59:45.670390 [info ] [MainThread]: 
[0m17:59:45.670770 [info ] [MainThread]:   compiled code at target/compiled/data_ai_index/models/marts/fct_github_repo_stats.sql
[0m17:59:45.671254 [info ] [MainThread]: 
[0m17:59:45.671774 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m17:59:45.676634 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 11.259301, "process_in_blocks": "0", "process_kernel_time": 0.85572, "process_mem_max_rss": "242208768", "process_out_blocks": "0", "process_user_time": 7.067566}
[0m17:59:45.677644 [debug] [MainThread]: Command `dbt run` failed at 17:59:45.677397 after 11.26 seconds
[0m17:59:45.678507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ec37e30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ed465d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ed44050>]}
[0m17:59:45.679445 [debug] [MainThread]: Flushing usage events
[0m17:59:45.981068 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:01:32.475999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3a3a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb4bc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb4bed0>]}


============================== 18:01:32.482188 | 675ad075-d596-4821-a251-bcad17917ad9 ==============================
[0m18:01:32.482188 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:01:32.483357 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '.', 'fail_fast': 'False', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'write_json': 'True', 'empty': 'False', 'debug': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'indirect_selection': 'eager', 'introspect': 'True', 'target_path': 'None', 'printer_width': '80', 'use_experimental_parser': 'False', 'log_path': '/Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/logs', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'use_colors': 'True', 'quiet': 'False', 'invocation_command': 'dbt run --select fct_github_repo_stats --profiles-dir .', 'static_parser': 'True', 'log_format': 'default', 'log_cache_events': 'False'}
[0m18:01:33.947050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '675ad075-d596-4821-a251-bcad17917ad9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee98510>]}
[0m18:01:34.040269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '675ad075-d596-4821-a251-bcad17917ad9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11adc5370>]}
[0m18:01:34.041512 [info ] [MainThread]: Registered adapter: snowflake=1.10.2
[0m18:01:34.275247 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:01:34.497109 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:01:34.497583 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:01:34.579412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '675ad075-d596-4821-a251-bcad17917ad9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11add9150>]}
[0m18:01:34.731328 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/manifest.json
[0m18:01:34.734796 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/semantic_manifest.json
[0m18:01:34.764460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '675ad075-d596-4821-a251-bcad17917ad9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11adbd400>]}
[0m18:01:34.765560 [info ] [MainThread]: Found 18 models, 3 seeds, 49 data tests, 5 sources, 608 macros
[0m18:01:34.766438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '675ad075-d596-4821-a251-bcad17917ad9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b52b850>]}
[0m18:01:34.770414 [info ] [MainThread]: 
[0m18:01:34.771611 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:01:34.772312 [info ] [MainThread]: 
[0m18:01:34.773629 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m18:01:34.775021 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT'
[0m18:01:34.897223 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT"
[0m18:01:34.900352 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT: show terse schemas in database DATAEXPERT_STUDENT
    limit 10000
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT"} */
[0m18:01:34.901381 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:01:38.255369 [debug] [ThreadPool]: SQL status: SUCCESS 426 in 3.354 seconds
[0m18:01:38.282615 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate'
[0m18:01:38.290043 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging'
[0m18:01:38.296533 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY'
[0m18:01:38.301993 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"
[0m18:01:38.302848 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts'
[0m18:01:38.305604 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"
[0m18:01:38.308667 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY"
[0m18:01:38.309264 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"} */;
[0m18:01:38.311596 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"
[0m18:01:38.312023 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"} */;
[0m18:01:38.312418 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY"} */;
[0m18:01:38.312829 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:01:38.313160 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"} */;
[0m18:01:38.313496 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:01:38.313864 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:01:38.314475 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:01:39.144215 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.831 seconds
[0m18:01:39.222847 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.910 seconds
[0m18:01:39.482002 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.168 seconds
[0m18:01:39.499545 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.186 seconds
[0m18:01:39.504970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '675ad075-d596-4821-a251-bcad17917ad9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bc176c0>]}
[0m18:01:39.509027 [debug] [Thread-1 (]: Began running node model.data_ai_index.fct_github_repo_stats
[0m18:01:39.509957 [info ] [Thread-1 (]: 1 of 1 START sql table model KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats . [RUN]
[0m18:01:39.510619 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate, now model.data_ai_index.fct_github_repo_stats)
[0m18:01:39.511143 [debug] [Thread-1 (]: Began compiling node model.data_ai_index.fct_github_repo_stats
[0m18:01:39.519702 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_ai_index.fct_github_repo_stats"
[0m18:01:39.520622 [debug] [Thread-1 (]: Began executing node model.data_ai_index.fct_github_repo_stats
[0m18:01:39.563041 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_ai_index.fct_github_repo_stats"
[0m18:01:39.564996 [debug] [Thread-1 (]: Using snowflake connection "model.data_ai_index.fct_github_repo_stats"
[0m18:01:39.565475 [debug] [Thread-1 (]: On model.data_ai_index.fct_github_repo_stats: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats
    
    
    
    as (with repo_stats as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats
)

select
    repo_id,
    repo_name,
    full_name,
    category,
    primary_language,
    description,
    stars,
    forks,
    open_issues,
    watchers,
    repo_created_at,
    last_push_at,
    fetched_at,
    -- Derived metrics
    round(forks * 1.0 / nullif(stars, 0), 4) as fork_to_star_ratio,
    round(open_issues * 1.0 / nullif(stars, 0), 6) as issues_per_star,
    datediff('day', repo_created_at::date, fetched_at::date) as days_since_creation,
    datediff('day', last_push_at::date, fetched_at::date) as days_since_last_push,
    -- Activity classification
    case
        when datediff('day', last_push_at::date, fetched_at::date) <= 7 then 'Very Active'
        when datediff('day', last_push_at::date, fetched_at::date) <= 30 then 'Active'
        when datediff('day', last_push_at::date, fetched_at::date) <= 90 then 'Moderate'
        else 'Low Activity'
    end as activity_level
from repo_stats
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.fct_github_repo_stats"} */;
[0m18:01:40.560209 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01c1de7d-0107-8ae8-0000-33eb03353642
[0m18:01:40.560915 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
[0m18:01:40.569421 [debug] [Thread-1 (]: Database Error in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)
  100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
  compiled code at target/run/data_ai_index/models/marts/fct_github_repo_stats.sql
[0m18:01:40.572258 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '675ad075-d596-4821-a251-bcad17917ad9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f103590>]}
[0m18:01:40.573408 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats  [[31mERROR[0m in 1.06s]
[0m18:01:40.574348 [debug] [Thread-1 (]: Finished running node model.data_ai_index.fct_github_repo_stats
[0m18:01:40.575106 [debug] [Thread-7 (]: Marking all children of 'model.data_ai_index.fct_github_repo_stats' to be skipped because of status 'error'.  Reason: Database Error in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)
  100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
  compiled code at target/run/data_ai_index/models/marts/fct_github_repo_stats.sql.
[0m18:01:40.577791 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:01:40.578295 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT' was left open.
[0m18:01:40.578739 [debug] [MainThread]: On list_DATAEXPERT_STUDENT: Close
[0m18:01:40.729121 [debug] [MainThread]: Connection 'model.data_ai_index.fct_github_repo_stats' was left open.
[0m18:01:40.729649 [debug] [MainThread]: On model.data_ai_index.fct_github_repo_stats: Close
[0m18:01:40.956729 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging' was left open.
[0m18:01:40.957402 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging: Close
[0m18:01:41.187280 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY' was left open.
[0m18:01:41.188377 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY: Close
[0m18:01:41.371634 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts' was left open.
[0m18:01:41.372127 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts: Close
[0m18:01:41.536946 [info ] [MainThread]: 
[0m18:01:41.537546 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 6.76 seconds (6.76s).
[0m18:01:41.538505 [debug] [MainThread]: Command end result
[0m18:01:41.591050 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/manifest.json
[0m18:01:41.594177 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/semantic_manifest.json
[0m18:01:41.602757 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/run_results.json
[0m18:01:41.603521 [info ] [MainThread]: 
[0m18:01:41.604401 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:01:41.604928 [info ] [MainThread]: 
[0m18:01:41.605470 [error] [MainThread]: [31mFailure in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)[0m
[0m18:01:41.606005 [error] [MainThread]:   Database Error in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)
  100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
  compiled code at target/run/data_ai_index/models/marts/fct_github_repo_stats.sql
[0m18:01:41.606341 [info ] [MainThread]: 
[0m18:01:41.606817 [info ] [MainThread]:   compiled code at target/compiled/data_ai_index/models/marts/fct_github_repo_stats.sql
[0m18:01:41.607188 [info ] [MainThread]: 
[0m18:01:41.607652 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m18:01:41.612162 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.242857, "process_in_blocks": "0", "process_kernel_time": 0.806823, "process_mem_max_rss": "237727744", "process_out_blocks": "0", "process_user_time": 6.274513}
[0m18:01:41.613040 [debug] [MainThread]: Command `dbt run` failed at 18:01:41.612837 after 9.24 seconds
[0m18:01:41.613578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f12fe30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f037ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f037bb0>]}
[0m18:01:41.614168 [debug] [MainThread]: Flushing usage events
[0m18:01:41.840225 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:17:46.015192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5dba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd8fc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd8fed0>]}


============================== 18:17:46.022214 | abf1d35d-d04a-4462-b535-d4a269bd43e1 ==============================
[0m18:17:46.022214 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:17:46.023027 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'indirect_selection': 'eager', 'debug': 'False', 'partial_parse': 'True', 'printer_width': '80', 'target_path': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select stg_github__repo_stats+ --profiles-dir .', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'quiet': 'False', 'write_json': 'True', 'fail_fast': 'False', 'log_path': '/Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/logs', 'warn_error': 'None', 'no_print': 'None', 'log_cache_events': 'False', 'profiles_dir': '.', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'empty': 'False'}
[0m18:17:48.074035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'abf1d35d-d04a-4462-b535-d4a269bd43e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0d0510>]}
[0m18:17:48.165987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'abf1d35d-d04a-4462-b535-d4a269bd43e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11afad370>]}
[0m18:17:48.185636 [info ] [MainThread]: Registered adapter: snowflake=1.10.2
[0m18:17:48.393652 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:17:48.683268 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:17:48.684003 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:17:48.777415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'abf1d35d-d04a-4462-b535-d4a269bd43e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11afc1150>]}
[0m18:17:48.942056 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/manifest.json
[0m18:17:48.946307 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/semantic_manifest.json
[0m18:17:48.988788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'abf1d35d-d04a-4462-b535-d4a269bd43e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11afb5400>]}
[0m18:17:48.989389 [info ] [MainThread]: Found 18 models, 3 seeds, 49 data tests, 5 sources, 608 macros
[0m18:17:48.989871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'abf1d35d-d04a-4462-b535-d4a269bd43e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b70f850>]}
[0m18:17:48.992748 [info ] [MainThread]: 
[0m18:17:48.993327 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:17:48.993728 [info ] [MainThread]: 
[0m18:17:48.994311 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m18:17:49.001094 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT'
[0m18:17:49.010108 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT'
[0m18:17:49.084004 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT"
[0m18:17:49.084804 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT"
[0m18:17:49.085252 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT: show terse schemas in database DATAEXPERT_STUDENT
    limit 10000
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT"} */
[0m18:17:49.085752 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT: show terse schemas in database DATAEXPERT_STUDENT
    limit 10000
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT"} */
[0m18:17:49.086625 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:17:49.087363 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:17:53.117711 [debug] [ThreadPool]: SQL status: SUCCESS 426 in 4.031 seconds
[0m18:17:53.170719 [debug] [ThreadPool]: SQL status: SUCCESS 426 in 4.083 seconds
[0m18:17:53.184842 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY'
[0m18:17:53.185577 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts'
[0m18:17:53.192567 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging'
[0m18:17:53.204073 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate'
[0m18:17:53.203561 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY"
[0m18:17:53.207058 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"
[0m18:17:53.210602 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"
[0m18:17:53.214020 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"
[0m18:17:53.214510 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY"} */;
[0m18:17:53.214880 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"} */;
[0m18:17:53.215260 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"} */;
[0m18:17:53.215642 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"} */;
[0m18:17:53.215972 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:17:53.216326 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:17:53.216679 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:17:53.216989 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:17:56.006754 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2.790 seconds
[0m18:17:56.010200 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2.793 seconds
[0m18:17:56.013095 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2.797 seconds
[0m18:17:56.032000 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2.815 seconds
[0m18:17:56.036386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'abf1d35d-d04a-4462-b535-d4a269bd43e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11eaf81f0>]}
[0m18:17:56.041460 [debug] [Thread-1 (]: Began running node model.data_ai_index.stg_github__repo_stats
[0m18:17:56.042312 [info ] [Thread-1 (]: 1 of 2 START sql view model KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats  [RUN]
[0m18:17:56.043046 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY, now model.data_ai_index.stg_github__repo_stats)
[0m18:17:56.043857 [debug] [Thread-1 (]: Began compiling node model.data_ai_index.stg_github__repo_stats
[0m18:17:56.053363 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_ai_index.stg_github__repo_stats"
[0m18:17:56.054333 [debug] [Thread-1 (]: Began executing node model.data_ai_index.stg_github__repo_stats
[0m18:17:56.101745 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_ai_index.stg_github__repo_stats"
[0m18:17:56.103306 [debug] [Thread-1 (]: Using snowflake connection "model.data_ai_index.stg_github__repo_stats"
[0m18:17:56.103799 [debug] [Thread-1 (]: On model.data_ai_index.stg_github__repo_stats: create or replace   view DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats
  
  
  
  
  as (
    with source as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.raw_github_repo_stats
),

cleaned as (
    select
        full_name as repo_id,
        repo_name,
        full_name,
        category,
        stars,
        forks,
        open_issues,
        watchers,
        language as primary_language,
        description,
        created_at as repo_created_at,
        updated_at as repo_updated_at,
        pushed_at as last_push_at,
        fetched_at,
        _loaded_at

    from source
)

select * from cleaned
  )
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.stg_github__repo_stats"} */;
[0m18:17:56.471714 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.367 seconds
[0m18:17:56.518722 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'abf1d35d-d04a-4462-b535-d4a269bd43e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f33a810>]}
[0m18:17:56.519665 [info ] [Thread-1 (]: 1 of 2 OK created sql view model KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats  [[32mSUCCESS 1[0m in 0.47s]
[0m18:17:56.520484 [debug] [Thread-1 (]: Finished running node model.data_ai_index.stg_github__repo_stats
[0m18:17:56.521658 [debug] [Thread-2 (]: Began running node model.data_ai_index.fct_github_repo_stats
[0m18:17:56.522342 [info ] [Thread-2 (]: 2 of 2 START sql table model KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats . [RUN]
[0m18:17:56.523056 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts, now model.data_ai_index.fct_github_repo_stats)
[0m18:17:56.523467 [debug] [Thread-2 (]: Began compiling node model.data_ai_index.fct_github_repo_stats
[0m18:17:56.527074 [debug] [Thread-2 (]: Writing injected SQL for node "model.data_ai_index.fct_github_repo_stats"
[0m18:17:56.528419 [debug] [Thread-2 (]: Began executing node model.data_ai_index.fct_github_repo_stats
[0m18:17:56.562455 [debug] [Thread-2 (]: Writing runtime sql for node "model.data_ai_index.fct_github_repo_stats"
[0m18:17:56.564785 [debug] [Thread-2 (]: Using snowflake connection "model.data_ai_index.fct_github_repo_stats"
[0m18:17:56.565346 [debug] [Thread-2 (]: On model.data_ai_index.fct_github_repo_stats: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats
    
    
    
    as (with repo_stats as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats
)

select
    repo_id,
    repo_name,
    full_name,
    category,
    primary_language,
    description,
    stars,
    forks,
    open_issues,
    watchers,
    repo_created_at,
    last_push_at,
    fetched_at,
    -- Derived metrics
    round(forks * 1.0 / nullif(stars, 0), 4) as fork_to_star_ratio,
    round(open_issues * 1.0 / nullif(stars, 0), 6) as issues_per_star,
    datediff('day', repo_created_at::date, fetched_at::date) as days_since_creation,
    datediff('day', last_push_at::date, fetched_at::date) as days_since_last_push,
    -- Activity classification
    case
        when datediff('day', last_push_at::date, fetched_at::date) <= 7 then 'Very Active'
        when datediff('day', last_push_at::date, fetched_at::date) <= 30 then 'Active'
        when datediff('day', last_push_at::date, fetched_at::date) <= 90 then 'Moderate'
        else 'Low Activity'
    end as activity_level
from repo_stats
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.fct_github_repo_stats"} */;
[0m18:17:58.332943 [debug] [Thread-2 (]: Snowflake adapter: Snowflake query id: 01c1de8d-0107-8ae8-0000-33eb033539b2
[0m18:17:58.333662 [debug] [Thread-2 (]: Snowflake adapter: Snowflake error: 100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
[0m18:17:58.342214 [debug] [Thread-2 (]: Database Error in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)
  100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
  compiled code at target/run/data_ai_index/models/marts/fct_github_repo_stats.sql
[0m18:17:58.343256 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'abf1d35d-d04a-4462-b535-d4a269bd43e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f3b6a40>]}
[0m18:17:58.344530 [error] [Thread-2 (]: 2 of 2 ERROR creating sql table model KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats  [[31mERROR[0m in 1.82s]
[0m18:17:58.345461 [debug] [Thread-2 (]: Finished running node model.data_ai_index.fct_github_repo_stats
[0m18:17:58.346223 [debug] [Thread-7 (]: Marking all children of 'model.data_ai_index.fct_github_repo_stats' to be skipped because of status 'error'.  Reason: Database Error in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)
  100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
  compiled code at target/run/data_ai_index/models/marts/fct_github_repo_stats.sql.
[0m18:17:58.349083 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:17:58.349553 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT' was left open.
[0m18:17:58.350008 [debug] [MainThread]: On list_DATAEXPERT_STUDENT: Close
[0m18:17:58.531254 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT' was left open.
[0m18:17:58.531892 [debug] [MainThread]: On list_DATAEXPERT_STUDENT: Close
[0m18:17:58.724968 [debug] [MainThread]: Connection 'model.data_ai_index.stg_github__repo_stats' was left open.
[0m18:17:58.726377 [debug] [MainThread]: On model.data_ai_index.stg_github__repo_stats: Close
[0m18:17:58.911553 [debug] [MainThread]: Connection 'model.data_ai_index.fct_github_repo_stats' was left open.
[0m18:17:58.912724 [debug] [MainThread]: On model.data_ai_index.fct_github_repo_stats: Close
[0m18:17:59.105383 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging' was left open.
[0m18:17:59.106032 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging: Close
[0m18:17:59.289359 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate' was left open.
[0m18:17:59.289946 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate: Close
[0m18:17:59.457285 [info ] [MainThread]: 
[0m18:17:59.457860 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 10.46 seconds (10.46s).
[0m18:17:59.459330 [debug] [MainThread]: Command end result
[0m18:17:59.506273 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/manifest.json
[0m18:17:59.509475 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/semantic_manifest.json
[0m18:17:59.518923 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/run_results.json
[0m18:17:59.519419 [info ] [MainThread]: 
[0m18:17:59.519946 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:17:59.520339 [info ] [MainThread]: 
[0m18:17:59.520827 [error] [MainThread]: [31mFailure in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)[0m
[0m18:17:59.521362 [error] [MainThread]:   Database Error in model fct_github_repo_stats (models/marts/fct_github_repo_stats.sql)
  100035 (22007): Timestamp '(seconds_since_epoch=1768680966332993200)' is not recognized
  compiled code at target/run/data_ai_index/models/marts/fct_github_repo_stats.sql
[0m18:17:59.521928 [info ] [MainThread]: 
[0m18:17:59.522517 [info ] [MainThread]:   compiled code at target/compiled/data_ai_index/models/marts/fct_github_repo_stats.sql
[0m18:17:59.523056 [info ] [MainThread]: 
[0m18:17:59.523714 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=2
[0m18:17:59.529158 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 13.624137, "process_in_blocks": "0", "process_kernel_time": 1.224653, "process_mem_max_rss": "238858240", "process_out_blocks": "0", "process_user_time": 7.243179}
[0m18:17:59.530356 [debug] [MainThread]: Command `dbt run` failed at 18:17:59.530169 after 13.63 seconds
[0m18:17:59.530911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0a53b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f3fed50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b4be8d0>]}
[0m18:17:59.531346 [debug] [MainThread]: Flushing usage events
[0m18:17:59.828309 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:31:58.986919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c577a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dce3c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dce3ed0>]}


============================== 18:31:58.992174 | 09130df4-9690-4ceb-91f6-466c0376a065 ==============================
[0m18:31:58.992174 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:31:58.992863 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'invocation_command': 'dbt run --select stg_github__repo_stats+ --profiles-dir .', 'log_format': 'default', 'use_experimental_parser': 'False', 'version_check': 'True', 'profiles_dir': '.', 'indirect_selection': 'eager', 'printer_width': '80', 'fail_fast': 'False', 'introspect': 'True', 'static_parser': 'True', 'quiet': 'False', 'use_colors': 'True', 'warn_error': 'None', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'empty': 'False', 'log_cache_events': 'False', 'log_path': '/Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/logs', 'cache_selected_only': 'False'}
[0m18:32:00.722637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '09130df4-9690-4ceb-91f6-466c0376a065', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d05c510>]}
[0m18:32:00.849618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '09130df4-9690-4ceb-91f6-466c0376a065', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118fc1370>]}
[0m18:32:00.850729 [info ] [MainThread]: Registered adapter: snowflake=1.10.2
[0m18:32:01.063526 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:32:01.300571 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:32:01.301067 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:32:01.388500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '09130df4-9690-4ceb-91f6-466c0376a065', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118fd5150>]}
[0m18:32:01.554356 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/manifest.json
[0m18:32:01.557115 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/semantic_manifest.json
[0m18:32:01.583977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '09130df4-9690-4ceb-91f6-466c0376a065', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118fc9400>]}
[0m18:32:01.584598 [info ] [MainThread]: Found 18 models, 3 seeds, 49 data tests, 5 sources, 608 macros
[0m18:32:01.585117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '09130df4-9690-4ceb-91f6-466c0376a065', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119637850>]}
[0m18:32:01.589267 [info ] [MainThread]: 
[0m18:32:01.589825 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:32:01.590204 [info ] [MainThread]: 
[0m18:32:01.590835 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m18:32:01.597417 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT'
[0m18:32:01.598321 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT'
[0m18:32:01.685304 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT"
[0m18:32:01.686790 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT"
[0m18:32:01.687390 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT: show terse schemas in database DATAEXPERT_STUDENT
    limit 10000
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT"} */
[0m18:32:01.688166 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT: show terse schemas in database DATAEXPERT_STUDENT
    limit 10000
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT"} */
[0m18:32:01.688986 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:32:01.689512 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:32:04.990902 [debug] [ThreadPool]: SQL status: SUCCESS 426 in 3.301 seconds
[0m18:32:05.438525 [debug] [ThreadPool]: SQL status: SUCCESS 426 in 3.750 seconds
[0m18:32:05.454254 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts'
[0m18:32:05.461449 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate'
[0m18:32:05.462604 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY'
[0m18:32:05.481194 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging'
[0m18:32:05.488277 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"
[0m18:32:05.491820 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY"
[0m18:32:05.492334 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"
[0m18:32:05.495273 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"
[0m18:32:05.496037 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"} */;
[0m18:32:05.496592 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY"} */;
[0m18:32:05.497204 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"} */;
[0m18:32:05.497757 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"} */;
[0m18:32:05.498195 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:32:05.498686 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:32:05.499084 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:32:05.499492 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:32:06.321819 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.823 seconds
[0m18:32:06.348450 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.849 seconds
[0m18:32:06.361058 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.862 seconds
[0m18:32:06.414776 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.917 seconds
[0m18:32:06.419647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '09130df4-9690-4ceb-91f6-466c0376a065', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b70460>]}
[0m18:32:06.423908 [debug] [Thread-1 (]: Began running node model.data_ai_index.stg_github__repo_stats
[0m18:32:06.424691 [info ] [Thread-1 (]: 1 of 2 START sql view model KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats  [RUN]
[0m18:32:06.425312 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts, now model.data_ai_index.stg_github__repo_stats)
[0m18:32:06.425835 [debug] [Thread-1 (]: Began compiling node model.data_ai_index.stg_github__repo_stats
[0m18:32:06.437105 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_ai_index.stg_github__repo_stats"
[0m18:32:06.438151 [debug] [Thread-1 (]: Began executing node model.data_ai_index.stg_github__repo_stats
[0m18:32:06.487791 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_ai_index.stg_github__repo_stats"
[0m18:32:06.489837 [debug] [Thread-1 (]: Using snowflake connection "model.data_ai_index.stg_github__repo_stats"
[0m18:32:06.490618 [debug] [Thread-1 (]: On model.data_ai_index.stg_github__repo_stats: create or replace   view DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats
  
  
  
  
  as (
    with source as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY.raw_github_repo_stats
),

cleaned as (
    select
        full_name as repo_id,
        repo_name,
        full_name,
        category,
        stars,
        forks,
        open_issues,
        watchers,
        language as primary_language,
        description,
        created_at as repo_created_at,
        updated_at as repo_updated_at,
        pushed_at as last_push_at,
        fetched_at,
        _loaded_at

    from source
)

select * from cleaned
  )
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.stg_github__repo_stats"} */;
[0m18:32:06.859515 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.368 seconds
[0m18:32:06.896673 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09130df4-9690-4ceb-91f6-466c0376a065', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d1db590>]}
[0m18:32:06.897671 [info ] [Thread-1 (]: 1 of 2 OK created sql view model KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats  [[32mSUCCESS 1[0m in 0.47s]
[0m18:32:06.899170 [debug] [Thread-1 (]: Finished running node model.data_ai_index.stg_github__repo_stats
[0m18:32:06.901031 [debug] [Thread-2 (]: Began running node model.data_ai_index.fct_github_repo_stats
[0m18:32:06.902554 [info ] [Thread-2 (]: 2 of 2 START sql table model KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats . [RUN]
[0m18:32:06.903558 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate, now model.data_ai_index.fct_github_repo_stats)
[0m18:32:06.904569 [debug] [Thread-2 (]: Began compiling node model.data_ai_index.fct_github_repo_stats
[0m18:32:06.909450 [debug] [Thread-2 (]: Writing injected SQL for node "model.data_ai_index.fct_github_repo_stats"
[0m18:32:06.910506 [debug] [Thread-2 (]: Began executing node model.data_ai_index.fct_github_repo_stats
[0m18:32:06.949372 [debug] [Thread-2 (]: Writing runtime sql for node "model.data_ai_index.fct_github_repo_stats"
[0m18:32:06.952614 [debug] [Thread-2 (]: Using snowflake connection "model.data_ai_index.fct_github_repo_stats"
[0m18:32:06.953529 [debug] [Thread-2 (]: On model.data_ai_index.fct_github_repo_stats: create or replace transient table DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats
    
    
    
    as (with repo_stats as (
    select * from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats
)

select
    repo_id,
    repo_name,
    full_name,
    category,
    primary_language,
    description,
    stars,
    forks,
    open_issues,
    watchers,
    repo_created_at,
    last_push_at,
    fetched_at,
    -- Derived metrics
    round(forks * 1.0 / nullif(stars, 0), 4) as fork_to_star_ratio,
    round(open_issues * 1.0 / nullif(stars, 0), 6) as issues_per_star,
    datediff('day', repo_created_at::date, fetched_at::date) as days_since_creation,
    datediff('day', last_push_at::date, fetched_at::date) as days_since_last_push,
    -- Activity classification
    case
        when datediff('day', last_push_at::date, fetched_at::date) <= 7 then 'Very Active'
        when datediff('day', last_push_at::date, fetched_at::date) <= 30 then 'Active'
        when datediff('day', last_push_at::date, fetched_at::date) <= 90 then 'Moderate'
        else 'Low Activity'
    end as activity_level
from repo_stats
    )

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "model.data_ai_index.fct_github_repo_stats"} */;
[0m18:32:08.438095 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1.484 seconds
[0m18:32:08.442304 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09130df4-9690-4ceb-91f6-466c0376a065', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d242620>]}
[0m18:32:08.443143 [info ] [Thread-2 (]: 2 of 2 OK created sql table model KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats  [[32mSUCCESS 1[0m in 1.54s]
[0m18:32:08.443896 [debug] [Thread-2 (]: Finished running node model.data_ai_index.fct_github_repo_stats
[0m18:32:08.445920 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:32:08.446395 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT' was left open.
[0m18:32:08.446809 [debug] [MainThread]: On list_DATAEXPERT_STUDENT: Close
[0m18:32:08.706462 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT' was left open.
[0m18:32:08.707446 [debug] [MainThread]: On list_DATAEXPERT_STUDENT: Close
[0m18:32:08.896135 [debug] [MainThread]: Connection 'model.data_ai_index.stg_github__repo_stats' was left open.
[0m18:32:08.896656 [debug] [MainThread]: On model.data_ai_index.stg_github__repo_stats: Close
[0m18:32:09.101954 [debug] [MainThread]: Connection 'model.data_ai_index.fct_github_repo_stats' was left open.
[0m18:32:09.102681 [debug] [MainThread]: On model.data_ai_index.fct_github_repo_stats: Close
[0m18:32:09.280766 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY' was left open.
[0m18:32:09.281640 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY: Close
[0m18:32:09.901956 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging' was left open.
[0m18:32:09.902474 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging: Close
[0m18:32:10.114587 [info ] [MainThread]: 
[0m18:32:10.115640 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 8.52 seconds (8.52s).
[0m18:32:10.117412 [debug] [MainThread]: Command end result
[0m18:32:10.168473 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/manifest.json
[0m18:32:10.171807 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/semantic_manifest.json
[0m18:32:10.180681 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/run_results.json
[0m18:32:10.181413 [info ] [MainThread]: 
[0m18:32:10.182590 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:32:10.183162 [info ] [MainThread]: 
[0m18:32:10.183704 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m18:32:10.190062 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 11.299233, "process_in_blocks": "0", "process_kernel_time": 0.898794, "process_mem_max_rss": "239128576", "process_out_blocks": "0", "process_user_time": 6.565572}
[0m18:32:10.190831 [debug] [MainThread]: Command `dbt run` succeeded at 18:32:10.190665 after 11.30 seconds
[0m18:32:10.191352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d13a2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d28f260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1191479d0>]}
[0m18:32:10.191865 [debug] [MainThread]: Flushing usage events
[0m18:32:10.497042 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:32:31.500666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e433a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbdfc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbdfed0>]}


============================== 18:32:31.508253 | 5132ea13-43b6-4886-a016-641d2ea95131 ==============================
[0m18:32:31.508253 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:32:31.509095 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': '.', 'no_print': 'None', 'target_path': 'None', 'log_cache_events': 'False', 'static_parser': 'True', 'warn_error': 'None', 'use_experimental_parser': 'False', 'debug': 'False', 'use_colors': 'True', 'version_check': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'introspect': 'True', 'printer_width': '80', 'fail_fast': 'False', 'log_path': '/Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/logs', 'empty': 'None', 'invocation_command': 'dbt test --profiles-dir .', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'quiet': 'False'}
[0m18:32:32.943833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5132ea13-43b6-4886-a016-641d2ea95131', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef28510>]}
[0m18:32:33.033870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5132ea13-43b6-4886-a016-641d2ea95131', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ae91370>]}
[0m18:32:33.035041 [info ] [MainThread]: Registered adapter: snowflake=1.10.2
[0m18:32:33.209099 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:32:33.428027 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:32:33.428519 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:32:33.506030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5132ea13-43b6-4886-a016-641d2ea95131', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aea1350>]}
[0m18:32:33.725486 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/manifest.json
[0m18:32:33.728021 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/semantic_manifest.json
[0m18:32:33.766620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5132ea13-43b6-4886-a016-641d2ea95131', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b6035c0>]}
[0m18:32:33.767218 [info ] [MainThread]: Found 18 models, 3 seeds, 49 data tests, 5 sources, 608 macros
[0m18:32:33.767644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5132ea13-43b6-4886-a016-641d2ea95131', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b0044b0>]}
[0m18:32:33.773016 [info ] [MainThread]: 
[0m18:32:33.773786 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:32:33.774550 [info ] [MainThread]: 
[0m18:32:33.775603 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m18:32:33.787087 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging'
[0m18:32:33.799736 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate'
[0m18:32:33.818094 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY'
[0m18:32:33.831417 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts'
[0m18:32:33.902417 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY"
[0m18:32:33.903327 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"
[0m18:32:33.904004 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY"} */;
[0m18:32:33.904629 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"
[0m18:32:33.905254 [debug] [ThreadPool]: Using snowflake connection "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"
[0m18:32:33.905682 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging"} */;
[0m18:32:33.906094 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:32:33.906491 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts"} */;
[0m18:32:33.906840 [debug] [ThreadPool]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate: show objects in DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "connection_name": "list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate"} */;
[0m18:32:33.907187 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:32:33.908730 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:32:33.909570 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:32:37.346260 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 3.440 seconds
[0m18:32:37.390918 [debug] [ThreadPool]: SQL status: SUCCESS 9 in 3.482 seconds
[0m18:32:37.488588 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 3.579 seconds
[0m18:32:37.529584 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 3.622 seconds
[0m18:32:37.534081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5132ea13-43b6-4886-a016-641d2ea95131', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b58f5f0>]}
[0m18:32:37.539508 [debug] [Thread-2 (]: Began running node test.data_ai_index.not_null_dim_date_date_key.881d0a31b6
[0m18:32:37.540142 [debug] [Thread-1 (]: Began running node test.data_ai_index.accepted_values_dim_roles_tier__1__2__3__4__5.cee9b4d79c
[0m18:32:37.540630 [debug] [Thread-3 (]: Began running node test.data_ai_index.not_null_dim_roles_role_id.4c31620634
[0m18:32:37.541102 [info ] [Thread-2 (]: 2 of 49 START test not_null_dim_date_date_key .................................. [RUN]
[0m18:32:37.541723 [debug] [Thread-4 (]: Began running node test.data_ai_index.not_null_dim_roles_role_name.aafac91aed
[0m18:32:37.542422 [info ] [Thread-1 (]: 1 of 49 START test accepted_values_dim_roles_tier__1__2__3__4__5 ............... [RUN]
[0m18:32:37.543410 [info ] [Thread-3 (]: 3 of 49 START test not_null_dim_roles_role_id .................................. [RUN]
[0m18:32:37.544457 [debug] [Thread-2 (]: Acquiring new snowflake connection 'test.data_ai_index.not_null_dim_date_date_key.881d0a31b6'
[0m18:32:37.545333 [info ] [Thread-4 (]: 4 of 49 START test not_null_dim_roles_role_name ................................ [RUN]
[0m18:32:37.546583 [debug] [Thread-1 (]: Acquiring new snowflake connection 'test.data_ai_index.accepted_values_dim_roles_tier__1__2__3__4__5.cee9b4d79c'
[0m18:32:37.547337 [debug] [Thread-3 (]: Acquiring new snowflake connection 'test.data_ai_index.not_null_dim_roles_role_id.4c31620634'
[0m18:32:37.548130 [debug] [Thread-2 (]: Began compiling node test.data_ai_index.not_null_dim_date_date_key.881d0a31b6
[0m18:32:37.549079 [debug] [Thread-4 (]: Acquiring new snowflake connection 'test.data_ai_index.not_null_dim_roles_role_name.aafac91aed'
[0m18:32:37.549738 [debug] [Thread-1 (]: Began compiling node test.data_ai_index.accepted_values_dim_roles_tier__1__2__3__4__5.cee9b4d79c
[0m18:32:37.550348 [debug] [Thread-3 (]: Began compiling node test.data_ai_index.not_null_dim_roles_role_id.4c31620634
[0m18:32:37.556218 [debug] [Thread-4 (]: Began compiling node test.data_ai_index.not_null_dim_roles_role_name.aafac91aed
[0m18:32:37.574108 [debug] [Thread-2 (]: Writing injected SQL for node "test.data_ai_index.not_null_dim_date_date_key.881d0a31b6"
[0m18:32:37.592111 [debug] [Thread-3 (]: Writing injected SQL for node "test.data_ai_index.not_null_dim_roles_role_id.4c31620634"
[0m18:32:37.586564 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_ai_index.accepted_values_dim_roles_tier__1__2__3__4__5.cee9b4d79c"
[0m18:32:37.614331 [debug] [Thread-4 (]: Writing injected SQL for node "test.data_ai_index.not_null_dim_roles_role_name.aafac91aed"
[0m18:32:37.615621 [debug] [Thread-2 (]: Began executing node test.data_ai_index.not_null_dim_date_date_key.881d0a31b6
[0m18:32:37.616312 [debug] [Thread-1 (]: Began executing node test.data_ai_index.accepted_values_dim_roles_tier__1__2__3__4__5.cee9b4d79c
[0m18:32:37.622412 [debug] [Thread-3 (]: Began executing node test.data_ai_index.not_null_dim_roles_role_id.4c31620634
[0m18:32:37.652857 [debug] [Thread-4 (]: Began executing node test.data_ai_index.not_null_dim_roles_role_name.aafac91aed
[0m18:32:37.700267 [debug] [Thread-4 (]: Writing runtime sql for node "test.data_ai_index.not_null_dim_roles_role_name.aafac91aed"
[0m18:32:37.709435 [debug] [Thread-3 (]: Writing runtime sql for node "test.data_ai_index.not_null_dim_roles_role_id.4c31620634"
[0m18:32:37.711833 [debug] [Thread-2 (]: Writing runtime sql for node "test.data_ai_index.not_null_dim_date_date_key.881d0a31b6"
[0m18:32:37.713824 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_ai_index.accepted_values_dim_roles_tier__1__2__3__4__5.cee9b4d79c"
[0m18:32:37.716625 [debug] [Thread-4 (]: Using snowflake connection "test.data_ai_index.not_null_dim_roles_role_name.aafac91aed"
[0m18:32:37.717789 [debug] [Thread-3 (]: Using snowflake connection "test.data_ai_index.not_null_dim_roles_role_id.4c31620634"
[0m18:32:37.718881 [debug] [Thread-4 (]: On test.data_ai_index.not_null_dim_roles_role_name.aafac91aed: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select role_name
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_roles
where role_name is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_dim_roles_role_name.aafac91aed"} */
[0m18:32:37.720678 [debug] [Thread-1 (]: Using snowflake connection "test.data_ai_index.accepted_values_dim_roles_tier__1__2__3__4__5.cee9b4d79c"
[0m18:32:37.722124 [debug] [Thread-2 (]: Using snowflake connection "test.data_ai_index.not_null_dim_date_date_key.881d0a31b6"
[0m18:32:37.722808 [debug] [Thread-3 (]: On test.data_ai_index.not_null_dim_roles_role_id.4c31620634: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select role_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_roles
where role_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_dim_roles_role_id.4c31620634"} */
[0m18:32:37.723511 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m18:32:37.724198 [debug] [Thread-1 (]: On test.data_ai_index.accepted_values_dim_roles_tier__1__2__3__4__5.cee9b4d79c: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        tier as value_field,
        count(*) as n_records

    from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_roles
    group by tier

)

select *
from all_values
where value_field not in (
    '1','2','3','4','5'
)



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.accepted_values_dim_roles_tier__1__2__3__4__5.cee9b4d79c"} */
[0m18:32:37.725041 [debug] [Thread-2 (]: On test.data_ai_index.not_null_dim_date_date_key.881d0a31b6: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date_key
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_date
where date_key is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_dim_date_date_key.881d0a31b6"} */
[0m18:32:37.725648 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m18:32:37.726639 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:32:37.728004 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:32:40.560720 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 2.835 seconds
[0m18:32:40.577196 [info ] [Thread-3 (]: 3 of 49 PASS not_null_dim_roles_role_id ........................................ [[32mPASS[0m in 3.03s]
[0m18:32:40.578882 [debug] [Thread-3 (]: Finished running node test.data_ai_index.not_null_dim_roles_role_id.4c31620634
[0m18:32:40.579546 [debug] [Thread-3 (]: Began running node test.data_ai_index.not_null_dim_technologies_technology_id.29429ee493
[0m18:32:40.580191 [info ] [Thread-3 (]: 5 of 49 START test not_null_dim_technologies_technology_id ..................... [RUN]
[0m18:32:40.580910 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_dim_roles_role_id.4c31620634, now test.data_ai_index.not_null_dim_technologies_technology_id.29429ee493)
[0m18:32:40.581778 [debug] [Thread-3 (]: Began compiling node test.data_ai_index.not_null_dim_technologies_technology_id.29429ee493
[0m18:32:40.589989 [debug] [Thread-3 (]: Writing injected SQL for node "test.data_ai_index.not_null_dim_technologies_technology_id.29429ee493"
[0m18:32:40.591106 [debug] [Thread-3 (]: Began executing node test.data_ai_index.not_null_dim_technologies_technology_id.29429ee493
[0m18:32:40.595091 [debug] [Thread-3 (]: Writing runtime sql for node "test.data_ai_index.not_null_dim_technologies_technology_id.29429ee493"
[0m18:32:40.597058 [debug] [Thread-3 (]: Using snowflake connection "test.data_ai_index.not_null_dim_technologies_technology_id.29429ee493"
[0m18:32:40.597993 [debug] [Thread-3 (]: On test.data_ai_index.not_null_dim_technologies_technology_id.29429ee493: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select technology_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_technologies
where technology_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_dim_technologies_technology_id.29429ee493"} */
[0m18:32:40.609540 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 2.881 seconds
[0m18:32:40.612499 [info ] [Thread-2 (]: 2 of 49 PASS not_null_dim_date_date_key ........................................ [[32mPASS[0m in 3.07s]
[0m18:32:40.613346 [debug] [Thread-2 (]: Finished running node test.data_ai_index.not_null_dim_date_date_key.881d0a31b6
[0m18:32:40.613859 [debug] [Thread-2 (]: Began running node test.data_ai_index.not_null_dim_technologies_technology_name.7e8d31ebe5
[0m18:32:40.614307 [info ] [Thread-2 (]: 6 of 49 START test not_null_dim_technologies_technology_name ................... [RUN]
[0m18:32:40.615310 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_dim_date_date_key.881d0a31b6, now test.data_ai_index.not_null_dim_technologies_technology_name.7e8d31ebe5)
[0m18:32:40.616787 [debug] [Thread-2 (]: Began compiling node test.data_ai_index.not_null_dim_technologies_technology_name.7e8d31ebe5
[0m18:32:40.624823 [debug] [Thread-2 (]: Writing injected SQL for node "test.data_ai_index.not_null_dim_technologies_technology_name.7e8d31ebe5"
[0m18:32:40.626395 [debug] [Thread-2 (]: Began executing node test.data_ai_index.not_null_dim_technologies_technology_name.7e8d31ebe5
[0m18:32:40.630744 [debug] [Thread-2 (]: Writing runtime sql for node "test.data_ai_index.not_null_dim_technologies_technology_name.7e8d31ebe5"
[0m18:32:40.632920 [debug] [Thread-2 (]: Using snowflake connection "test.data_ai_index.not_null_dim_technologies_technology_name.7e8d31ebe5"
[0m18:32:40.633490 [debug] [Thread-2 (]: On test.data_ai_index.not_null_dim_technologies_technology_name.7e8d31ebe5: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select technology_name
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_technologies
where technology_name is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_dim_technologies_technology_name.7e8d31ebe5"} */
[0m18:32:40.635890 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 2.912 seconds
[0m18:32:40.638810 [info ] [Thread-4 (]: 4 of 49 PASS not_null_dim_roles_role_name ...................................... [[32mPASS[0m in 3.09s]
[0m18:32:40.640491 [debug] [Thread-4 (]: Finished running node test.data_ai_index.not_null_dim_roles_role_name.aafac91aed
[0m18:32:40.641393 [debug] [Thread-4 (]: Began running node test.data_ai_index.not_null_fct_github_repo_stats_category.a938b3c1b3
[0m18:32:40.642224 [info ] [Thread-4 (]: 7 of 49 START test not_null_fct_github_repo_stats_category ..................... [RUN]
[0m18:32:40.643177 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_dim_roles_role_name.aafac91aed, now test.data_ai_index.not_null_fct_github_repo_stats_category.a938b3c1b3)
[0m18:32:40.644143 [debug] [Thread-4 (]: Began compiling node test.data_ai_index.not_null_fct_github_repo_stats_category.a938b3c1b3
[0m18:32:40.651783 [debug] [Thread-4 (]: Writing injected SQL for node "test.data_ai_index.not_null_fct_github_repo_stats_category.a938b3c1b3"
[0m18:32:40.652946 [debug] [Thread-4 (]: Began executing node test.data_ai_index.not_null_fct_github_repo_stats_category.a938b3c1b3
[0m18:32:40.656639 [debug] [Thread-4 (]: Writing runtime sql for node "test.data_ai_index.not_null_fct_github_repo_stats_category.a938b3c1b3"
[0m18:32:40.658237 [debug] [Thread-4 (]: Using snowflake connection "test.data_ai_index.not_null_fct_github_repo_stats_category.a938b3c1b3"
[0m18:32:40.658972 [debug] [Thread-4 (]: On test.data_ai_index.not_null_fct_github_repo_stats_category.a938b3c1b3: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select category
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats
where category is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_fct_github_repo_stats_category.a938b3c1b3"} */
[0m18:32:40.722287 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2.995 seconds
[0m18:32:40.725049 [info ] [Thread-1 (]: 1 of 49 PASS accepted_values_dim_roles_tier__1__2__3__4__5 ..................... [[32mPASS[0m in 3.18s]
[0m18:32:40.725853 [debug] [Thread-1 (]: Finished running node test.data_ai_index.accepted_values_dim_roles_tier__1__2__3__4__5.cee9b4d79c
[0m18:32:40.726683 [debug] [Thread-1 (]: Began running node test.data_ai_index.not_null_fct_github_repo_stats_repo_id.c1b60ad944
[0m18:32:40.727490 [info ] [Thread-1 (]: 8 of 49 START test not_null_fct_github_repo_stats_repo_id ...................... [RUN]
[0m18:32:40.728209 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_ai_index.accepted_values_dim_roles_tier__1__2__3__4__5.cee9b4d79c, now test.data_ai_index.not_null_fct_github_repo_stats_repo_id.c1b60ad944)
[0m18:32:40.728943 [debug] [Thread-1 (]: Began compiling node test.data_ai_index.not_null_fct_github_repo_stats_repo_id.c1b60ad944
[0m18:32:40.735152 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_ai_index.not_null_fct_github_repo_stats_repo_id.c1b60ad944"
[0m18:32:40.736113 [debug] [Thread-1 (]: Began executing node test.data_ai_index.not_null_fct_github_repo_stats_repo_id.c1b60ad944
[0m18:32:40.739423 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_ai_index.not_null_fct_github_repo_stats_repo_id.c1b60ad944"
[0m18:32:40.740775 [debug] [Thread-1 (]: Using snowflake connection "test.data_ai_index.not_null_fct_github_repo_stats_repo_id.c1b60ad944"
[0m18:32:40.741751 [debug] [Thread-1 (]: On test.data_ai_index.not_null_fct_github_repo_stats_repo_id.c1b60ad944: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select repo_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats
where repo_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_fct_github_repo_stats_repo_id.c1b60ad944"} */
[0m18:32:40.829275 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.230 seconds
[0m18:32:40.833556 [info ] [Thread-3 (]: 5 of 49 PASS not_null_dim_technologies_technology_id ........................... [[32mPASS[0m in 0.25s]
[0m18:32:40.834475 [debug] [Thread-3 (]: Finished running node test.data_ai_index.not_null_dim_technologies_technology_id.29429ee493
[0m18:32:40.835089 [debug] [Thread-3 (]: Began running node test.data_ai_index.not_null_fct_hn_role_mentions_mention_id.26534bf507
[0m18:32:40.835569 [info ] [Thread-3 (]: 9 of 49 START test not_null_fct_hn_role_mentions_mention_id .................... [RUN]
[0m18:32:40.836091 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_dim_technologies_technology_id.29429ee493, now test.data_ai_index.not_null_fct_hn_role_mentions_mention_id.26534bf507)
[0m18:32:40.836569 [debug] [Thread-3 (]: Began compiling node test.data_ai_index.not_null_fct_hn_role_mentions_mention_id.26534bf507
[0m18:32:40.842428 [debug] [Thread-3 (]: Writing injected SQL for node "test.data_ai_index.not_null_fct_hn_role_mentions_mention_id.26534bf507"
[0m18:32:40.843797 [debug] [Thread-3 (]: Began executing node test.data_ai_index.not_null_fct_hn_role_mentions_mention_id.26534bf507
[0m18:32:40.847229 [debug] [Thread-3 (]: Writing runtime sql for node "test.data_ai_index.not_null_fct_hn_role_mentions_mention_id.26534bf507"
[0m18:32:40.848738 [debug] [Thread-3 (]: Using snowflake connection "test.data_ai_index.not_null_fct_hn_role_mentions_mention_id.26534bf507"
[0m18:32:40.849397 [debug] [Thread-3 (]: On test.data_ai_index.not_null_fct_hn_role_mentions_mention_id.26534bf507: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select mention_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_hn_role_mentions
where mention_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_fct_hn_role_mentions_mention_id.26534bf507"} */
[0m18:32:40.910434 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.168 seconds
[0m18:32:40.913429 [info ] [Thread-1 (]: 8 of 49 PASS not_null_fct_github_repo_stats_repo_id ............................ [[32mPASS[0m in 0.19s]
[0m18:32:40.914434 [debug] [Thread-1 (]: Finished running node test.data_ai_index.not_null_fct_github_repo_stats_repo_id.c1b60ad944
[0m18:32:40.914940 [debug] [Thread-1 (]: Began running node test.data_ai_index.not_null_fct_hn_role_mentions_posting_id.3d650797ef
[0m18:32:40.915369 [info ] [Thread-1 (]: 10 of 49 START test not_null_fct_hn_role_mentions_posting_id ................... [RUN]
[0m18:32:40.916680 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_fct_github_repo_stats_repo_id.c1b60ad944, now test.data_ai_index.not_null_fct_hn_role_mentions_posting_id.3d650797ef)
[0m18:32:40.917473 [debug] [Thread-1 (]: Began compiling node test.data_ai_index.not_null_fct_hn_role_mentions_posting_id.3d650797ef
[0m18:32:40.929529 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_ai_index.not_null_fct_hn_role_mentions_posting_id.3d650797ef"
[0m18:32:40.932939 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.299 seconds
[0m18:32:40.936740 [info ] [Thread-2 (]: 6 of 49 PASS not_null_dim_technologies_technology_name ......................... [[32mPASS[0m in 0.32s]
[0m18:32:40.938016 [debug] [Thread-2 (]: Finished running node test.data_ai_index.not_null_dim_technologies_technology_name.7e8d31ebe5
[0m18:32:40.939344 [debug] [Thread-2 (]: Began running node test.data_ai_index.not_null_fct_hn_technology_mentions_mention_id.f6ebed3cb8
[0m18:32:40.941344 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.281 seconds
[0m18:32:40.942622 [info ] [Thread-2 (]: 11 of 49 START test not_null_fct_hn_technology_mentions_mention_id ............. [RUN]
[0m18:32:40.962171 [debug] [Thread-1 (]: Began executing node test.data_ai_index.not_null_fct_hn_role_mentions_posting_id.3d650797ef
[0m18:32:40.960961 [info ] [Thread-4 (]: 7 of 49 PASS not_null_fct_github_repo_stats_category ........................... [[32mPASS[0m in 0.32s]
[0m18:32:40.964754 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_dim_technologies_technology_name.7e8d31ebe5, now test.data_ai_index.not_null_fct_hn_technology_mentions_mention_id.f6ebed3cb8)
[0m18:32:40.992855 [debug] [Thread-4 (]: Finished running node test.data_ai_index.not_null_fct_github_repo_stats_category.a938b3c1b3
[0m18:32:40.996236 [debug] [Thread-2 (]: Began compiling node test.data_ai_index.not_null_fct_hn_technology_mentions_mention_id.f6ebed3cb8
[0m18:32:41.008948 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_ai_index.not_null_fct_hn_role_mentions_posting_id.3d650797ef"
[0m18:32:41.030688 [debug] [Thread-4 (]: Began running node test.data_ai_index.not_null_fct_hn_technology_mentions_posting_id.3398f9fdfa
[0m18:32:41.040915 [debug] [Thread-2 (]: Writing injected SQL for node "test.data_ai_index.not_null_fct_hn_technology_mentions_mention_id.f6ebed3cb8"
[0m18:32:41.042094 [info ] [Thread-4 (]: 12 of 49 START test not_null_fct_hn_technology_mentions_posting_id ............. [RUN]
[0m18:32:41.043545 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_fct_github_repo_stats_category.a938b3c1b3, now test.data_ai_index.not_null_fct_hn_technology_mentions_posting_id.3398f9fdfa)
[0m18:32:41.044350 [debug] [Thread-4 (]: Began compiling node test.data_ai_index.not_null_fct_hn_technology_mentions_posting_id.3398f9fdfa
[0m18:32:41.051943 [debug] [Thread-1 (]: Using snowflake connection "test.data_ai_index.not_null_fct_hn_role_mentions_posting_id.3d650797ef"
[0m18:32:41.053172 [debug] [Thread-4 (]: Writing injected SQL for node "test.data_ai_index.not_null_fct_hn_technology_mentions_posting_id.3398f9fdfa"
[0m18:32:41.054384 [debug] [Thread-1 (]: On test.data_ai_index.not_null_fct_hn_role_mentions_posting_id.3d650797ef: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select posting_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_hn_role_mentions
where posting_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_fct_hn_role_mentions_posting_id.3d650797ef"} */
[0m18:32:41.055912 [debug] [Thread-2 (]: Began executing node test.data_ai_index.not_null_fct_hn_technology_mentions_mention_id.f6ebed3cb8
[0m18:32:41.067545 [debug] [Thread-2 (]: Writing runtime sql for node "test.data_ai_index.not_null_fct_hn_technology_mentions_mention_id.f6ebed3cb8"
[0m18:32:41.070877 [debug] [Thread-4 (]: Began executing node test.data_ai_index.not_null_fct_hn_technology_mentions_posting_id.3398f9fdfa
[0m18:32:41.074301 [debug] [Thread-4 (]: Writing runtime sql for node "test.data_ai_index.not_null_fct_hn_technology_mentions_posting_id.3398f9fdfa"
[0m18:32:41.075540 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.225 seconds
[0m18:32:41.078980 [info ] [Thread-3 (]: 9 of 49 PASS not_null_fct_hn_role_mentions_mention_id .......................... [[32mPASS[0m in 0.24s]
[0m18:32:41.080342 [debug] [Thread-3 (]: Finished running node test.data_ai_index.not_null_fct_hn_role_mentions_mention_id.26534bf507
[0m18:32:41.081180 [debug] [Thread-3 (]: Began running node test.data_ai_index.not_null_fct_hn_technology_mentions_technology_name.2dcbc36ce7
[0m18:32:41.083943 [debug] [Thread-2 (]: Using snowflake connection "test.data_ai_index.not_null_fct_hn_technology_mentions_mention_id.f6ebed3cb8"
[0m18:32:41.081901 [info ] [Thread-3 (]: 13 of 49 START test not_null_fct_hn_technology_mentions_technology_name ........ [RUN]
[0m18:32:41.084942 [debug] [Thread-2 (]: On test.data_ai_index.not_null_fct_hn_technology_mentions_mention_id.f6ebed3cb8: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select mention_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_hn_technology_mentions
where mention_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_fct_hn_technology_mentions_mention_id.f6ebed3cb8"} */
[0m18:32:41.085981 [debug] [Thread-4 (]: Using snowflake connection "test.data_ai_index.not_null_fct_hn_technology_mentions_posting_id.3398f9fdfa"
[0m18:32:41.086662 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_fct_hn_role_mentions_mention_id.26534bf507, now test.data_ai_index.not_null_fct_hn_technology_mentions_technology_name.2dcbc36ce7)
[0m18:32:41.088373 [debug] [Thread-4 (]: On test.data_ai_index.not_null_fct_hn_technology_mentions_posting_id.3398f9fdfa: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select posting_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_hn_technology_mentions
where posting_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_fct_hn_technology_mentions_posting_id.3398f9fdfa"} */
[0m18:32:41.089713 [debug] [Thread-3 (]: Began compiling node test.data_ai_index.not_null_fct_hn_technology_mentions_technology_name.2dcbc36ce7
[0m18:32:41.097185 [debug] [Thread-3 (]: Writing injected SQL for node "test.data_ai_index.not_null_fct_hn_technology_mentions_technology_name.2dcbc36ce7"
[0m18:32:41.101621 [debug] [Thread-3 (]: Began executing node test.data_ai_index.not_null_fct_hn_technology_mentions_technology_name.2dcbc36ce7
[0m18:32:41.107633 [debug] [Thread-3 (]: Writing runtime sql for node "test.data_ai_index.not_null_fct_hn_technology_mentions_technology_name.2dcbc36ce7"
[0m18:32:41.111304 [debug] [Thread-3 (]: Using snowflake connection "test.data_ai_index.not_null_fct_hn_technology_mentions_technology_name.2dcbc36ce7"
[0m18:32:41.112390 [debug] [Thread-3 (]: On test.data_ai_index.not_null_fct_hn_technology_mentions_technology_name.2dcbc36ce7: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select technology_name
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_hn_technology_mentions
where technology_name is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_fct_hn_technology_mentions_technology_name.2dcbc36ce7"} */
[0m18:32:41.267841 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.177 seconds
[0m18:32:41.270860 [info ] [Thread-4 (]: 12 of 49 PASS not_null_fct_hn_technology_mentions_posting_id ................... [[32mPASS[0m in 0.23s]
[0m18:32:41.273035 [debug] [Thread-4 (]: Finished running node test.data_ai_index.not_null_fct_hn_technology_mentions_posting_id.3398f9fdfa
[0m18:32:41.274015 [debug] [Thread-4 (]: Began running node test.data_ai_index.not_null_fct_linkedin_skill_counts_skill_name.21873086a3
[0m18:32:41.275684 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.162 seconds
[0m18:32:41.276803 [info ] [Thread-4 (]: 14 of 49 START test not_null_fct_linkedin_skill_counts_skill_name .............. [RUN]
[0m18:32:41.281592 [info ] [Thread-3 (]: 13 of 49 PASS not_null_fct_hn_technology_mentions_technology_name .............. [[32mPASS[0m in 0.19s]
[0m18:32:41.285638 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.198 seconds
[0m18:32:41.287141 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_fct_hn_technology_mentions_posting_id.3398f9fdfa, now test.data_ai_index.not_null_fct_linkedin_skill_counts_skill_name.21873086a3)
[0m18:32:41.288842 [debug] [Thread-3 (]: Finished running node test.data_ai_index.not_null_fct_hn_technology_mentions_technology_name.2dcbc36ce7
[0m18:32:41.295846 [info ] [Thread-2 (]: 11 of 49 PASS not_null_fct_hn_technology_mentions_mention_id ................... [[32mPASS[0m in 0.33s]
[0m18:32:41.298373 [debug] [Thread-4 (]: Began compiling node test.data_ai_index.not_null_fct_linkedin_skill_counts_skill_name.21873086a3
[0m18:32:41.299702 [debug] [Thread-3 (]: Began running node test.data_ai_index.not_null_fct_monthly_role_trends_posting_month.1acae59e87
[0m18:32:41.301477 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.244 seconds
[0m18:32:41.303088 [debug] [Thread-2 (]: Finished running node test.data_ai_index.not_null_fct_hn_technology_mentions_mention_id.f6ebed3cb8
[0m18:32:41.313901 [debug] [Thread-4 (]: Writing injected SQL for node "test.data_ai_index.not_null_fct_linkedin_skill_counts_skill_name.21873086a3"
[0m18:32:41.315021 [info ] [Thread-3 (]: 15 of 49 START test not_null_fct_monthly_role_trends_posting_month ............. [RUN]
[0m18:32:41.319897 [info ] [Thread-1 (]: 10 of 49 PASS not_null_fct_hn_role_mentions_posting_id ......................... [[32mPASS[0m in 0.40s]
[0m18:32:41.320655 [debug] [Thread-2 (]: Began running node test.data_ai_index.not_null_fct_monthly_role_trends_role_name.e45072c198
[0m18:32:41.321719 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_fct_hn_technology_mentions_technology_name.2dcbc36ce7, now test.data_ai_index.not_null_fct_monthly_role_trends_posting_month.1acae59e87)
[0m18:32:41.323128 [debug] [Thread-1 (]: Finished running node test.data_ai_index.not_null_fct_hn_role_mentions_posting_id.3d650797ef
[0m18:32:41.324069 [info ] [Thread-2 (]: 16 of 49 START test not_null_fct_monthly_role_trends_role_name ................. [RUN]
[0m18:32:41.325100 [debug] [Thread-4 (]: Began executing node test.data_ai_index.not_null_fct_linkedin_skill_counts_skill_name.21873086a3
[0m18:32:41.325783 [debug] [Thread-3 (]: Began compiling node test.data_ai_index.not_null_fct_monthly_role_trends_posting_month.1acae59e87
[0m18:32:41.326905 [debug] [Thread-1 (]: Began running node test.data_ai_index.not_null_fct_monthly_technology_trends_posting_month.8df333d81f
[0m18:32:41.327825 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_fct_hn_technology_mentions_mention_id.f6ebed3cb8, now test.data_ai_index.not_null_fct_monthly_role_trends_role_name.e45072c198)
[0m18:32:41.332231 [debug] [Thread-4 (]: Writing runtime sql for node "test.data_ai_index.not_null_fct_linkedin_skill_counts_skill_name.21873086a3"
[0m18:32:41.338567 [debug] [Thread-3 (]: Writing injected SQL for node "test.data_ai_index.not_null_fct_monthly_role_trends_posting_month.1acae59e87"
[0m18:32:41.339788 [info ] [Thread-1 (]: 17 of 49 START test not_null_fct_monthly_technology_trends_posting_month ....... [RUN]
[0m18:32:41.340907 [debug] [Thread-2 (]: Began compiling node test.data_ai_index.not_null_fct_monthly_role_trends_role_name.e45072c198
[0m18:32:41.343143 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_fct_hn_role_mentions_posting_id.3d650797ef, now test.data_ai_index.not_null_fct_monthly_technology_trends_posting_month.8df333d81f)
[0m18:32:41.348364 [debug] [Thread-2 (]: Writing injected SQL for node "test.data_ai_index.not_null_fct_monthly_role_trends_role_name.e45072c198"
[0m18:32:41.349905 [debug] [Thread-3 (]: Began executing node test.data_ai_index.not_null_fct_monthly_role_trends_posting_month.1acae59e87
[0m18:32:41.350875 [debug] [Thread-4 (]: Using snowflake connection "test.data_ai_index.not_null_fct_linkedin_skill_counts_skill_name.21873086a3"
[0m18:32:41.351725 [debug] [Thread-1 (]: Began compiling node test.data_ai_index.not_null_fct_monthly_technology_trends_posting_month.8df333d81f
[0m18:32:41.358266 [debug] [Thread-3 (]: Writing runtime sql for node "test.data_ai_index.not_null_fct_monthly_role_trends_posting_month.1acae59e87"
[0m18:32:41.359492 [debug] [Thread-4 (]: On test.data_ai_index.not_null_fct_linkedin_skill_counts_skill_name.21873086a3: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select skill_name
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_linkedin_skill_counts
where skill_name is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_fct_linkedin_skill_counts_skill_name.21873086a3"} */
[0m18:32:41.366270 [debug] [Thread-2 (]: Began executing node test.data_ai_index.not_null_fct_monthly_role_trends_role_name.e45072c198
[0m18:32:41.369956 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_ai_index.not_null_fct_monthly_technology_trends_posting_month.8df333d81f"
[0m18:32:41.375006 [debug] [Thread-2 (]: Writing runtime sql for node "test.data_ai_index.not_null_fct_monthly_role_trends_role_name.e45072c198"
[0m18:32:41.377735 [debug] [Thread-3 (]: Using snowflake connection "test.data_ai_index.not_null_fct_monthly_role_trends_posting_month.1acae59e87"
[0m18:32:41.379924 [debug] [Thread-3 (]: On test.data_ai_index.not_null_fct_monthly_role_trends_posting_month.1acae59e87: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select posting_month
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_monthly_role_trends
where posting_month is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_fct_monthly_role_trends_posting_month.1acae59e87"} */
[0m18:32:41.381974 [debug] [Thread-1 (]: Began executing node test.data_ai_index.not_null_fct_monthly_technology_trends_posting_month.8df333d81f
[0m18:32:41.385254 [debug] [Thread-2 (]: Using snowflake connection "test.data_ai_index.not_null_fct_monthly_role_trends_role_name.e45072c198"
[0m18:32:41.389251 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_ai_index.not_null_fct_monthly_technology_trends_posting_month.8df333d81f"
[0m18:32:41.390123 [debug] [Thread-2 (]: On test.data_ai_index.not_null_fct_monthly_role_trends_role_name.e45072c198: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select role_name
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_monthly_role_trends
where role_name is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_fct_monthly_role_trends_role_name.e45072c198"} */
[0m18:32:41.395521 [debug] [Thread-1 (]: Using snowflake connection "test.data_ai_index.not_null_fct_monthly_technology_trends_posting_month.8df333d81f"
[0m18:32:41.397163 [debug] [Thread-1 (]: On test.data_ai_index.not_null_fct_monthly_technology_trends_posting_month.8df333d81f: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select posting_month
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_monthly_technology_trends
where posting_month is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_fct_monthly_technology_trends_posting_month.8df333d81f"} */
[0m18:32:41.578020 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.197 seconds
[0m18:32:41.583482 [info ] [Thread-3 (]: 15 of 49 PASS not_null_fct_monthly_role_trends_posting_month ................... [[32mPASS[0m in 0.26s]
[0m18:32:41.584878 [debug] [Thread-3 (]: Finished running node test.data_ai_index.not_null_fct_monthly_role_trends_posting_month.1acae59e87
[0m18:32:41.585454 [debug] [Thread-3 (]: Began running node test.data_ai_index.not_null_fct_monthly_technology_trends_technology_name.482912e896
[0m18:32:41.586142 [info ] [Thread-3 (]: 18 of 49 START test not_null_fct_monthly_technology_trends_technology_name ..... [RUN]
[0m18:32:41.586789 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_fct_monthly_role_trends_posting_month.1acae59e87, now test.data_ai_index.not_null_fct_monthly_technology_trends_technology_name.482912e896)
[0m18:32:41.587319 [debug] [Thread-3 (]: Began compiling node test.data_ai_index.not_null_fct_monthly_technology_trends_technology_name.482912e896
[0m18:32:41.594843 [debug] [Thread-3 (]: Writing injected SQL for node "test.data_ai_index.not_null_fct_monthly_technology_trends_technology_name.482912e896"
[0m18:32:41.598222 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.204 seconds
[0m18:32:41.602976 [info ] [Thread-2 (]: 16 of 49 PASS not_null_fct_monthly_role_trends_role_name ....................... [[32mPASS[0m in 0.27s]
[0m18:32:41.604401 [debug] [Thread-2 (]: Finished running node test.data_ai_index.not_null_fct_monthly_role_trends_role_name.e45072c198
[0m18:32:41.605343 [debug] [Thread-3 (]: Began executing node test.data_ai_index.not_null_fct_monthly_technology_trends_technology_name.482912e896
[0m18:32:41.606262 [debug] [Thread-2 (]: Began running node test.data_ai_index.not_null_int_hn__databases_extracted_database_name.9c18ac0b89
[0m18:32:41.612556 [debug] [Thread-3 (]: Writing runtime sql for node "test.data_ai_index.not_null_fct_monthly_technology_trends_technology_name.482912e896"
[0m18:32:41.614562 [info ] [Thread-2 (]: 19 of 49 START test not_null_int_hn__databases_extracted_database_name ......... [RUN]
[0m18:32:41.616557 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.218 seconds
[0m18:32:41.617630 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_fct_monthly_role_trends_role_name.e45072c198, now test.data_ai_index.not_null_int_hn__databases_extracted_database_name.9c18ac0b89)
[0m18:32:41.620096 [info ] [Thread-1 (]: 17 of 49 PASS not_null_fct_monthly_technology_trends_posting_month ............. [[32mPASS[0m in 0.28s]
[0m18:32:41.620897 [debug] [Thread-2 (]: Began compiling node test.data_ai_index.not_null_int_hn__databases_extracted_database_name.9c18ac0b89
[0m18:32:41.622296 [debug] [Thread-1 (]: Finished running node test.data_ai_index.not_null_fct_monthly_technology_trends_posting_month.8df333d81f
[0m18:32:41.623474 [debug] [Thread-3 (]: Using snowflake connection "test.data_ai_index.not_null_fct_monthly_technology_trends_technology_name.482912e896"
[0m18:32:41.633543 [debug] [Thread-2 (]: Writing injected SQL for node "test.data_ai_index.not_null_int_hn__databases_extracted_database_name.9c18ac0b89"
[0m18:32:41.634234 [debug] [Thread-1 (]: Began running node test.data_ai_index.not_null_int_hn__databases_extracted_posting_id.b3a3077dc0
[0m18:32:41.634939 [debug] [Thread-3 (]: On test.data_ai_index.not_null_fct_monthly_technology_trends_technology_name.482912e896: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select technology_name
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_monthly_technology_trends
where technology_name is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_fct_monthly_technology_trends_technology_name.482912e896"} */
[0m18:32:41.636278 [info ] [Thread-1 (]: 20 of 49 START test not_null_int_hn__databases_extracted_posting_id ............ [RUN]
[0m18:32:41.638089 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_fct_monthly_technology_trends_posting_month.8df333d81f, now test.data_ai_index.not_null_int_hn__databases_extracted_posting_id.b3a3077dc0)
[0m18:32:41.638992 [debug] [Thread-1 (]: Began compiling node test.data_ai_index.not_null_int_hn__databases_extracted_posting_id.b3a3077dc0
[0m18:32:41.639611 [debug] [Thread-2 (]: Began executing node test.data_ai_index.not_null_int_hn__databases_extracted_database_name.9c18ac0b89
[0m18:32:41.652546 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_ai_index.not_null_int_hn__databases_extracted_posting_id.b3a3077dc0"
[0m18:32:41.662993 [debug] [Thread-2 (]: Writing runtime sql for node "test.data_ai_index.not_null_int_hn__databases_extracted_database_name.9c18ac0b89"
[0m18:32:41.666981 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.296 seconds
[0m18:32:41.671043 [info ] [Thread-4 (]: 14 of 49 PASS not_null_fct_linkedin_skill_counts_skill_name .................... [[32mPASS[0m in 0.38s]
[0m18:32:41.671854 [debug] [Thread-1 (]: Began executing node test.data_ai_index.not_null_int_hn__databases_extracted_posting_id.b3a3077dc0
[0m18:32:41.673719 [debug] [Thread-2 (]: Using snowflake connection "test.data_ai_index.not_null_int_hn__databases_extracted_database_name.9c18ac0b89"
[0m18:32:41.675593 [debug] [Thread-4 (]: Finished running node test.data_ai_index.not_null_fct_linkedin_skill_counts_skill_name.21873086a3
[0m18:32:41.680510 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_ai_index.not_null_int_hn__databases_extracted_posting_id.b3a3077dc0"
[0m18:32:41.681678 [debug] [Thread-2 (]: On test.data_ai_index.not_null_int_hn__databases_extracted_database_name.9c18ac0b89: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select database_name
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_hn__databases_extracted
where database_name is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_int_hn__databases_extracted_database_name.9c18ac0b89"} */
[0m18:32:41.682676 [debug] [Thread-4 (]: Began running node test.data_ai_index.not_null_int_hn__roles_extracted_posting_id.4e4db2cb51
[0m18:32:41.684356 [info ] [Thread-4 (]: 21 of 49 START test not_null_int_hn__roles_extracted_posting_id ................ [RUN]
[0m18:32:41.685098 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_fct_linkedin_skill_counts_skill_name.21873086a3, now test.data_ai_index.not_null_int_hn__roles_extracted_posting_id.4e4db2cb51)
[0m18:32:41.685620 [debug] [Thread-4 (]: Began compiling node test.data_ai_index.not_null_int_hn__roles_extracted_posting_id.4e4db2cb51
[0m18:32:41.694458 [debug] [Thread-4 (]: Writing injected SQL for node "test.data_ai_index.not_null_int_hn__roles_extracted_posting_id.4e4db2cb51"
[0m18:32:41.696071 [debug] [Thread-1 (]: Using snowflake connection "test.data_ai_index.not_null_int_hn__databases_extracted_posting_id.b3a3077dc0"
[0m18:32:41.697392 [debug] [Thread-1 (]: On test.data_ai_index.not_null_int_hn__databases_extracted_posting_id.b3a3077dc0: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select posting_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_hn__databases_extracted
where posting_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_int_hn__databases_extracted_posting_id.b3a3077dc0"} */
[0m18:32:41.698754 [debug] [Thread-4 (]: Began executing node test.data_ai_index.not_null_int_hn__roles_extracted_posting_id.4e4db2cb51
[0m18:32:41.703439 [debug] [Thread-4 (]: Writing runtime sql for node "test.data_ai_index.not_null_int_hn__roles_extracted_posting_id.4e4db2cb51"
[0m18:32:41.706760 [debug] [Thread-4 (]: Using snowflake connection "test.data_ai_index.not_null_int_hn__roles_extracted_posting_id.4e4db2cb51"
[0m18:32:41.708755 [debug] [Thread-4 (]: On test.data_ai_index.not_null_int_hn__roles_extracted_posting_id.4e4db2cb51: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select posting_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_hn__roles_extracted
where posting_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_int_hn__roles_extracted_posting_id.4e4db2cb51"} */
[0m18:32:41.849597 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.166 seconds
[0m18:32:41.853773 [info ] [Thread-2 (]: 19 of 49 PASS not_null_int_hn__databases_extracted_database_name ............... [[32mPASS[0m in 0.24s]
[0m18:32:41.855510 [debug] [Thread-2 (]: Finished running node test.data_ai_index.not_null_int_hn__databases_extracted_database_name.9c18ac0b89
[0m18:32:41.859329 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.161 seconds
[0m18:32:41.860834 [debug] [Thread-2 (]: Began running node test.data_ai_index.not_null_int_hn__roles_extracted_role.5b48e7b8b0
[0m18:32:41.863251 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.225 seconds
[0m18:32:41.868259 [info ] [Thread-1 (]: 20 of 49 PASS not_null_int_hn__databases_extracted_posting_id .................. [[32mPASS[0m in 0.23s]
[0m18:32:41.869135 [info ] [Thread-2 (]: 22 of 49 START test not_null_int_hn__roles_extracted_role ...................... [RUN]
[0m18:32:41.872413 [info ] [Thread-3 (]: 18 of 49 PASS not_null_fct_monthly_technology_trends_technology_name ........... [[32mPASS[0m in 0.29s]
[0m18:32:41.873387 [debug] [Thread-1 (]: Finished running node test.data_ai_index.not_null_int_hn__databases_extracted_posting_id.b3a3077dc0
[0m18:32:41.874113 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_int_hn__databases_extracted_database_name.9c18ac0b89, now test.data_ai_index.not_null_int_hn__roles_extracted_role.5b48e7b8b0)
[0m18:32:41.875259 [debug] [Thread-3 (]: Finished running node test.data_ai_index.not_null_fct_monthly_technology_trends_technology_name.482912e896
[0m18:32:41.876178 [debug] [Thread-1 (]: Began running node test.data_ai_index.not_null_int_hn__technologies_extracted_posting_id.47ca486602
[0m18:32:41.876824 [debug] [Thread-2 (]: Began compiling node test.data_ai_index.not_null_int_hn__roles_extracted_role.5b48e7b8b0
[0m18:32:41.877437 [debug] [Thread-3 (]: Began running node test.data_ai_index.not_null_int_hn__technologies_extracted_technology.0c38928f13
[0m18:32:41.877930 [info ] [Thread-1 (]: 23 of 49 START test not_null_int_hn__technologies_extracted_posting_id ......... [RUN]
[0m18:32:41.884952 [info ] [Thread-3 (]: 24 of 49 START test not_null_int_hn__technologies_extracted_technology ......... [RUN]
[0m18:32:41.891446 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_int_hn__databases_extracted_posting_id.b3a3077dc0, now test.data_ai_index.not_null_int_hn__technologies_extracted_posting_id.47ca486602)
[0m18:32:41.896677 [debug] [Thread-2 (]: Writing injected SQL for node "test.data_ai_index.not_null_int_hn__roles_extracted_role.5b48e7b8b0"
[0m18:32:41.897463 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_fct_monthly_technology_trends_technology_name.482912e896, now test.data_ai_index.not_null_int_hn__technologies_extracted_technology.0c38928f13)
[0m18:32:41.899670 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.190 seconds
[0m18:32:41.900237 [debug] [Thread-1 (]: Began compiling node test.data_ai_index.not_null_int_hn__technologies_extracted_posting_id.47ca486602
[0m18:32:41.901210 [debug] [Thread-3 (]: Began compiling node test.data_ai_index.not_null_int_hn__technologies_extracted_technology.0c38928f13
[0m18:32:41.905426 [info ] [Thread-4 (]: 21 of 49 PASS not_null_int_hn__roles_extracted_posting_id ...................... [[32mPASS[0m in 0.22s]
[0m18:32:41.916049 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_ai_index.not_null_int_hn__technologies_extracted_posting_id.47ca486602"
[0m18:32:41.922677 [debug] [Thread-3 (]: Writing injected SQL for node "test.data_ai_index.not_null_int_hn__technologies_extracted_technology.0c38928f13"
[0m18:32:41.923742 [debug] [Thread-4 (]: Finished running node test.data_ai_index.not_null_int_hn__roles_extracted_posting_id.4e4db2cb51
[0m18:32:41.924571 [debug] [Thread-2 (]: Began executing node test.data_ai_index.not_null_int_hn__roles_extracted_role.5b48e7b8b0
[0m18:32:41.926422 [debug] [Thread-4 (]: Began running node test.data_ai_index.not_null_int_linkedin__skills_standardized_posting_id.252442d199
[0m18:32:41.930960 [debug] [Thread-2 (]: Writing runtime sql for node "test.data_ai_index.not_null_int_hn__roles_extracted_role.5b48e7b8b0"
[0m18:32:41.931787 [info ] [Thread-4 (]: 25 of 49 START test not_null_int_linkedin__skills_standardized_posting_id ...... [RUN]
[0m18:32:41.932887 [debug] [Thread-3 (]: Began executing node test.data_ai_index.not_null_int_hn__technologies_extracted_technology.0c38928f13
[0m18:32:41.933373 [debug] [Thread-1 (]: Began executing node test.data_ai_index.not_null_int_hn__technologies_extracted_posting_id.47ca486602
[0m18:32:41.934145 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_int_hn__roles_extracted_posting_id.4e4db2cb51, now test.data_ai_index.not_null_int_linkedin__skills_standardized_posting_id.252442d199)
[0m18:32:41.938160 [debug] [Thread-3 (]: Writing runtime sql for node "test.data_ai_index.not_null_int_hn__technologies_extracted_technology.0c38928f13"
[0m18:32:41.943090 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_ai_index.not_null_int_hn__technologies_extracted_posting_id.47ca486602"
[0m18:32:41.944002 [debug] [Thread-4 (]: Began compiling node test.data_ai_index.not_null_int_linkedin__skills_standardized_posting_id.252442d199
[0m18:32:41.945577 [debug] [Thread-2 (]: Using snowflake connection "test.data_ai_index.not_null_int_hn__roles_extracted_role.5b48e7b8b0"
[0m18:32:41.953095 [debug] [Thread-3 (]: Using snowflake connection "test.data_ai_index.not_null_int_hn__technologies_extracted_technology.0c38928f13"
[0m18:32:41.955854 [debug] [Thread-4 (]: Writing injected SQL for node "test.data_ai_index.not_null_int_linkedin__skills_standardized_posting_id.252442d199"
[0m18:32:41.956977 [debug] [Thread-2 (]: On test.data_ai_index.not_null_int_hn__roles_extracted_role.5b48e7b8b0: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select role
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_hn__roles_extracted
where role is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_int_hn__roles_extracted_role.5b48e7b8b0"} */
[0m18:32:41.958876 [debug] [Thread-1 (]: Using snowflake connection "test.data_ai_index.not_null_int_hn__technologies_extracted_posting_id.47ca486602"
[0m18:32:41.959907 [debug] [Thread-3 (]: On test.data_ai_index.not_null_int_hn__technologies_extracted_technology.0c38928f13: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select technology
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_hn__technologies_extracted
where technology is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_int_hn__technologies_extracted_technology.0c38928f13"} */
[0m18:32:41.962582 [debug] [Thread-1 (]: On test.data_ai_index.not_null_int_hn__technologies_extracted_posting_id.47ca486602: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select posting_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_hn__technologies_extracted
where posting_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_int_hn__technologies_extracted_posting_id.47ca486602"} */
[0m18:32:41.965548 [debug] [Thread-4 (]: Began executing node test.data_ai_index.not_null_int_linkedin__skills_standardized_posting_id.252442d199
[0m18:32:41.970238 [debug] [Thread-4 (]: Writing runtime sql for node "test.data_ai_index.not_null_int_linkedin__skills_standardized_posting_id.252442d199"
[0m18:32:41.975862 [debug] [Thread-4 (]: Using snowflake connection "test.data_ai_index.not_null_int_linkedin__skills_standardized_posting_id.252442d199"
[0m18:32:41.977094 [debug] [Thread-4 (]: On test.data_ai_index.not_null_int_linkedin__skills_standardized_posting_id.252442d199: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select posting_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_linkedin__skills_standardized
where posting_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_int_linkedin__skills_standardized_posting_id.252442d199"} */
[0m18:32:42.128912 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.168 seconds
[0m18:32:42.133009 [info ] [Thread-2 (]: 22 of 49 PASS not_null_int_hn__roles_extracted_role ............................ [[32mPASS[0m in 0.26s]
[0m18:32:42.134507 [debug] [Thread-2 (]: Finished running node test.data_ai_index.not_null_int_hn__roles_extracted_role.5b48e7b8b0
[0m18:32:42.135988 [debug] [Thread-2 (]: Began running node test.data_ai_index.not_null_int_linkedin__skills_standardized_skill_name.714de4e628
[0m18:32:42.136780 [info ] [Thread-2 (]: 26 of 49 START test not_null_int_linkedin__skills_standardized_skill_name ...... [RUN]
[0m18:32:42.138828 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.160 seconds
[0m18:32:42.139416 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_int_hn__roles_extracted_role.5b48e7b8b0, now test.data_ai_index.not_null_int_linkedin__skills_standardized_skill_name.714de4e628)
[0m18:32:42.142292 [info ] [Thread-4 (]: 25 of 49 PASS not_null_int_linkedin__skills_standardized_posting_id ............ [[32mPASS[0m in 0.21s]
[0m18:32:42.143164 [debug] [Thread-2 (]: Began compiling node test.data_ai_index.not_null_int_linkedin__skills_standardized_skill_name.714de4e628
[0m18:32:42.143932 [debug] [Thread-4 (]: Finished running node test.data_ai_index.not_null_int_linkedin__skills_standardized_posting_id.252442d199
[0m18:32:42.150289 [debug] [Thread-2 (]: Writing injected SQL for node "test.data_ai_index.not_null_int_linkedin__skills_standardized_skill_name.714de4e628"
[0m18:32:42.151351 [debug] [Thread-4 (]: Began running node test.data_ai_index.not_null_stg_github__repo_stats_category.0bab32271a
[0m18:32:42.152597 [info ] [Thread-4 (]: 27 of 49 START test not_null_stg_github__repo_stats_category ................... [RUN]
[0m18:32:42.153691 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_int_linkedin__skills_standardized_posting_id.252442d199, now test.data_ai_index.not_null_stg_github__repo_stats_category.0bab32271a)
[0m18:32:42.154677 [debug] [Thread-4 (]: Began compiling node test.data_ai_index.not_null_stg_github__repo_stats_category.0bab32271a
[0m18:32:42.161440 [debug] [Thread-2 (]: Began executing node test.data_ai_index.not_null_int_linkedin__skills_standardized_skill_name.714de4e628
[0m18:32:42.166286 [debug] [Thread-4 (]: Writing injected SQL for node "test.data_ai_index.not_null_stg_github__repo_stats_category.0bab32271a"
[0m18:32:42.176749 [debug] [Thread-2 (]: Writing runtime sql for node "test.data_ai_index.not_null_int_linkedin__skills_standardized_skill_name.714de4e628"
[0m18:32:42.179994 [debug] [Thread-4 (]: Began executing node test.data_ai_index.not_null_stg_github__repo_stats_category.0bab32271a
[0m18:32:42.181687 [debug] [Thread-2 (]: Using snowflake connection "test.data_ai_index.not_null_int_linkedin__skills_standardized_skill_name.714de4e628"
[0m18:32:42.185632 [debug] [Thread-4 (]: Writing runtime sql for node "test.data_ai_index.not_null_stg_github__repo_stats_category.0bab32271a"
[0m18:32:42.186281 [debug] [Thread-2 (]: On test.data_ai_index.not_null_int_linkedin__skills_standardized_skill_name.714de4e628: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select skill_name
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_intermediate.int_linkedin__skills_standardized
where skill_name is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_int_linkedin__skills_standardized_skill_name.714de4e628"} */
[0m18:32:42.189478 [debug] [Thread-4 (]: Using snowflake connection "test.data_ai_index.not_null_stg_github__repo_stats_category.0bab32271a"
[0m18:32:42.190284 [debug] [Thread-4 (]: On test.data_ai_index.not_null_stg_github__repo_stats_category.0bab32271a: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select category
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats
where category is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_stg_github__repo_stats_category.0bab32271a"} */
[0m18:32:42.230658 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.264 seconds
[0m18:32:42.233684 [info ] [Thread-1 (]: 23 of 49 PASS not_null_int_hn__technologies_extracted_posting_id ............... [[32mPASS[0m in 0.34s]
[0m18:32:42.234604 [debug] [Thread-1 (]: Finished running node test.data_ai_index.not_null_int_hn__technologies_extracted_posting_id.47ca486602
[0m18:32:42.235165 [debug] [Thread-1 (]: Began running node test.data_ai_index.not_null_stg_github__repo_stats_repo_id.cc3c373a4c
[0m18:32:42.235652 [info ] [Thread-1 (]: 28 of 49 START test not_null_stg_github__repo_stats_repo_id .................... [RUN]
[0m18:32:42.236363 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_int_hn__technologies_extracted_posting_id.47ca486602, now test.data_ai_index.not_null_stg_github__repo_stats_repo_id.cc3c373a4c)
[0m18:32:42.236954 [debug] [Thread-1 (]: Began compiling node test.data_ai_index.not_null_stg_github__repo_stats_repo_id.cc3c373a4c
[0m18:32:42.243856 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_ai_index.not_null_stg_github__repo_stats_repo_id.cc3c373a4c"
[0m18:32:42.245967 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.281 seconds
[0m18:32:42.249448 [info ] [Thread-3 (]: 24 of 49 PASS not_null_int_hn__technologies_extracted_technology ............... [[32mPASS[0m in 0.35s]
[0m18:32:42.250633 [debug] [Thread-3 (]: Finished running node test.data_ai_index.not_null_int_hn__technologies_extracted_technology.0c38928f13
[0m18:32:42.251616 [debug] [Thread-3 (]: Began running node test.data_ai_index.not_null_stg_github__repo_stats_stars.89a30f9950
[0m18:32:42.252586 [debug] [Thread-1 (]: Began executing node test.data_ai_index.not_null_stg_github__repo_stats_repo_id.cc3c373a4c
[0m18:32:42.253512 [info ] [Thread-3 (]: 29 of 49 START test not_null_stg_github__repo_stats_stars ...................... [RUN]
[0m18:32:42.261132 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_ai_index.not_null_stg_github__repo_stats_repo_id.cc3c373a4c"
[0m18:32:42.262267 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_int_hn__technologies_extracted_technology.0c38928f13, now test.data_ai_index.not_null_stg_github__repo_stats_stars.89a30f9950)
[0m18:32:42.263437 [debug] [Thread-3 (]: Began compiling node test.data_ai_index.not_null_stg_github__repo_stats_stars.89a30f9950
[0m18:32:42.277126 [debug] [Thread-1 (]: Using snowflake connection "test.data_ai_index.not_null_stg_github__repo_stats_repo_id.cc3c373a4c"
[0m18:32:42.278001 [debug] [Thread-3 (]: Writing injected SQL for node "test.data_ai_index.not_null_stg_github__repo_stats_stars.89a30f9950"
[0m18:32:42.278901 [debug] [Thread-1 (]: On test.data_ai_index.not_null_stg_github__repo_stats_repo_id.cc3c373a4c: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select repo_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats
where repo_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_stg_github__repo_stats_repo_id.cc3c373a4c"} */
[0m18:32:42.281598 [debug] [Thread-3 (]: Began executing node test.data_ai_index.not_null_stg_github__repo_stats_stars.89a30f9950
[0m18:32:42.284800 [debug] [Thread-3 (]: Writing runtime sql for node "test.data_ai_index.not_null_stg_github__repo_stats_stars.89a30f9950"
[0m18:32:42.286445 [debug] [Thread-3 (]: Using snowflake connection "test.data_ai_index.not_null_stg_github__repo_stats_stars.89a30f9950"
[0m18:32:42.287258 [debug] [Thread-3 (]: On test.data_ai_index.not_null_stg_github__repo_stats_stars.89a30f9950: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select stars
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats
where stars is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_stg_github__repo_stats_stars.89a30f9950"} */
[0m18:32:42.369666 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.178 seconds
[0m18:32:42.372323 [info ] [Thread-4 (]: 27 of 49 PASS not_null_stg_github__repo_stats_category ......................... [[32mPASS[0m in 0.22s]
[0m18:32:42.373310 [debug] [Thread-4 (]: Finished running node test.data_ai_index.not_null_stg_github__repo_stats_category.0bab32271a
[0m18:32:42.374149 [debug] [Thread-4 (]: Began running node test.data_ai_index.not_null_stg_hn__job_postings_posting_id.490b94c4ba
[0m18:32:42.375454 [info ] [Thread-4 (]: 30 of 49 START test not_null_stg_hn__job_postings_posting_id ................... [RUN]
[0m18:32:42.376416 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_stg_github__repo_stats_category.0bab32271a, now test.data_ai_index.not_null_stg_hn__job_postings_posting_id.490b94c4ba)
[0m18:32:42.377254 [debug] [Thread-4 (]: Began compiling node test.data_ai_index.not_null_stg_hn__job_postings_posting_id.490b94c4ba
[0m18:32:42.386445 [debug] [Thread-4 (]: Writing injected SQL for node "test.data_ai_index.not_null_stg_hn__job_postings_posting_id.490b94c4ba"
[0m18:32:42.387699 [debug] [Thread-4 (]: Began executing node test.data_ai_index.not_null_stg_hn__job_postings_posting_id.490b94c4ba
[0m18:32:42.390540 [debug] [Thread-4 (]: Writing runtime sql for node "test.data_ai_index.not_null_stg_hn__job_postings_posting_id.490b94c4ba"
[0m18:32:42.393145 [debug] [Thread-4 (]: Using snowflake connection "test.data_ai_index.not_null_stg_hn__job_postings_posting_id.490b94c4ba"
[0m18:32:42.394463 [debug] [Thread-4 (]: On test.data_ai_index.not_null_stg_hn__job_postings_posting_id.490b94c4ba: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select posting_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_hn__job_postings
where posting_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_stg_hn__job_postings_posting_id.490b94c4ba"} */
[0m18:32:42.430421 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.243 seconds
[0m18:32:42.434062 [info ] [Thread-2 (]: 26 of 49 PASS not_null_int_linkedin__skills_standardized_skill_name ............ [[32mPASS[0m in 0.29s]
[0m18:32:42.435009 [debug] [Thread-2 (]: Finished running node test.data_ai_index.not_null_int_linkedin__skills_standardized_skill_name.714de4e628
[0m18:32:42.435562 [debug] [Thread-2 (]: Began running node test.data_ai_index.not_null_stg_hn__job_postings_posting_text.79d3b4f60e
[0m18:32:42.436145 [info ] [Thread-2 (]: 31 of 49 START test not_null_stg_hn__job_postings_posting_text ................. [RUN]
[0m18:32:42.437059 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_int_linkedin__skills_standardized_skill_name.714de4e628, now test.data_ai_index.not_null_stg_hn__job_postings_posting_text.79d3b4f60e)
[0m18:32:42.437601 [debug] [Thread-2 (]: Began compiling node test.data_ai_index.not_null_stg_hn__job_postings_posting_text.79d3b4f60e
[0m18:32:42.444513 [debug] [Thread-2 (]: Writing injected SQL for node "test.data_ai_index.not_null_stg_hn__job_postings_posting_text.79d3b4f60e"
[0m18:32:42.445616 [debug] [Thread-2 (]: Began executing node test.data_ai_index.not_null_stg_hn__job_postings_posting_text.79d3b4f60e
[0m18:32:42.449643 [debug] [Thread-2 (]: Writing runtime sql for node "test.data_ai_index.not_null_stg_hn__job_postings_posting_text.79d3b4f60e"
[0m18:32:42.451428 [debug] [Thread-2 (]: Using snowflake connection "test.data_ai_index.not_null_stg_hn__job_postings_posting_text.79d3b4f60e"
[0m18:32:42.452348 [debug] [Thread-2 (]: On test.data_ai_index.not_null_stg_hn__job_postings_posting_text.79d3b4f60e: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select posting_text
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_hn__job_postings
where posting_text is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_stg_hn__job_postings_posting_text.79d3b4f60e"} */
[0m18:32:42.545133 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.257 seconds
[0m18:32:42.548232 [info ] [Thread-3 (]: 29 of 49 PASS not_null_stg_github__repo_stats_stars ............................ [[32mPASS[0m in 0.29s]
[0m18:32:42.550015 [debug] [Thread-3 (]: Finished running node test.data_ai_index.not_null_stg_github__repo_stats_stars.89a30f9950
[0m18:32:42.552067 [debug] [Thread-3 (]: Began running node test.data_ai_index.not_null_stg_linkedin__postings_job_title.2bcfcdfcfd
[0m18:32:42.554539 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.275 seconds
[0m18:32:42.556091 [info ] [Thread-3 (]: 32 of 49 START test not_null_stg_linkedin__postings_job_title .................. [RUN]
[0m18:32:42.561232 [info ] [Thread-1 (]: 28 of 49 PASS not_null_stg_github__repo_stats_repo_id .......................... [[32mPASS[0m in 0.32s]
[0m18:32:42.563297 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_stg_github__repo_stats_stars.89a30f9950, now test.data_ai_index.not_null_stg_linkedin__postings_job_title.2bcfcdfcfd)
[0m18:32:42.565163 [debug] [Thread-1 (]: Finished running node test.data_ai_index.not_null_stg_github__repo_stats_repo_id.cc3c373a4c
[0m18:32:42.566069 [debug] [Thread-3 (]: Began compiling node test.data_ai_index.not_null_stg_linkedin__postings_job_title.2bcfcdfcfd
[0m18:32:42.567243 [debug] [Thread-1 (]: Began running node test.data_ai_index.not_null_stg_linkedin__postings_posting_id.7da96baf0a
[0m18:32:42.573728 [debug] [Thread-3 (]: Writing injected SQL for node "test.data_ai_index.not_null_stg_linkedin__postings_job_title.2bcfcdfcfd"
[0m18:32:42.574734 [info ] [Thread-1 (]: 33 of 49 START test not_null_stg_linkedin__postings_posting_id ................. [RUN]
[0m18:32:42.575953 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_stg_github__repo_stats_repo_id.cc3c373a4c, now test.data_ai_index.not_null_stg_linkedin__postings_posting_id.7da96baf0a)
[0m18:32:42.577055 [debug] [Thread-1 (]: Began compiling node test.data_ai_index.not_null_stg_linkedin__postings_posting_id.7da96baf0a
[0m18:32:42.583562 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_ai_index.not_null_stg_linkedin__postings_posting_id.7da96baf0a"
[0m18:32:42.584485 [debug] [Thread-3 (]: Began executing node test.data_ai_index.not_null_stg_linkedin__postings_job_title.2bcfcdfcfd
[0m18:32:42.587868 [debug] [Thread-3 (]: Writing runtime sql for node "test.data_ai_index.not_null_stg_linkedin__postings_job_title.2bcfcdfcfd"
[0m18:32:42.588881 [debug] [Thread-1 (]: Began executing node test.data_ai_index.not_null_stg_linkedin__postings_posting_id.7da96baf0a
[0m18:32:42.594081 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_ai_index.not_null_stg_linkedin__postings_posting_id.7da96baf0a"
[0m18:32:42.596643 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.201 seconds
[0m18:32:42.597762 [debug] [Thread-3 (]: Using snowflake connection "test.data_ai_index.not_null_stg_linkedin__postings_job_title.2bcfcdfcfd"
[0m18:32:42.602132 [info ] [Thread-4 (]: 30 of 49 PASS not_null_stg_hn__job_postings_posting_id ......................... [[32mPASS[0m in 0.23s]
[0m18:32:42.603545 [debug] [Thread-3 (]: On test.data_ai_index.not_null_stg_linkedin__postings_job_title.2bcfcdfcfd: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select job_title
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__postings
where job_title is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_stg_linkedin__postings_job_title.2bcfcdfcfd"} */
[0m18:32:42.605326 [debug] [Thread-4 (]: Finished running node test.data_ai_index.not_null_stg_hn__job_postings_posting_id.490b94c4ba
[0m18:32:42.607007 [debug] [Thread-1 (]: Using snowflake connection "test.data_ai_index.not_null_stg_linkedin__postings_posting_id.7da96baf0a"
[0m18:32:42.608594 [debug] [Thread-4 (]: Began running node test.data_ai_index.not_null_stg_linkedin__skills_posting_id.94cb44b6cd
[0m18:32:42.610168 [debug] [Thread-1 (]: On test.data_ai_index.not_null_stg_linkedin__postings_posting_id.7da96baf0a: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select posting_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__postings
where posting_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_stg_linkedin__postings_posting_id.7da96baf0a"} */
[0m18:32:42.611493 [info ] [Thread-4 (]: 34 of 49 START test not_null_stg_linkedin__skills_posting_id ................... [RUN]
[0m18:32:42.613565 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_stg_hn__job_postings_posting_id.490b94c4ba, now test.data_ai_index.not_null_stg_linkedin__skills_posting_id.94cb44b6cd)
[0m18:32:42.615681 [debug] [Thread-4 (]: Began compiling node test.data_ai_index.not_null_stg_linkedin__skills_posting_id.94cb44b6cd
[0m18:32:42.636176 [debug] [Thread-4 (]: Writing injected SQL for node "test.data_ai_index.not_null_stg_linkedin__skills_posting_id.94cb44b6cd"
[0m18:32:42.639597 [debug] [Thread-4 (]: Began executing node test.data_ai_index.not_null_stg_linkedin__skills_posting_id.94cb44b6cd
[0m18:32:42.643858 [debug] [Thread-4 (]: Writing runtime sql for node "test.data_ai_index.not_null_stg_linkedin__skills_posting_id.94cb44b6cd"
[0m18:32:42.645512 [debug] [Thread-4 (]: Using snowflake connection "test.data_ai_index.not_null_stg_linkedin__skills_posting_id.94cb44b6cd"
[0m18:32:42.646141 [debug] [Thread-4 (]: On test.data_ai_index.not_null_stg_linkedin__skills_posting_id.94cb44b6cd: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select posting_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__skills
where posting_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_stg_linkedin__skills_posting_id.94cb44b6cd"} */
[0m18:32:42.870116 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.258 seconds
[0m18:32:42.873558 [info ] [Thread-1 (]: 33 of 49 PASS not_null_stg_linkedin__postings_posting_id ....................... [[32mPASS[0m in 0.30s]
[0m18:32:42.875650 [debug] [Thread-1 (]: Finished running node test.data_ai_index.not_null_stg_linkedin__postings_posting_id.7da96baf0a
[0m18:32:42.876896 [debug] [Thread-1 (]: Began running node test.data_ai_index.not_null_stg_linkedin__skills_skill_name.cd76332611
[0m18:32:42.877744 [info ] [Thread-1 (]: 35 of 49 START test not_null_stg_linkedin__skills_skill_name ................... [RUN]
[0m18:32:42.878573 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_stg_linkedin__postings_posting_id.7da96baf0a, now test.data_ai_index.not_null_stg_linkedin__skills_skill_name.cd76332611)
[0m18:32:42.879532 [debug] [Thread-1 (]: Began compiling node test.data_ai_index.not_null_stg_linkedin__skills_skill_name.cd76332611
[0m18:32:42.886778 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_ai_index.not_null_stg_linkedin__skills_skill_name.cd76332611"
[0m18:32:42.888969 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.281 seconds
[0m18:32:42.892592 [info ] [Thread-3 (]: 32 of 49 PASS not_null_stg_linkedin__postings_job_title ........................ [[32mPASS[0m in 0.33s]
[0m18:32:42.893536 [debug] [Thread-1 (]: Began executing node test.data_ai_index.not_null_stg_linkedin__skills_skill_name.cd76332611
[0m18:32:42.894908 [debug] [Thread-3 (]: Finished running node test.data_ai_index.not_null_stg_linkedin__postings_job_title.2bcfcdfcfd
[0m18:32:42.900222 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_ai_index.not_null_stg_linkedin__skills_skill_name.cd76332611"
[0m18:32:42.901012 [debug] [Thread-3 (]: Began running node test.data_ai_index.not_null_stg_linkedin__summaries_posting_id.cb0e83b98c
[0m18:32:42.902029 [info ] [Thread-3 (]: 36 of 49 START test not_null_stg_linkedin__summaries_posting_id ................ [RUN]
[0m18:32:42.903136 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_stg_linkedin__postings_job_title.2bcfcdfcfd, now test.data_ai_index.not_null_stg_linkedin__summaries_posting_id.cb0e83b98c)
[0m18:32:42.904047 [debug] [Thread-3 (]: Began compiling node test.data_ai_index.not_null_stg_linkedin__summaries_posting_id.cb0e83b98c
[0m18:32:42.905393 [debug] [Thread-1 (]: Using snowflake connection "test.data_ai_index.not_null_stg_linkedin__skills_skill_name.cd76332611"
[0m18:32:42.917855 [debug] [Thread-1 (]: On test.data_ai_index.not_null_stg_linkedin__skills_skill_name.cd76332611: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select skill_name
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__skills
where skill_name is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_stg_linkedin__skills_skill_name.cd76332611"} */
[0m18:32:42.918691 [debug] [Thread-3 (]: Writing injected SQL for node "test.data_ai_index.not_null_stg_linkedin__summaries_posting_id.cb0e83b98c"
[0m18:32:42.920610 [debug] [Thread-3 (]: Began executing node test.data_ai_index.not_null_stg_linkedin__summaries_posting_id.cb0e83b98c
[0m18:32:42.924883 [debug] [Thread-3 (]: Writing runtime sql for node "test.data_ai_index.not_null_stg_linkedin__summaries_posting_id.cb0e83b98c"
[0m18:32:42.927621 [debug] [Thread-3 (]: Using snowflake connection "test.data_ai_index.not_null_stg_linkedin__summaries_posting_id.cb0e83b98c"
[0m18:32:42.928764 [debug] [Thread-3 (]: On test.data_ai_index.not_null_stg_linkedin__summaries_posting_id.cb0e83b98c: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select posting_id
from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__summaries
where posting_id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.not_null_stg_linkedin__summaries_posting_id.cb0e83b98c"} */
[0m18:32:43.057492 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.410 seconds
[0m18:32:43.062687 [info ] [Thread-4 (]: 34 of 49 PASS not_null_stg_linkedin__skills_posting_id ......................... [[32mPASS[0m in 0.45s]
[0m18:32:43.066186 [debug] [Thread-4 (]: Finished running node test.data_ai_index.not_null_stg_linkedin__skills_posting_id.94cb44b6cd
[0m18:32:43.069613 [debug] [Thread-4 (]: Began running node test.data_ai_index.unique_dim_date_date_key.0869fd48f9
[0m18:32:43.071123 [info ] [Thread-4 (]: 37 of 49 START test unique_dim_date_date_key ................................... [RUN]
[0m18:32:43.072997 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_stg_linkedin__skills_posting_id.94cb44b6cd, now test.data_ai_index.unique_dim_date_date_key.0869fd48f9)
[0m18:32:43.073884 [debug] [Thread-4 (]: Began compiling node test.data_ai_index.unique_dim_date_date_key.0869fd48f9
[0m18:32:43.086303 [debug] [Thread-4 (]: Writing injected SQL for node "test.data_ai_index.unique_dim_date_date_key.0869fd48f9"
[0m18:32:43.087314 [debug] [Thread-4 (]: Began executing node test.data_ai_index.unique_dim_date_date_key.0869fd48f9
[0m18:32:43.090539 [debug] [Thread-4 (]: Writing runtime sql for node "test.data_ai_index.unique_dim_date_date_key.0869fd48f9"
[0m18:32:43.093038 [debug] [Thread-4 (]: Using snowflake connection "test.data_ai_index.unique_dim_date_date_key.0869fd48f9"
[0m18:32:43.094356 [debug] [Thread-4 (]: On test.data_ai_index.unique_dim_date_date_key.0869fd48f9: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    date_key as unique_field,
    count(*) as n_records

from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_date
where date_key is not null
group by date_key
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.unique_dim_date_date_key.0869fd48f9"} */
[0m18:32:43.143213 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.690 seconds
[0m18:32:43.146786 [info ] [Thread-2 (]: 31 of 49 PASS not_null_stg_hn__job_postings_posting_text ....................... [[32mPASS[0m in 0.71s]
[0m18:32:43.148468 [debug] [Thread-2 (]: Finished running node test.data_ai_index.not_null_stg_hn__job_postings_posting_text.79d3b4f60e
[0m18:32:43.149138 [debug] [Thread-2 (]: Began running node test.data_ai_index.unique_dim_roles_role_id.4428347340
[0m18:32:43.150360 [info ] [Thread-2 (]: 38 of 49 START test unique_dim_roles_role_id ................................... [RUN]
[0m18:32:43.151315 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_stg_hn__job_postings_posting_text.79d3b4f60e, now test.data_ai_index.unique_dim_roles_role_id.4428347340)
[0m18:32:43.152274 [debug] [Thread-2 (]: Began compiling node test.data_ai_index.unique_dim_roles_role_id.4428347340
[0m18:32:43.161695 [debug] [Thread-2 (]: Writing injected SQL for node "test.data_ai_index.unique_dim_roles_role_id.4428347340"
[0m18:32:43.162731 [debug] [Thread-2 (]: Began executing node test.data_ai_index.unique_dim_roles_role_id.4428347340
[0m18:32:43.166718 [debug] [Thread-2 (]: Writing runtime sql for node "test.data_ai_index.unique_dim_roles_role_id.4428347340"
[0m18:32:43.168340 [debug] [Thread-2 (]: Using snowflake connection "test.data_ai_index.unique_dim_roles_role_id.4428347340"
[0m18:32:43.168855 [debug] [Thread-2 (]: On test.data_ai_index.unique_dim_roles_role_id.4428347340: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    role_id as unique_field,
    count(*) as n_records

from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_roles
where role_id is not null
group by role_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.unique_dim_roles_role_id.4428347340"} */
[0m18:32:43.328753 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.159 seconds
[0m18:32:43.331439 [info ] [Thread-2 (]: 38 of 49 PASS unique_dim_roles_role_id ......................................... [[32mPASS[0m in 0.18s]
[0m18:32:43.333229 [debug] [Thread-2 (]: Finished running node test.data_ai_index.unique_dim_roles_role_id.4428347340
[0m18:32:43.334345 [debug] [Thread-2 (]: Began running node test.data_ai_index.unique_dim_roles_role_name.afa4ccc649
[0m18:32:43.335609 [info ] [Thread-2 (]: 39 of 49 START test unique_dim_roles_role_name ................................. [RUN]
[0m18:32:43.336662 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.data_ai_index.unique_dim_roles_role_id.4428347340, now test.data_ai_index.unique_dim_roles_role_name.afa4ccc649)
[0m18:32:43.337338 [debug] [Thread-2 (]: Began compiling node test.data_ai_index.unique_dim_roles_role_name.afa4ccc649
[0m18:32:43.342863 [debug] [Thread-2 (]: Writing injected SQL for node "test.data_ai_index.unique_dim_roles_role_name.afa4ccc649"
[0m18:32:43.343772 [debug] [Thread-2 (]: Began executing node test.data_ai_index.unique_dim_roles_role_name.afa4ccc649
[0m18:32:43.346833 [debug] [Thread-2 (]: Writing runtime sql for node "test.data_ai_index.unique_dim_roles_role_name.afa4ccc649"
[0m18:32:43.348793 [debug] [Thread-2 (]: Using snowflake connection "test.data_ai_index.unique_dim_roles_role_name.afa4ccc649"
[0m18:32:43.349863 [debug] [Thread-2 (]: On test.data_ai_index.unique_dim_roles_role_name.afa4ccc649: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    role_name as unique_field,
    count(*) as n_records

from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_roles
where role_name is not null
group by role_name
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.unique_dim_roles_role_name.afa4ccc649"} */
[0m18:32:43.384265 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.289 seconds
[0m18:32:43.388254 [info ] [Thread-4 (]: 37 of 49 PASS unique_dim_date_date_key ......................................... [[32mPASS[0m in 0.31s]
[0m18:32:43.390859 [debug] [Thread-4 (]: Finished running node test.data_ai_index.unique_dim_date_date_key.0869fd48f9
[0m18:32:43.392024 [debug] [Thread-4 (]: Began running node test.data_ai_index.unique_dim_technologies_technology_id.477695a9fd
[0m18:32:43.392687 [info ] [Thread-4 (]: 40 of 49 START test unique_dim_technologies_technology_id ...................... [RUN]
[0m18:32:43.393483 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.data_ai_index.unique_dim_date_date_key.0869fd48f9, now test.data_ai_index.unique_dim_technologies_technology_id.477695a9fd)
[0m18:32:43.394041 [debug] [Thread-4 (]: Began compiling node test.data_ai_index.unique_dim_technologies_technology_id.477695a9fd
[0m18:32:43.518606 [debug] [Thread-4 (]: Writing injected SQL for node "test.data_ai_index.unique_dim_technologies_technology_id.477695a9fd"
[0m18:32:43.570087 [debug] [Thread-4 (]: Began executing node test.data_ai_index.unique_dim_technologies_technology_id.477695a9fd
[0m18:32:43.580823 [debug] [Thread-4 (]: Writing runtime sql for node "test.data_ai_index.unique_dim_technologies_technology_id.477695a9fd"
[0m18:32:43.595916 [debug] [Thread-4 (]: Using snowflake connection "test.data_ai_index.unique_dim_technologies_technology_id.477695a9fd"
[0m18:32:43.602795 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.672 seconds
[0m18:32:43.604212 [debug] [Thread-4 (]: On test.data_ai_index.unique_dim_technologies_technology_id.477695a9fd: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    technology_id as unique_field,
    count(*) as n_records

from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_technologies
where technology_id is not null
group by technology_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.unique_dim_technologies_technology_id.477695a9fd"} */
[0m18:32:43.607507 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.257 seconds
[0m18:32:43.611978 [info ] [Thread-3 (]: 36 of 49 PASS not_null_stg_linkedin__summaries_posting_id ...................... [[32mPASS[0m in 0.71s]
[0m18:32:43.617707 [info ] [Thread-2 (]: 39 of 49 PASS unique_dim_roles_role_name ....................................... [[32mPASS[0m in 0.28s]
[0m18:32:43.618995 [debug] [Thread-3 (]: Finished running node test.data_ai_index.not_null_stg_linkedin__summaries_posting_id.cb0e83b98c
[0m18:32:43.620828 [debug] [Thread-2 (]: Finished running node test.data_ai_index.unique_dim_roles_role_name.afa4ccc649
[0m18:32:43.622249 [debug] [Thread-3 (]: Began running node test.data_ai_index.unique_dim_technologies_technology_name.7589c62256
[0m18:32:43.623511 [debug] [Thread-2 (]: Began running node test.data_ai_index.unique_fct_github_repo_stats_repo_id.af46e0c84b
[0m18:32:43.625691 [info ] [Thread-3 (]: 41 of 49 START test unique_dim_technologies_technology_name .................... [RUN]
[0m18:32:43.627164 [info ] [Thread-2 (]: 42 of 49 START test unique_fct_github_repo_stats_repo_id ....................... [RUN]
[0m18:32:43.629110 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_stg_linkedin__summaries_posting_id.cb0e83b98c, now test.data_ai_index.unique_dim_technologies_technology_name.7589c62256)
[0m18:32:43.629993 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.data_ai_index.unique_dim_roles_role_name.afa4ccc649, now test.data_ai_index.unique_fct_github_repo_stats_repo_id.af46e0c84b)
[0m18:32:43.631558 [debug] [Thread-3 (]: Began compiling node test.data_ai_index.unique_dim_technologies_technology_name.7589c62256
[0m18:32:43.632461 [debug] [Thread-2 (]: Began compiling node test.data_ai_index.unique_fct_github_repo_stats_repo_id.af46e0c84b
[0m18:32:43.641412 [debug] [Thread-3 (]: Writing injected SQL for node "test.data_ai_index.unique_dim_technologies_technology_name.7589c62256"
[0m18:32:43.657691 [debug] [Thread-2 (]: Writing injected SQL for node "test.data_ai_index.unique_fct_github_repo_stats_repo_id.af46e0c84b"
[0m18:32:43.659693 [debug] [Thread-3 (]: Began executing node test.data_ai_index.unique_dim_technologies_technology_name.7589c62256
[0m18:32:43.665307 [debug] [Thread-3 (]: Writing runtime sql for node "test.data_ai_index.unique_dim_technologies_technology_name.7589c62256"
[0m18:32:43.666791 [debug] [Thread-2 (]: Began executing node test.data_ai_index.unique_fct_github_repo_stats_repo_id.af46e0c84b
[0m18:32:43.672751 [debug] [Thread-2 (]: Writing runtime sql for node "test.data_ai_index.unique_fct_github_repo_stats_repo_id.af46e0c84b"
[0m18:32:43.674824 [debug] [Thread-3 (]: Using snowflake connection "test.data_ai_index.unique_dim_technologies_technology_name.7589c62256"
[0m18:32:43.676453 [debug] [Thread-3 (]: On test.data_ai_index.unique_dim_technologies_technology_name.7589c62256: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    technology_name as unique_field,
    count(*) as n_records

from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.dim_technologies
where technology_name is not null
group by technology_name
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.unique_dim_technologies_technology_name.7589c62256"} */
[0m18:32:43.679173 [debug] [Thread-2 (]: Using snowflake connection "test.data_ai_index.unique_fct_github_repo_stats_repo_id.af46e0c84b"
[0m18:32:43.679888 [debug] [Thread-2 (]: On test.data_ai_index.unique_fct_github_repo_stats_repo_id.af46e0c84b: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    repo_id as unique_field,
    count(*) as n_records

from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_github_repo_stats
where repo_id is not null
group by repo_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.unique_fct_github_repo_stats_repo_id.af46e0c84b"} */
[0m18:32:43.932730 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.320 seconds
[0m18:32:43.936024 [info ] [Thread-4 (]: 40 of 49 PASS unique_dim_technologies_technology_id ............................ [[32mPASS[0m in 0.54s]
[0m18:32:43.936922 [debug] [Thread-4 (]: Finished running node test.data_ai_index.unique_dim_technologies_technology_id.477695a9fd
[0m18:32:43.937425 [debug] [Thread-4 (]: Began running node test.data_ai_index.unique_fct_hn_role_mentions_mention_id.64ddc42167
[0m18:32:43.937852 [info ] [Thread-4 (]: 43 of 49 START test unique_fct_hn_role_mentions_mention_id ..................... [RUN]
[0m18:32:43.938448 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.data_ai_index.unique_dim_technologies_technology_id.477695a9fd, now test.data_ai_index.unique_fct_hn_role_mentions_mention_id.64ddc42167)
[0m18:32:43.938905 [debug] [Thread-4 (]: Began compiling node test.data_ai_index.unique_fct_hn_role_mentions_mention_id.64ddc42167
[0m18:32:43.943447 [debug] [Thread-4 (]: Writing injected SQL for node "test.data_ai_index.unique_fct_hn_role_mentions_mention_id.64ddc42167"
[0m18:32:43.944369 [debug] [Thread-4 (]: Began executing node test.data_ai_index.unique_fct_hn_role_mentions_mention_id.64ddc42167
[0m18:32:43.948077 [debug] [Thread-4 (]: Writing runtime sql for node "test.data_ai_index.unique_fct_hn_role_mentions_mention_id.64ddc42167"
[0m18:32:43.950958 [debug] [Thread-4 (]: Using snowflake connection "test.data_ai_index.unique_fct_hn_role_mentions_mention_id.64ddc42167"
[0m18:32:43.952567 [debug] [Thread-4 (]: On test.data_ai_index.unique_fct_hn_role_mentions_mention_id.64ddc42167: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    mention_id as unique_field,
    count(*) as n_records

from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_hn_role_mentions
where mention_id is not null
group by mention_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.unique_fct_hn_role_mentions_mention_id.64ddc42167"} */
[0m18:32:43.982929 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.302 seconds
[0m18:32:43.986778 [info ] [Thread-2 (]: 42 of 49 PASS unique_fct_github_repo_stats_repo_id ............................. [[32mPASS[0m in 0.36s]
[0m18:32:43.987811 [debug] [Thread-2 (]: Finished running node test.data_ai_index.unique_fct_github_repo_stats_repo_id.af46e0c84b
[0m18:32:43.988363 [debug] [Thread-2 (]: Began running node test.data_ai_index.unique_fct_hn_technology_mentions_mention_id.7395652166
[0m18:32:43.988822 [info ] [Thread-2 (]: 44 of 49 START test unique_fct_hn_technology_mentions_mention_id ............... [RUN]
[0m18:32:43.989913 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.data_ai_index.unique_fct_github_repo_stats_repo_id.af46e0c84b, now test.data_ai_index.unique_fct_hn_technology_mentions_mention_id.7395652166)
[0m18:32:43.990697 [debug] [Thread-2 (]: Began compiling node test.data_ai_index.unique_fct_hn_technology_mentions_mention_id.7395652166
[0m18:32:43.992083 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 0.315 seconds
[0m18:32:44.001273 [info ] [Thread-3 (]: 41 of 49 PASS unique_dim_technologies_technology_name .......................... [[32mPASS[0m in 0.37s]
[0m18:32:44.002428 [debug] [Thread-2 (]: Writing injected SQL for node "test.data_ai_index.unique_fct_hn_technology_mentions_mention_id.7395652166"
[0m18:32:44.003886 [debug] [Thread-3 (]: Finished running node test.data_ai_index.unique_dim_technologies_technology_name.7589c62256
[0m18:32:44.005382 [debug] [Thread-3 (]: Began running node test.data_ai_index.unique_fct_linkedin_skill_counts_skill_name.af9fb76193
[0m18:32:44.006269 [info ] [Thread-3 (]: 45 of 49 START test unique_fct_linkedin_skill_counts_skill_name ................ [RUN]
[0m18:32:44.007326 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.data_ai_index.unique_dim_technologies_technology_name.7589c62256, now test.data_ai_index.unique_fct_linkedin_skill_counts_skill_name.af9fb76193)
[0m18:32:44.008390 [debug] [Thread-3 (]: Began compiling node test.data_ai_index.unique_fct_linkedin_skill_counts_skill_name.af9fb76193
[0m18:32:44.014823 [debug] [Thread-2 (]: Began executing node test.data_ai_index.unique_fct_hn_technology_mentions_mention_id.7395652166
[0m18:32:44.019698 [debug] [Thread-3 (]: Writing injected SQL for node "test.data_ai_index.unique_fct_linkedin_skill_counts_skill_name.af9fb76193"
[0m18:32:44.023653 [debug] [Thread-2 (]: Writing runtime sql for node "test.data_ai_index.unique_fct_hn_technology_mentions_mention_id.7395652166"
[0m18:32:44.026791 [debug] [Thread-3 (]: Began executing node test.data_ai_index.unique_fct_linkedin_skill_counts_skill_name.af9fb76193
[0m18:32:44.028703 [debug] [Thread-2 (]: Using snowflake connection "test.data_ai_index.unique_fct_hn_technology_mentions_mention_id.7395652166"
[0m18:32:44.035813 [debug] [Thread-3 (]: Writing runtime sql for node "test.data_ai_index.unique_fct_linkedin_skill_counts_skill_name.af9fb76193"
[0m18:32:44.037100 [debug] [Thread-2 (]: On test.data_ai_index.unique_fct_hn_technology_mentions_mention_id.7395652166: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    mention_id as unique_field,
    count(*) as n_records

from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_hn_technology_mentions
where mention_id is not null
group by mention_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.unique_fct_hn_technology_mentions_mention_id.7395652166"} */
[0m18:32:44.039789 [debug] [Thread-3 (]: Using snowflake connection "test.data_ai_index.unique_fct_linkedin_skill_counts_skill_name.af9fb76193"
[0m18:32:44.040604 [debug] [Thread-3 (]: On test.data_ai_index.unique_fct_linkedin_skill_counts_skill_name.af9fb76193: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    skill_name as unique_field,
    count(*) as n_records

from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_marts.fct_linkedin_skill_counts
where skill_name is not null
group by skill_name
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.unique_fct_linkedin_skill_counts_skill_name.af9fb76193"} */
[0m18:32:44.117520 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.164 seconds
[0m18:32:44.120597 [info ] [Thread-4 (]: 43 of 49 PASS unique_fct_hn_role_mentions_mention_id ........................... [[32mPASS[0m in 0.18s]
[0m18:32:44.121538 [debug] [Thread-4 (]: Finished running node test.data_ai_index.unique_fct_hn_role_mentions_mention_id.64ddc42167
[0m18:32:44.122425 [debug] [Thread-4 (]: Began running node test.data_ai_index.unique_stg_github__repo_stats_repo_id.97f7303bba
[0m18:32:44.123205 [info ] [Thread-4 (]: 46 of 49 START test unique_stg_github__repo_stats_repo_id ...................... [RUN]
[0m18:32:44.124106 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.data_ai_index.unique_fct_hn_role_mentions_mention_id.64ddc42167, now test.data_ai_index.unique_stg_github__repo_stats_repo_id.97f7303bba)
[0m18:32:44.124620 [debug] [Thread-4 (]: Began compiling node test.data_ai_index.unique_stg_github__repo_stats_repo_id.97f7303bba
[0m18:32:44.128983 [debug] [Thread-4 (]: Writing injected SQL for node "test.data_ai_index.unique_stg_github__repo_stats_repo_id.97f7303bba"
[0m18:32:44.131728 [debug] [Thread-4 (]: Began executing node test.data_ai_index.unique_stg_github__repo_stats_repo_id.97f7303bba
[0m18:32:44.145074 [debug] [Thread-4 (]: Writing runtime sql for node "test.data_ai_index.unique_stg_github__repo_stats_repo_id.97f7303bba"
[0m18:32:44.146502 [debug] [Thread-4 (]: Using snowflake connection "test.data_ai_index.unique_stg_github__repo_stats_repo_id.97f7303bba"
[0m18:32:44.148894 [debug] [Thread-4 (]: On test.data_ai_index.unique_stg_github__repo_stats_repo_id.97f7303bba: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    repo_id as unique_field,
    count(*) as n_records

from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_github__repo_stats
where repo_id is not null
group by repo_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.unique_stg_github__repo_stats_repo_id.97f7303bba"} */
[0m18:32:44.185512 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.147 seconds
[0m18:32:44.188305 [info ] [Thread-2 (]: 44 of 49 PASS unique_fct_hn_technology_mentions_mention_id ..................... [[32mPASS[0m in 0.20s]
[0m18:32:44.189174 [debug] [Thread-2 (]: Finished running node test.data_ai_index.unique_fct_hn_technology_mentions_mention_id.7395652166
[0m18:32:44.189965 [debug] [Thread-2 (]: Began running node test.data_ai_index.unique_stg_hn__job_postings_posting_id.7a1f313e5d
[0m18:32:44.190814 [info ] [Thread-2 (]: 47 of 49 START test unique_stg_hn__job_postings_posting_id ..................... [RUN]
[0m18:32:44.191607 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.data_ai_index.unique_fct_hn_technology_mentions_mention_id.7395652166, now test.data_ai_index.unique_stg_hn__job_postings_posting_id.7a1f313e5d)
[0m18:32:44.192068 [debug] [Thread-2 (]: Began compiling node test.data_ai_index.unique_stg_hn__job_postings_posting_id.7a1f313e5d
[0m18:32:44.196476 [debug] [Thread-2 (]: Writing injected SQL for node "test.data_ai_index.unique_stg_hn__job_postings_posting_id.7a1f313e5d"
[0m18:32:44.198586 [debug] [Thread-2 (]: Began executing node test.data_ai_index.unique_stg_hn__job_postings_posting_id.7a1f313e5d
[0m18:32:44.203172 [debug] [Thread-2 (]: Writing runtime sql for node "test.data_ai_index.unique_stg_hn__job_postings_posting_id.7a1f313e5d"
[0m18:32:44.205347 [debug] [Thread-2 (]: Using snowflake connection "test.data_ai_index.unique_stg_hn__job_postings_posting_id.7a1f313e5d"
[0m18:32:44.206109 [debug] [Thread-2 (]: On test.data_ai_index.unique_stg_hn__job_postings_posting_id.7a1f313e5d: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    posting_id as unique_field,
    count(*) as n_records

from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_hn__job_postings
where posting_id is not null
group by posting_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.unique_stg_hn__job_postings_posting_id.7a1f313e5d"} */
[0m18:32:44.362306 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.213 seconds
[0m18:32:44.365880 [info ] [Thread-4 (]: 46 of 49 PASS unique_stg_github__repo_stats_repo_id ............................ [[32mPASS[0m in 0.24s]
[0m18:32:44.367186 [debug] [Thread-4 (]: Finished running node test.data_ai_index.unique_stg_github__repo_stats_repo_id.97f7303bba
[0m18:32:44.367945 [debug] [Thread-4 (]: Began running node test.data_ai_index.unique_stg_linkedin__postings_posting_id.ce232b5882
[0m18:32:44.368989 [info ] [Thread-4 (]: 48 of 49 START test unique_stg_linkedin__postings_posting_id ................... [RUN]
[0m18:32:44.369930 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.data_ai_index.unique_stg_github__repo_stats_repo_id.97f7303bba, now test.data_ai_index.unique_stg_linkedin__postings_posting_id.ce232b5882)
[0m18:32:44.370946 [debug] [Thread-4 (]: Began compiling node test.data_ai_index.unique_stg_linkedin__postings_posting_id.ce232b5882
[0m18:32:44.376454 [debug] [Thread-4 (]: Writing injected SQL for node "test.data_ai_index.unique_stg_linkedin__postings_posting_id.ce232b5882"
[0m18:32:44.377769 [debug] [Thread-4 (]: Began executing node test.data_ai_index.unique_stg_linkedin__postings_posting_id.ce232b5882
[0m18:32:44.382224 [debug] [Thread-4 (]: Writing runtime sql for node "test.data_ai_index.unique_stg_linkedin__postings_posting_id.ce232b5882"
[0m18:32:44.384995 [debug] [Thread-4 (]: Using snowflake connection "test.data_ai_index.unique_stg_linkedin__postings_posting_id.ce232b5882"
[0m18:32:44.385823 [debug] [Thread-4 (]: On test.data_ai_index.unique_stg_linkedin__postings_posting_id.ce232b5882: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    posting_id as unique_field,
    count(*) as n_records

from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__postings
where posting_id is not null
group by posting_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.unique_stg_linkedin__postings_posting_id.ce232b5882"} */
[0m18:32:44.451947 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1.533 seconds
[0m18:32:44.456924 [info ] [Thread-1 (]: 35 of 49 PASS not_null_stg_linkedin__skills_skill_name ......................... [[32mPASS[0m in 1.58s]
[0m18:32:44.458556 [debug] [Thread-1 (]: Finished running node test.data_ai_index.not_null_stg_linkedin__skills_skill_name.cd76332611
[0m18:32:44.459983 [debug] [Thread-1 (]: Began running node test.data_ai_index.unique_stg_linkedin__summaries_posting_id.2f250e809e
[0m18:32:44.461097 [info ] [Thread-1 (]: 49 of 49 START test unique_stg_linkedin__summaries_posting_id .................. [RUN]
[0m18:32:44.462093 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_ai_index.not_null_stg_linkedin__skills_skill_name.cd76332611, now test.data_ai_index.unique_stg_linkedin__summaries_posting_id.2f250e809e)
[0m18:32:44.462984 [debug] [Thread-1 (]: Began compiling node test.data_ai_index.unique_stg_linkedin__summaries_posting_id.2f250e809e
[0m18:32:44.470617 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_ai_index.unique_stg_linkedin__summaries_posting_id.2f250e809e"
[0m18:32:44.471597 [debug] [Thread-1 (]: Began executing node test.data_ai_index.unique_stg_linkedin__summaries_posting_id.2f250e809e
[0m18:32:44.476128 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_ai_index.unique_stg_linkedin__summaries_posting_id.2f250e809e"
[0m18:32:44.477851 [debug] [Thread-1 (]: Using snowflake connection "test.data_ai_index.unique_stg_linkedin__summaries_posting_id.2f250e809e"
[0m18:32:44.478571 [debug] [Thread-1 (]: On test.data_ai_index.unique_stg_linkedin__summaries_posting_id.2f250e809e: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    posting_id as unique_field,
    count(*) as n_records

from DATAEXPERT_STUDENT.KOUVERK_DATA_INDUSTRY_staging.stg_linkedin__summaries
where posting_id is not null
group by posting_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "data_ai_index", "target_name": "dev", "node_id": "test.data_ai_index.unique_stg_linkedin__summaries_posting_id.2f250e809e"} */
[0m18:32:44.681568 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.475 seconds
[0m18:32:44.684412 [info ] [Thread-2 (]: 47 of 49 PASS unique_stg_hn__job_postings_posting_id ........................... [[32mPASS[0m in 0.49s]
[0m18:32:44.686045 [debug] [Thread-2 (]: Finished running node test.data_ai_index.unique_stg_hn__job_postings_posting_id.7a1f313e5d
[0m18:32:45.254099 [debug] [Thread-3 (]: SQL status: SUCCESS 1 in 1.213 seconds
[0m18:32:45.256940 [error] [Thread-3 (]: 45 of 49 FAIL 4 unique_fct_linkedin_skill_counts_skill_name .................... [[31mFAIL 4[0m in 1.25s]
[0m18:32:45.258138 [debug] [Thread-3 (]: Finished running node test.data_ai_index.unique_fct_linkedin_skill_counts_skill_name.af9fb76193
[0m18:32:45.346883 [debug] [Thread-4 (]: SQL status: SUCCESS 1 in 0.960 seconds
[0m18:32:45.349402 [info ] [Thread-4 (]: 48 of 49 PASS unique_stg_linkedin__postings_posting_id ......................... [[32mPASS[0m in 0.98s]
[0m18:32:45.350546 [debug] [Thread-4 (]: Finished running node test.data_ai_index.unique_stg_linkedin__postings_posting_id.ce232b5882
[0m18:32:47.046762 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 2.568 seconds
[0m18:32:47.049740 [info ] [Thread-1 (]: 49 of 49 PASS unique_stg_linkedin__summaries_posting_id ........................ [[32mPASS[0m in 2.59s]
[0m18:32:47.050943 [debug] [Thread-1 (]: Finished running node test.data_ai_index.unique_stg_linkedin__summaries_posting_id.2f250e809e
[0m18:32:47.053165 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:32:47.053572 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging' was left open.
[0m18:32:47.053926 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_staging: Close
[0m18:32:47.214856 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate' was left open.
[0m18:32:47.215763 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_intermediate: Close
[0m18:32:47.404220 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY' was left open.
[0m18:32:47.405479 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY: Close
[0m18:32:47.562901 [debug] [MainThread]: Connection 'list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts' was left open.
[0m18:32:47.563935 [debug] [MainThread]: On list_DATAEXPERT_STUDENT_KOUVERK_DATA_INDUSTRY_marts: Close
[0m18:32:47.725725 [debug] [MainThread]: Connection 'test.data_ai_index.unique_stg_hn__job_postings_posting_id.7a1f313e5d' was left open.
[0m18:32:47.726242 [debug] [MainThread]: On test.data_ai_index.unique_stg_hn__job_postings_posting_id.7a1f313e5d: Close
[0m18:32:47.925270 [debug] [MainThread]: Connection 'test.data_ai_index.unique_stg_linkedin__summaries_posting_id.2f250e809e' was left open.
[0m18:32:47.925931 [debug] [MainThread]: On test.data_ai_index.unique_stg_linkedin__summaries_posting_id.2f250e809e: Close
[0m18:32:48.103215 [debug] [MainThread]: Connection 'test.data_ai_index.unique_fct_linkedin_skill_counts_skill_name.af9fb76193' was left open.
[0m18:32:48.104374 [debug] [MainThread]: On test.data_ai_index.unique_fct_linkedin_skill_counts_skill_name.af9fb76193: Close
[0m18:32:48.278263 [debug] [MainThread]: Connection 'test.data_ai_index.unique_stg_linkedin__postings_posting_id.ce232b5882' was left open.
[0m18:32:48.279080 [debug] [MainThread]: On test.data_ai_index.unique_stg_linkedin__postings_posting_id.ce232b5882: Close
[0m18:32:48.463486 [info ] [MainThread]: 
[0m18:32:48.464103 [info ] [MainThread]: Finished running 49 data tests in 0 hours 0 minutes and 14.69 seconds (14.69s).
[0m18:32:48.477875 [debug] [MainThread]: Command end result
[0m18:32:48.528610 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/manifest.json
[0m18:32:48.531671 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/semantic_manifest.json
[0m18:32:48.543845 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/kouverbingham/development/data-expert-analytics/data-ai-industry-index-tracker/dbt/target/run_results.json
[0m18:32:48.544573 [info ] [MainThread]: 
[0m18:32:48.545088 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:32:48.545881 [info ] [MainThread]: 
[0m18:32:48.546528 [error] [MainThread]: [31mFailure in test unique_fct_linkedin_skill_counts_skill_name (models/marts/_marts__models.yml)[0m
[0m18:32:48.546980 [error] [MainThread]:   Got 4 results, configured to fail if != 0
[0m18:32:48.547350 [info ] [MainThread]: 
[0m18:32:48.547773 [info ] [MainThread]:   compiled code at target/compiled/data_ai_index/models/marts/_marts__models.yml/unique_fct_linkedin_skill_counts_skill_name.sql
[0m18:32:48.548259 [info ] [MainThread]: 
[0m18:32:48.549121 [info ] [MainThread]: Done. PASS=48 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=49
[0m18:32:48.554045 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 17.177319, "process_in_blocks": "0", "process_kernel_time": 1.321097, "process_mem_max_rss": "243212288", "process_out_blocks": "0", "process_user_time": 8.371136}
[0m18:32:48.554775 [debug] [MainThread]: Command `dbt test` failed at 18:32:48.554636 after 17.18 seconds
[0m18:32:48.555315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbe0410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f30fe30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f30fd80>]}
[0m18:32:48.555776 [debug] [MainThread]: Flushing usage events
[0m18:32:48.813973 [debug] [MainThread]: An error was encountered while trying to flush usage events
